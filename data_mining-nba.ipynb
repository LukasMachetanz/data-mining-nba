{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3815,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sb\n",
    "sb.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sb.color_palette(\"bright\", 10)\n",
    "\"\"\"\n",
    "\n",
    "# In order to see full screen (horizontal scrolling) dataframes\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Ziel / Problembeschreibung\n",
    "\n",
    "Für den gewählten Datensatz soll versucht werden mittels Regressionsmethoden die Gehälter der NBA-Spieler vorherzusagen. Welche Features sind ausschlaggebend für ein hohes bzw. niedriges Gehalt?\n",
    "\n",
    "Es soll ein Regressionsproblem gelöst werden, wodurch folgende Bereiche behandelt werden sollen:\n",
    "\n",
    "- Linear Regression (Regression)\n",
    "- KNN (Regression)\n",
    "- Decision Tree (Regression)\n",
    "- Neuronal Network (Regression)\n",
    "\n",
    "\n",
    "- PCA (visualisieren)\n",
    "- T-SNE (visualisieren)\n",
    "\n",
    "\n",
    "- KMeans (CLustern)\n",
    "- Spectral Clustering (Clustern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Wie?\n",
    "\n",
    "Dimensionality Reduction kannst du zum Visualisieren benutzen um visuell zu sehen, ob es Gruppierungen bei den Spielern gibt (Welche Features sind dabei wichtig? zb College oder Position).\n",
    "\n",
    "Mit Clustering kannst du dann die Spieler in k Gruppen einteilen, abhängig von den sportlichen Werten (Wenn man ähnlich gute sportliche Werte hat, hat man dann auch ein ähnliches gutes Gehalt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Daten\n",
    "\n",
    "Die Datensätze __salaries__ und __players__ wurden aus folgender Quelle gewählt: https://data.world/datadavis/nba-salaries.\n",
    "\n",
    "Der Datensatz __seasons_stats__ wurde aus folgender Quelle gewählt: https://www.kaggle.com/drgilermo/nba-players-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3648,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df = pd.read_csv('data/salaries.csv')\n",
    "players_df = pd.read_csv('data/players.csv')\n",
    "seasons_stats_df = pd.read_csv('data/seasons_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Datenaufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === === === === === === === === === ===\n",
    "## Dataframe: Salaries\n",
    "\n",
    "Diese Daten von https://data.world/datadavis/nba-salaries bilden den Ausgangspunkt für die beschriebene Fragestellung. Der Datensatz beinhaltet im Wesentlichen das ausbezahlte __Gehalt__ an einen Spieler für eine bestimmte __Saison__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>player_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>season</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>NBA</td>\n",
       "      <td>dayeda01</td>\n",
       "      <td>120000</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>1986</td>\n",
       "      <td>1985</td>\n",
       "      <td>Washington Bullets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     league player_id  salary   season  season_end  season_start  \\\n",
       "3167    NBA  dayeda01  120000  1985-86        1986          1985   \n",
       "\n",
       "                    team  \n",
       "3167  Washington Bullets  "
      ]
     },
     "execution_count": 3649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Profiling Report\n",
    "\n",
    "Der nachfolgende _Pandas Profiling Report_ verschafft einen vollständigen Überblick (Statistiken, Visualisierungen) über den importierten Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salaries_profile_report = salaries_df.profile_report()\n",
    "# salaries_profile_report.to_file(output_file=\"salaries_profile_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse der einzelnen Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['league', 'player_id', 'salary', 'season', 'season_end', 'season_start',\n",
       "       'team'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### League\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ handelt es sich bei der Variable __league__ um eine Konstante. Alle Spieler des Datensatzes sind in der _NBA_ tätig. Das Feature schafft somit keinen Mehrwert und kann entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     14163\n",
       "unique        1\n",
       "top         NBA\n",
       "freq      14163\n",
       "Name: league, dtype: object"
      ]
     },
     "execution_count": 3652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df['league'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3653,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df.drop(columns=['league'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player ID\n",
    "\n",
    "Die Variable __player_id__ kann zunächst im Datensatz gelassen werden. Über diese ID können später die zusätzlichen Daten des Spielers vom Datensatz __Players__ eingebunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary\n",
    "\n",
    "Die wichtigste Variable __salary__ wird natürlich im Datensatz behalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Season (Start, End)\n",
    "\n",
    "Die Variablen __season__, __season_start__ und __season_end__ müssen nicht alle im Datensatz belassen werden. Die Variable __season__ kann aus den beiden anderen konstruiert werden und ist somit redundant. Sie kann somit entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3654,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_df.drop(columns=['season'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>395000</td>\n",
       "      <td>1991</td>\n",
       "      <td>1990</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>494000</td>\n",
       "      <td>1992</td>\n",
       "      <td>1991</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>500000</td>\n",
       "      <td>1993</td>\n",
       "      <td>1992</td>\n",
       "      <td>Boston Celtics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>805000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>Boston Celtics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>650000</td>\n",
       "      <td>1995</td>\n",
       "      <td>1994</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_id  salary  season_end  season_start                    team\n",
       "0  abdelal01  395000        1991          1990  Portland Trail Blazers\n",
       "1  abdelal01  494000        1992          1991  Portland Trail Blazers\n",
       "2  abdelal01  500000        1993          1992          Boston Celtics\n",
       "3  abdelal01  805000        1994          1993          Boston Celtics\n",
       "4  abdelal01  650000        1995          1994        Sacramento Kings"
      ]
     },
     "execution_count": 3655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14158</th>\n",
       "      <td>zipsepa01</td>\n",
       "      <td>750000</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14159</th>\n",
       "      <td>zipsepa01</td>\n",
       "      <td>1312611</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14160</th>\n",
       "      <td>zizican01</td>\n",
       "      <td>1645200</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14161</th>\n",
       "      <td>zubaciv01</td>\n",
       "      <td>1034956</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>zubaciv01</td>\n",
       "      <td>1312611</td>\n",
       "      <td>2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_id   salary  season_end  season_start                 team\n",
       "14158  zipsepa01   750000        2017          2016        Chicago Bulls\n",
       "14159  zipsepa01  1312611        2018          2017        Chicago Bulls\n",
       "14160  zizican01  1645200        2018          2017  Cleveland Cavaliers\n",
       "14161  zubaciv01  1034956        2017          2016   Los Angeles Lakers\n",
       "14162  zubaciv01  1312611        2018          2017   Los Angeles Lakers"
      ]
     },
     "execution_count": 3656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>parksch02</td>\n",
       "      <td>971000</td>\n",
       "      <td>1996</td>\n",
       "      <td>1995</td>\n",
       "      <td>Dallas Mavericks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>gomesry01</td>\n",
       "      <td>4000000</td>\n",
       "      <td>2011</td>\n",
       "      <td>2010</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>barryjo01</td>\n",
       "      <td>650000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>Milwaukee Bucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10548</th>\n",
       "      <td>redicjj01</td>\n",
       "      <td>7250000</td>\n",
       "      <td>2011</td>\n",
       "      <td>2010</td>\n",
       "      <td>Orlando Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>boshch01</td>\n",
       "      <td>3348000</td>\n",
       "      <td>2006</td>\n",
       "      <td>2005</td>\n",
       "      <td>Toronto Raptors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>harklma01</td>\n",
       "      <td>1731960</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "      <td>Orlando Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>covinro01</td>\n",
       "      <td>1015696</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Philadelphia 76ers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_id   salary  season_end  season_start                  team\n",
       "9794   parksch02   971000        1996          1995      Dallas Mavericks\n",
       "4697   gomesry01  4000000        2011          2010  Los Angeles Clippers\n",
       "848    barryjo01   650000        1994          1993       Milwaukee Bucks\n",
       "10548  redicjj01  7250000        2011          2010         Orlando Magic\n",
       "1406    boshch01  3348000        2006          2005       Toronto Raptors\n",
       "5221   harklma01  1731960        2013          2012         Orlando Magic\n",
       "2706   covinro01  1015696        2017          2016    Philadelphia 76ers"
      ]
     },
     "execution_count": 3657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.416300e+04</td>\n",
       "      <td>14163.00000</td>\n",
       "      <td>14163.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.164870e+06</td>\n",
       "      <td>2003.66942</td>\n",
       "      <td>2002.66942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.185046e+06</td>\n",
       "      <td>9.16469</td>\n",
       "      <td>9.16469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.706000e+03</td>\n",
       "      <td>1985.00000</td>\n",
       "      <td>1984.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.300000e+05</td>\n",
       "      <td>1996.00000</td>\n",
       "      <td>1995.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>2004.00000</td>\n",
       "      <td>2003.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.884239e+06</td>\n",
       "      <td>2012.00000</td>\n",
       "      <td>2011.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.468255e+07</td>\n",
       "      <td>2018.00000</td>\n",
       "      <td>2017.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary   season_end  season_start\n",
       "count  1.416300e+04  14163.00000   14163.00000\n",
       "mean   3.164870e+06   2003.66942    2002.66942\n",
       "std    4.185046e+06      9.16469       9.16469\n",
       "min    2.706000e+03   1985.00000    1984.00000\n",
       "25%    6.300000e+05   1996.00000    1995.00000\n",
       "50%    1.500000e+06   2004.00000    2003.00000\n",
       "75%    3.884239e+06   2012.00000    2011.00000\n",
       "max    3.468255e+07   2018.00000    2017.00000"
      ]
     },
     "execution_count": 3658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14163 entries, 0 to 14162\n",
      "Data columns (total 5 columns):\n",
      "player_id       14163 non-null object\n",
      "salary          14163 non-null int64\n",
      "season_end      14163 non-null int64\n",
      "season_start    14163 non-null int64\n",
      "team            14159 non-null object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 553.4+ KB\n"
     ]
    }
   ],
   "source": [
    "salaries_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === === === === === === === === === ===\n",
    "## Dataframe: Players\n",
    "\n",
    "Die Daten von https://data.world/datadavis/nba-salaries komplementieren den zuvor beschriebenen __Salaries__ Datensatz. Sie beinhalten im Wesentlichen __Informationen zu den jeweiligen Spielern__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>birthPlace</th>\n",
       "      <th>career_AST</th>\n",
       "      <th>career_FG%</th>\n",
       "      <th>career_FG3%</th>\n",
       "      <th>career_FT%</th>\n",
       "      <th>career_G</th>\n",
       "      <th>career_PER</th>\n",
       "      <th>career_PTS</th>\n",
       "      <th>career_TRB</th>\n",
       "      <th>career_WS</th>\n",
       "      <th>career_eFG%</th>\n",
       "      <th>college</th>\n",
       "      <th>draft_pick</th>\n",
       "      <th>draft_round</th>\n",
       "      <th>draft_team</th>\n",
       "      <th>draft_year</th>\n",
       "      <th>height</th>\n",
       "      <th>highSchool</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>oboyljo01</td>\n",
       "      <td>March 7, 1928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.4</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colorado State University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John O'Boyle</td>\n",
       "      <td>Shooting Guard</td>\n",
       "      <td>Right</td>\n",
       "      <td>185lb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id      birthDate birthPlace  career_AST career_FG% career_FG3%  \\\n",
       "3091  oboyljo01  March 7, 1928        NaN         1.0       30.8         NaN   \n",
       "\n",
       "     career_FT%  career_G career_PER  career_PTS career_TRB career_WS  \\\n",
       "3091       71.4         5        3.4         4.2        2.0       0.0   \n",
       "\n",
       "     career_eFG%                    college draft_pick draft_round draft_team  \\\n",
       "3091         NaN  Colorado State University        NaN         NaN        NaN   \n",
       "\n",
       "     draft_year height highSchool          name        position shoots weight  \n",
       "3091        NaN    6-2        NaN  John O'Boyle  Shooting Guard  Right  185lb  "
      ]
     },
     "execution_count": 3660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Profiling Report\n",
    "\n",
    "Der nachfolgende _Pandas Profiling Report_ verschafft einen vollständigen Überblick (Statistiken, Visualisierungen) über den importierten Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_profile_report = players_df.profile_report()\n",
    "# players_profile_report.to_file(output_file=\"players_profile_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse der einzelnen Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'birthDate', 'birthPlace', 'career_AST', 'career_FG%',\n",
       "       'career_FG3%', 'career_FT%', 'career_G', 'career_PER', 'career_PTS',\n",
       "       'career_TRB', 'career_WS', 'career_eFG%', 'college', 'draft_pick',\n",
       "       'draft_round', 'draft_team', 'draft_year', 'height', 'highSchool',\n",
       "       'name', 'position', 'shoots', 'weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ID\n",
    "\n",
    "Die Variable __id__ kann zunächst im Datensatz belassen werden. Mit dieser Variable kann nämlich später das Matching mit dem __Salaries__ Datensatz vollzogen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birth Date\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable __birthDate__ folgende Probleme auf:\n",
    "\n",
    "- Hohe Kardinalität\n",
    "- Uniform\n",
    "\n",
    "Außerdem hat die Variable __28__ fehlende Datenpunkte.\n",
    "\n",
    "Prinzipiell könnten die Features _birth_month_, _birth_day_ und _birth_year_ aus der genannten Variable entnommen werden. Dies scheint auf den ersten Blick jedoch keinen wirklichen Mehrwert zu bieten. Somit wird dieses Feature verworfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3663,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.drop(columns=['birthDate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birth Place\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable __birthPlace__ folgende Probleme auf:\n",
    "\n",
    "- Fehlende Datenpunkte || 10.7%\n",
    "- Hohe Kardinalität || 39%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fehlende Datenpunkte\n",
    "\n",
    "Die fehlenden Daten werden mit dem Top-Wert aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  4185\n",
       "unique                 1632\n",
       "top       Chicago, Illinois\n",
       "freq                    137\n",
       "Name: birthPlace, dtype: object"
      ]
     },
     "execution_count": 3664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['birthPlace'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3665,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['birthPlace'] = players_df['birthPlace'].fillna(\"Chicago, Illinois\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hohe Kardinalität\n",
    "\n",
    "Um dieses Problem zu lösen soll nur das Land in Betracht gezogen werden. Eine drastischere Maßnahme wäre die reine Verwendung des Features __born_in_usa__. Diese Variable wurde nur Aufschluss darüber geben, ob der Spieler in der USA geboren wurde oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  4685\n",
       "unique                 1632\n",
       "top       Chicago, Illinois\n",
       "freq                    637\n",
       "Name: birthPlace, dtype: object"
      ]
     },
     "execution_count": 3666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['birthPlace'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man oberhalb erkennen kann weißt das Feature 1632 einmalige Werte auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3667,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalizeBirthPlace(birthPlace):\n",
    "    splitted =  birthPlace.split(\",\")\n",
    "    \n",
    "    return splitted[1] if len(splitted) >= 2 else \",\".join(splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3668,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statesToUSA(birthPlace):\n",
    "    states = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "              \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "              \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "              \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "    \n",
    "    def process(string):\n",
    "        return string.lower().strip()\n",
    "        \n",
    "    states = map(process, states)\n",
    "    \n",
    "    return \"USA\" if process(birthPlace) in states else birthPlace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3669,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['birthPlace'] = players_df['birthPlace'].apply(generalizeBirthPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3670,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['birthPlace'] = players_df['birthPlace'].apply(statesToUSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3671,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.rename(columns={\"birthPlace\": \"birth_country\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216                      USA\n",
       "3615                      USA\n",
       "2337                      USA\n",
       "3800                      USA\n",
       "4584                      USA\n",
       "1616                      USA\n",
       "3450     District of Columbia\n",
       "Name: birth_country, dtype: object"
      ]
     },
     "execution_count": 3672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['birth_country'].sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4685\n",
       "unique      90\n",
       "top        USA\n",
       "freq      4160\n",
       "Name: birth_country, dtype: object"
      ]
     },
     "execution_count": 3673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['birth_country'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die reine Verwendung des Landes lassen sich 1632 einmalige Werte auf 90 reduzieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3674,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['born_in_usa'] = np.where(players_df['birth_country'] == 'USA', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4685\n",
       "unique       2\n",
       "top       True\n",
       "freq      4160\n",
       "Name: born_in_usa, dtype: object"
      ]
     },
     "execution_count": 3675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['born_in_usa'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Career Stats\n",
    "\n",
    "Alle Variablen die Statistiken zu der gesamten Karriere des Spielers beinhalten können verworfen werden. Diese Features würden keinen Mehrwert für das aktuelle Gehalt in dieser Saison bieten. Stattdessen sollen im weiteren Verlauf die jeweiligen Saisonstatistiken des Spielers durch einen weiteren Datensatz erweitert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3676,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.drop(columns=['career_AST', 'career_FG%', 'career_FG3%', 'career_FT%', 'career_G', 'career_PER', 'career_PTS', 'career_TRB', 'career_WS', 'career_eFG%'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### College\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable __college__ folgende Probleme auf:\n",
    "\n",
    "- Fehlende Datenpunkte || 6.7%\n",
    "- Hohe Kardinalität || 16.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fehlende Datenpunkte\n",
    "\n",
    "Das Problem der fehlenden Datenpunkte wird durch folgende Annahme behoben: Fehlende Datenpunkte repräsentieren Spieler, die kein College besucht haben. _LeBron James_ hat beispielsweise kein College eingetragen und auch tatsächlich kein College besucht. Deshalb wird der Wert _NO_COLLEGE_ bei diesen Spielern hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3677,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['college'] = players_df['college'].fillna('NO_COLLEGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3678,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           4685\n",
       "unique           732\n",
       "top       NO_COLLEGE\n",
       "freq             313\n",
       "Name: college, dtype: object"
      ]
     },
     "execution_count": 3678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['college'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hohe Kardinalität\n",
    "\n",
    "Das Problem der hohen Kardinalität scheint derzeit nicht lösbar zu sein. Eine drastische Maßnahme wäre ausschließlich das Feature __attended_college__ aufzunehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3679,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['attended_college'] = np.where(players_df['college'] == 'NO_COLLEGE', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4685\n",
       "unique       2\n",
       "top       True\n",
       "freq      4372\n",
       "Name: attended_college, dtype: object"
      ]
     },
     "execution_count": 3680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['attended_college'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draft\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißen die Features __draft_pick__, __draft_round__, __draft_team__, __draft_year__ folgende Probleme auf:\n",
    "\n",
    "- Hohe Kardinalität\n",
    "- Fehlende Datenpunkte\n",
    "\n",
    "Diese Probleme sollen durch die Extrahierung eines neuen Features __drafted_player__ behoben werden. Die ursprünglichen Features werden verworfen. Das neue Feature beruht auf der Annahme, dass es sich bei diesen Spielern um _undrafted players_ handelt. Da es diese Kategorie im Datensatz nicht gibt und diese Art von Spielern jedoch sehrwohl existieren wird in dieser Analyse von diesem Umstand ausgegangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3681,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['drafted_player'] = np.where(\n",
    "    players_df['draft_pick'].isna() |\n",
    "    players_df['draft_round'].isna() |\n",
    "    players_df['draft_team'].isna() |\n",
    "    players_df['draft_year'].isna(), True, False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4685\n",
       "unique        2\n",
       "top       False\n",
       "freq       3306\n",
       "Name: drafted_player, dtype: object"
      ]
     },
     "execution_count": 3682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['drafted_player'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die originalen Features werden nicht benötigt und können vom Datensatz entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3683,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.drop(columns=['draft_pick', 'draft_round', 'draft_team', 'draft_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Height\n",
    "\n",
    "Bei der Variable __height__ handelt es sich derzeit um kategorische Daten. Die Größe soll daher in eine numerische Repräsentation umgewandelt werden. Im originalen Datensatz handelt es sich um eine Foot-Inch Darstellung. Daher wird die Größe auf Inches umgerechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heightToInches(height):\n",
    "    foot_and_inches = height.split('-')\n",
    "    foot_in_inches = int(foot_and_inches[0]) * 12\n",
    "    inches = int(foot_and_inches[1])\n",
    "    \n",
    "    return foot_in_inches + inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4685\n",
       "unique      28\n",
       "top        6-7\n",
       "freq       486\n",
       "Name: height, dtype: object"
      ]
     },
     "execution_count": 3685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['height'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3686,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['height'] = players_df['height'].apply(heightToInches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3687,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.rename(columns={\"height\": \"height_in_inches\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2977    79\n",
       "4070    80\n",
       "2798    75\n",
       "1031    79\n",
       "582     74\n",
       "351     76\n",
       "1283    77\n",
       "Name: height_in_inches, dtype: int64"
      ]
     },
     "execution_count": 3688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['height_in_inches'].sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High School\n",
    "\n",
    "Die Variable __highSchool__ weißt Ähnlichkeiten mit dem Feature __college__ auf: \n",
    "\n",
    "- Hohe Kardinalität || 67.3%\n",
    "- Fehlende Datenpunkte || 14.1%\n",
    "\n",
    "Da dieses Feature eine wirkliche hohe Kardinalität besitzt soll ausschließlich das Feature __attended_high_school__ extrahiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                              4025\n",
       "unique                                             2708\n",
       "top       Oak Hill Academy in Mouth of Wilson, Virginia\n",
       "freq                                                 29\n",
       "Name: highSchool, dtype: object"
      ]
     },
     "execution_count": 3689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['highSchool'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3690,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['highSchool'] = players_df['highSchool'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3691,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.rename(columns={\"highSchool\": \"attended_high_school\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905    False\n",
       "32      False\n",
       "3503    False\n",
       "3060     True\n",
       "2874    False\n",
       "3030    False\n",
       "2784    False\n",
       "Name: attended_high_school, dtype: bool"
      ]
     },
     "execution_count": 3692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['attended_high_school'].sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable __name__ folgende Probleme auf:\n",
    "\n",
    "- Hohe Kardinalität || 99%\n",
    "- Uniform \n",
    "\n",
    "Möglicherweise könnte man __name_length__ aus dem genannten Feature extrahieren, jedoch besteht die Vermutung, dass der Name keinen großen Einfluss auf das Gehalt der Spieler hat. Deshalb soll das Feature aus dem Datensatz entfernt werden. Vorerst wird es jedoch beibehalten, da es später für ein Matching mit einem anderen Datensatz verwendet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable _position_ keine hohe Kardinalität auf. Dennoch wird versucht die möglichen Ausprägungen etwas einzuschränken. Spieler denen mehrer Positionen zugeordnet sind bekommen einen dementsprechenden Eintrag. Eine drastischere Vorgehensweise wäre die reine Verwendung des Features __multiple_positions__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processMultiplePositions(position):\n",
    "    return \"MULTIPLE_POSITIONS\" if \"and\" in position.split() else position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count               4685\n",
       "unique                43\n",
       "top       Shooting Guard\n",
       "freq                 679\n",
       "Name: position, dtype: object"
      ]
     },
     "execution_count": 3694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['position'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3695,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['position'] = players_df['position'].apply(processMultiplePositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   4685\n",
       "unique                    12\n",
       "top       MULTIPLE_POSITIONS\n",
       "freq                    1208\n",
       "Name: position, dtype: object"
      ]
     },
     "execution_count": 3696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['position'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2473         Small Forward\n",
       "3552                Center\n",
       "430         Shooting Guard\n",
       "3685           Point Guard\n",
       "1935    MULTIPLE_POSITIONS\n",
       "2179         Power Forward\n",
       "197          Power Forward\n",
       "Name: position, dtype: object"
      ]
     },
     "execution_count": 3697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['position'].sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3698,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['multiple_positions'] = np.where(players_df['position'] == \"MULTIPLE_POSITIONS\", True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4685\n",
       "unique        2\n",
       "top       False\n",
       "freq       3477\n",
       "Name: multiple_positions, dtype: object"
      ]
     },
     "execution_count": 3699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['multiple_positions'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shoots\n",
    "\n",
    "Die Variable __shoots__ kann vorerst ohne weitere Bearbeitung übernommen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ weißt die Variable __weight__ folgendes Problem auf:\n",
    "\n",
    "- Hohe Kardinalität || 3.1%\n",
    "\n",
    "Derzeit handelt es sich beim Gewicht um einen kategorischen Wert. Das Gewicht soll daher in eine numerische Repräsentation umgewandelt werden. Somit wird die Einheit wird entfernt und der Datentyp angepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fehlende Datenpunkte\n",
    "\n",
    "Laut dem _Pandas Profiling Report_ hat diese Variable __5__ fehlende Datenpunkte. Diese werden durch den Top-Wert aufgefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4680\n",
       "unique      143\n",
       "top       210lb\n",
       "freq        334\n",
       "Name: weight, dtype: object"
      ]
     },
     "execution_count": 3700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3701,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['weight'] = players_df['weight'].fillna('210lb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wertumwandlung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      4685\n",
       "unique      143\n",
       "top       210lb\n",
       "freq        339\n",
       "Name: weight, dtype: object"
      ]
     },
     "execution_count": 3702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLB(weight):\n",
    "    return weight[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3704,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['weight'] = players_df['weight'].apply(removeLB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3705,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df['weight'] = players_df['weight'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1445    200\n",
       "3040    200\n",
       "4070    220\n",
       "2555    200\n",
       "3686    255\n",
       "1158    200\n",
       "3689    225\n",
       "Name: weight, dtype: int64"
      ]
     },
     "execution_count": 3706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df['weight'].sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>multiple_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdelal01</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>Power Forward</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdulza01</td>\n",
       "      <td>USA</td>\n",
       "      <td>Iowa State University</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>Zaid Abdul-Aziz</td>\n",
       "      <td>MULTIPLE_POSITIONS</td>\n",
       "      <td>Right</td>\n",
       "      <td>235</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdulka01</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>Center</td>\n",
       "      <td>Right</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdulma02</td>\n",
       "      <td>USA</td>\n",
       "      <td>Louisiana State University</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>Mahmoud Abdul-Rauf</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>Right</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdulta01</td>\n",
       "      <td>France</td>\n",
       "      <td>University of Michigan, San Jose State University</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>Shooting Guard</td>\n",
       "      <td>Right</td>\n",
       "      <td>223</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id birth_country                                            college  \\\n",
       "0  abdelal01         Egypt                                    Duke University   \n",
       "1  abdulza01           USA                              Iowa State University   \n",
       "2  abdulka01           USA              University of California, Los Angeles   \n",
       "3  abdulma02           USA                         Louisiana State University   \n",
       "4  abdulta01        France  University of Michigan, San Jose State University   \n",
       "\n",
       "   height_in_inches  attended_high_school                 name  \\\n",
       "0                82                 False       Alaa Abdelnaby   \n",
       "1                81                 False      Zaid Abdul-Aziz   \n",
       "2                86                 False  Kareem Abdul-Jabbar   \n",
       "3                73                 False   Mahmoud Abdul-Rauf   \n",
       "4                78                 False    Tariq Abdul-Wahad   \n",
       "\n",
       "             position shoots  weight  born_in_usa  attended_college  \\\n",
       "0       Power Forward  Right     240        False              True   \n",
       "1  MULTIPLE_POSITIONS  Right     235         True              True   \n",
       "2              Center  Right     225         True              True   \n",
       "3         Point Guard  Right     162         True              True   \n",
       "4      Shooting Guard  Right     223        False              True   \n",
       "\n",
       "   drafted_player  multiple_positions  \n",
       "0           False               False  \n",
       "1           False                True  \n",
       "2           False               False  \n",
       "3           False               False  \n",
       "4           False               False  "
      ]
     },
     "execution_count": 3707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>multiple_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4680</th>\n",
       "      <td>zizican01</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>NO_COLLEGE</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "      <td>Ante Zizic</td>\n",
       "      <td>Center</td>\n",
       "      <td>Right</td>\n",
       "      <td>254</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>zoetji01</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Kent State University</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>Jim Zoet</td>\n",
       "      <td>Center</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>zopfbi01</td>\n",
       "      <td>USA</td>\n",
       "      <td>Duquesne University</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>Bill Zopf</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>Right</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>zubaciv01</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>NO_COLLEGE</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>Center</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>zunicma01</td>\n",
       "      <td>USA</td>\n",
       "      <td>George Washington University</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>Guard/Forward</td>\n",
       "      <td>Right</td>\n",
       "      <td>195</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id            birth_country                       college  \\\n",
       "4680  zizican01                  Croatia                    NO_COLLEGE   \n",
       "4681   zoetji01                   Canada         Kent State University   \n",
       "4682   zopfbi01                      USA           Duquesne University   \n",
       "4683  zubaciv01   Bosnia and Herzegovina                    NO_COLLEGE   \n",
       "4684  zunicma01                      USA  George Washington University   \n",
       "\n",
       "      height_in_inches  attended_high_school         name       position  \\\n",
       "4680                83                  True   Ante Zizic         Center   \n",
       "4681                85                 False     Jim Zoet         Center   \n",
       "4682                73                 False    Bill Zopf    Point Guard   \n",
       "4683                85                  True  Ivica Zubac         Center   \n",
       "4684                75                  True   Matt Zunic  Guard/Forward   \n",
       "\n",
       "     shoots  weight  born_in_usa  attended_college  drafted_player  \\\n",
       "4680  Right     254        False             False           False   \n",
       "4681  Right     240        False              True            True   \n",
       "4682  Right     170         True              True           False   \n",
       "4683  Right     240        False             False           False   \n",
       "4684  Right     195         True              True            True   \n",
       "\n",
       "      multiple_positions  \n",
       "4680               False  \n",
       "4681               False  \n",
       "4682               False  \n",
       "4683               False  \n",
       "4684               False  "
      ]
     },
     "execution_count": 3708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>name</th>\n",
       "      <th>position</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>multiple_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>floydsl01</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgetown University</td>\n",
       "      <td>75</td>\n",
       "      <td>False</td>\n",
       "      <td>Sleepy Floyd</td>\n",
       "      <td>MULTIPLE_POSITIONS</td>\n",
       "      <td>Right</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>kennedj01</td>\n",
       "      <td>USA</td>\n",
       "      <td>St. John's University</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>D.J. Kennedy</td>\n",
       "      <td>Small Forward</td>\n",
       "      <td>Left</td>\n",
       "      <td>215</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>armstbj01</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Iowa</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>B.J. Armstrong</td>\n",
       "      <td>Point Guard</td>\n",
       "      <td>Right</td>\n",
       "      <td>175</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>vanzade01</td>\n",
       "      <td>USA</td>\n",
       "      <td>Azusa Pacific University</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>Dennis Van Zant</td>\n",
       "      <td>Power Forward</td>\n",
       "      <td>Right</td>\n",
       "      <td>210</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>lopezfe01</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>St. John's University</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>Felipe Lopez</td>\n",
       "      <td>MULTIPLE_POSITIONS</td>\n",
       "      <td>Right</td>\n",
       "      <td>199</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>stoudsa01</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>Salim Stoudamire</td>\n",
       "      <td>MULTIPLE_POSITIONS</td>\n",
       "      <td>Left</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>derrima01</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Georgetown University</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>Marcus Derrickson</td>\n",
       "      <td>Power Forward</td>\n",
       "      <td>Right</td>\n",
       "      <td>249</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id          birth_country                   college  \\\n",
       "1303  floydsl01                    USA     Georgetown University   \n",
       "2241  kennedj01                    USA     St. John's University   \n",
       "129   armstbj01                    USA        University of Iowa   \n",
       "4244  vanzade01                    USA  Azusa Pacific University   \n",
       "2520  lopezfe01     Dominican Republic     St. John's University   \n",
       "3990  stoudsa01                    USA     University of Arizona   \n",
       "1016  derrima01   District of Columbia     Georgetown University   \n",
       "\n",
       "      height_in_inches  attended_high_school               name  \\\n",
       "1303                75                 False       Sleepy Floyd   \n",
       "2241                78                 False       D.J. Kennedy   \n",
       "129                 74                 False     B.J. Armstrong   \n",
       "4244                81                 False    Dennis Van Zant   \n",
       "2520                77                 False       Felipe Lopez   \n",
       "3990                73                 False   Salim Stoudamire   \n",
       "1016                79                 False  Marcus Derrickson   \n",
       "\n",
       "                position shoots  weight  born_in_usa  attended_college  \\\n",
       "1303  MULTIPLE_POSITIONS  Right     170         True              True   \n",
       "2241       Small Forward   Left     215         True              True   \n",
       "129          Point Guard  Right     175         True              True   \n",
       "4244       Power Forward  Right     210         True              True   \n",
       "2520  MULTIPLE_POSITIONS  Right     199        False              True   \n",
       "3990  MULTIPLE_POSITIONS   Left     179         True              True   \n",
       "1016       Power Forward  Right     249        False              True   \n",
       "\n",
       "      drafted_player  multiple_positions  \n",
       "1303           False                True  \n",
       "2241            True               False  \n",
       "129            False               False  \n",
       "4244           False               False  \n",
       "2520           False                True  \n",
       "3990           False                True  \n",
       "1016            True               False  "
      ]
     },
     "execution_count": 3709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4685.000000</td>\n",
       "      <td>4685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.032657</td>\n",
       "      <td>209.056564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.632334</td>\n",
       "      <td>26.125355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       height_in_inches       weight\n",
       "count       4685.000000  4685.000000\n",
       "mean          78.032657   209.056564\n",
       "std            3.632334    26.125355\n",
       "min           63.000000   114.000000\n",
       "25%           75.000000   190.000000\n",
       "50%           78.000000   210.000000\n",
       "75%           81.000000   225.000000\n",
       "max           91.000000   360.000000"
      ]
     },
     "execution_count": 3710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4685 entries, 0 to 4684\n",
      "Data columns (total 13 columns):\n",
      "_id                     4685 non-null object\n",
      "birth_country           4685 non-null object\n",
      "college                 4685 non-null object\n",
      "height_in_inches        4685 non-null int64\n",
      "attended_high_school    4685 non-null bool\n",
      "name                    4685 non-null object\n",
      "position                4685 non-null object\n",
      "shoots                  4684 non-null object\n",
      "weight                  4685 non-null int64\n",
      "born_in_usa             4685 non-null bool\n",
      "attended_college        4685 non-null bool\n",
      "drafted_player          4685 non-null bool\n",
      "multiple_positions      4685 non-null bool\n",
      "dtypes: bool(5), int64(2), object(6)\n",
      "memory usage: 315.8+ KB\n"
     ]
    }
   ],
   "source": [
    "players_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === === === === === === === === === ===\n",
    "## Dataframe: Seasons Stats\n",
    "\n",
    "Die Daten von https://www.kaggle.com/drgilermo/nba-players-stats sollen als Erweiterung des __Salaries__ Datensatz fungieren. Wie bereits erwähnt, sind die _Career Stats_ des __Players__ Datensatzes eher unbrauchbar. Es macht vermutlich mehr Sinn, dass jeweilige Gehalt in einer Saison durch die entsprechenden _seasons_stats_ zu erweitern. Dies soll durch diesen Datensatz ermöglicht werden. Er beinhaltet im Wesentlichen __Statistiken von einem Spieler in einer Saison__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>10259</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Travis Mays</td>\n",
       "      <td>PG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SAC</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2145.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.457</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>294.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>0.406</td>\n",
       "      <td>72.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>222.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.456</td>\n",
       "      <td>255.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>54.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>915.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    Year       Player Pos   Age   Tm     G    GS      MP  \\\n",
       "10259       10259  1991.0  Travis Mays  PG  22.0  SAC  64.0  55.0  2145.0   \n",
       "\n",
       "        PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  \\\n",
       "10259  12.3  0.526  0.272  0.457   2.8   6.7   4.7  18.3   1.9   0.3  15.5   \n",
       "\n",
       "       USG%  blanl  OWS  DWS   WS  WS/48  blank2  OBPM  DBPM  BPM  VORP  \\\n",
       "10259  21.0    NaN  0.8  1.3  2.1  0.047     NaN  -0.1  -1.4 -1.5   0.2   \n",
       "\n",
       "          FG    FGA    FG%    3P    3PA    3P%     2P    2PA    2P%   eFG%  \\\n",
       "10259  294.0  724.0  0.406  72.0  197.0  0.365  222.0  527.0  0.421  0.456   \n",
       "\n",
       "          FT    FTA   FT%   ORB    DRB    TRB    AST   STL   BLK    TOV  \\\n",
       "10259  255.0  331.0  0.77  54.0  124.0  178.0  253.0  81.0  11.0  159.0   \n",
       "\n",
       "          PF    PTS  \n",
       "10259  169.0  915.0  "
      ]
     },
     "execution_count": 3712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse der einzelnen Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Player', 'Pos', 'Age', 'Tm', 'G', 'GS', 'MP',\n",
       "       'PER', 'TS%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%',\n",
       "       'BLK%', 'TOV%', 'USG%', 'blanl', 'OWS', 'DWS', 'WS', 'WS/48', 'blank2',\n",
       "       'OBPM', 'DBPM', 'BPM', 'VORP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',\n",
       "       '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB',\n",
       "       'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unnamed\n",
    "\n",
    "Die erste Variable __unnamed__ scheint einen Index darzustellen. Sie kann ohne weitere Bedenken entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3714,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_stats_df.drop(seasons_stats_df.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year und Player\n",
    "\n",
    "Die Variablen __year__ und __player__ sollen für das Matching mit den anderen Datensätzen verwendet werden. Die Variable __year__ kann mit __season_end__ des __Salaries__ Datensatzes verbunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position\n",
    "\n",
    "Dieser Datensatz beinhaltet ebenfalls eine Variable __Pos__ (Position). Diese kennzeichnet jedoch die Position in dieser Saison. Daher wird dieses feature und nicht das Feature des anderen Datensatzes verwendet. Die erstellten Features des anderen Datensatzes können somit zunächst verworfen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     24624\n",
       "unique       23\n",
       "top          PF\n",
       "freq       4966\n",
       "Name: Pos, dtype: object"
      ]
     },
     "execution_count": 3715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df['Pos'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3716,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df.drop(columns=['position', 'multiple_positions'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "\n",
    "Das Alter des jeweiligen Spielers scheint auf jeden Fall Sinn zu machen. Daher wird dieses Feature behalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24616.000000\n",
       "mean        26.664405\n",
       "std          3.841892\n",
       "min         18.000000\n",
       "25%         24.000000\n",
       "50%         26.000000\n",
       "75%         29.000000\n",
       "max         44.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 3717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df['Age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saisonstatistiken\n",
    "\n",
    "Alle Saisonstatistiken des Spielers sollen natürlich behalten werden. Der Datensatz soll genau diese Erweiterung an Daten liefern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Curly Armstrong</td>\n",
       "      <td>G-F</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FTW</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.279</td>\n",
       "      <td>170.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Cliff Barker</td>\n",
       "      <td>SG</td>\n",
       "      <td>29.0</td>\n",
       "      <td>INO</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.372</td>\n",
       "      <td>75.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Leo Barnhorst</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.349</td>\n",
       "      <td>90.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.256</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DNN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year           Player  Pos   Age   Tm     G  GS  MP  PER    TS%  3PAr  \\\n",
       "0  1950.0  Curly Armstrong  G-F  31.0  FTW  63.0 NaN NaN  NaN  0.368   NaN   \n",
       "1  1950.0     Cliff Barker   SG  29.0  INO  49.0 NaN NaN  NaN  0.435   NaN   \n",
       "2  1950.0    Leo Barnhorst   SF  25.0  CHS  67.0 NaN NaN  NaN  0.394   NaN   \n",
       "3  1950.0       Ed Bartels    F  24.0  TOT  15.0 NaN NaN  NaN  0.312   NaN   \n",
       "4  1950.0       Ed Bartels    F  24.0  DNN  13.0 NaN NaN  NaN  0.308   NaN   \n",
       "\n",
       "     FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  USG%  blanl  OWS  DWS  \\\n",
       "0  0.467   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.1  3.6   \n",
       "1  0.387   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  1.6  0.6   \n",
       "2  0.259   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  0.9  2.8   \n",
       "3  0.395   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.5 -0.1   \n",
       "4  0.378   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.5 -0.1   \n",
       "\n",
       "    WS  WS/48  blank2  OBPM  DBPM  BPM  VORP     FG    FGA    FG%  3P  3PA  \\\n",
       "0  3.5    NaN     NaN   NaN   NaN  NaN   NaN  144.0  516.0  0.279 NaN  NaN   \n",
       "1  2.2    NaN     NaN   NaN   NaN  NaN   NaN  102.0  274.0  0.372 NaN  NaN   \n",
       "2  3.6    NaN     NaN   NaN   NaN  NaN   NaN  174.0  499.0  0.349 NaN  NaN   \n",
       "3 -0.6    NaN     NaN   NaN   NaN  NaN   NaN   22.0   86.0  0.256 NaN  NaN   \n",
       "4 -0.6    NaN     NaN   NaN   NaN  NaN   NaN   21.0   82.0  0.256 NaN  NaN   \n",
       "\n",
       "   3P%     2P    2PA    2P%   eFG%     FT    FTA    FT%  ORB  DRB  TRB    AST  \\\n",
       "0  NaN  144.0  516.0  0.279  0.279  170.0  241.0  0.705  NaN  NaN  NaN  176.0   \n",
       "1  NaN  102.0  274.0  0.372  0.372   75.0  106.0  0.708  NaN  NaN  NaN  109.0   \n",
       "2  NaN  174.0  499.0  0.349  0.349   90.0  129.0  0.698  NaN  NaN  NaN  140.0   \n",
       "3  NaN   22.0   86.0  0.256  0.256   19.0   34.0  0.559  NaN  NaN  NaN   20.0   \n",
       "4  NaN   21.0   82.0  0.256  0.256   17.0   31.0  0.548  NaN  NaN  NaN   20.0   \n",
       "\n",
       "   STL  BLK  TOV     PF    PTS  \n",
       "0  NaN  NaN  NaN  217.0  458.0  \n",
       "1  NaN  NaN  NaN   99.0  279.0  \n",
       "2  NaN  NaN  NaN  192.0  438.0  \n",
       "3  NaN  NaN  NaN   29.0   63.0  \n",
       "4  NaN  NaN  NaN   27.0   59.0  "
      ]
     },
     "execution_count": 3718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24686</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>PF</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CHO</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.442</td>\n",
       "      <td>8.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>253.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>253.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.571</td>\n",
       "      <td>133.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>135.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24687</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Tyler Zeller</td>\n",
       "      <td>C</td>\n",
       "      <td>27.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.247</td>\n",
       "      <td>9.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>10.2</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.494</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.564</td>\n",
       "      <td>43.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24688</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Stephen Zimmerman</td>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>10.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.323</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24689</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Paul Zipser</td>\n",
       "      <td>SF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.181</td>\n",
       "      <td>1.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>33.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>55.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.473</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24690</th>\n",
       "      <td>2017.0</td>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>C</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.206</td>\n",
       "      <td>7.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.653</td>\n",
       "      <td>41.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year             Player Pos   Age   Tm     G    GS      MP   PER  \\\n",
       "24686  2017.0        Cody Zeller  PF  24.0  CHO  62.0  58.0  1725.0  16.7   \n",
       "24687  2017.0       Tyler Zeller   C  27.0  BOS  51.0   5.0   525.0  13.0   \n",
       "24688  2017.0  Stephen Zimmerman   C  20.0  ORL  19.0   0.0   108.0   7.3   \n",
       "24689  2017.0        Paul Zipser  SF  22.0  CHI  44.0  18.0   843.0   6.9   \n",
       "24690  2017.0        Ivica Zubac   C  19.0  LAL  38.0  11.0   609.0  17.0   \n",
       "\n",
       "         TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  USG%  \\\n",
       "24686  0.604  0.002  0.442   8.6  17.3  12.9   9.1   1.8   3.0  10.9  15.5   \n",
       "24687  0.508  0.006  0.247   9.2  17.0  13.2  12.2   0.7   3.3  10.2  16.5   \n",
       "24688  0.346  0.000  0.161  10.8  24.9  17.6   5.3   0.9   3.7   8.3  14.8   \n",
       "24689  0.503  0.448  0.181   1.9  14.2   8.0   6.1   0.9   1.5  14.4  14.4   \n",
       "24690  0.547  0.013  0.206   7.1  21.9  14.3   8.1   1.1   4.4  10.4  20.3   \n",
       "\n",
       "       blanl  OWS  DWS   WS  WS/48  blank2  OBPM  DBPM  BPM  VORP     FG  \\\n",
       "24686    NaN  3.4  2.2  5.6  0.157     NaN  -0.2   2.3  2.1   1.8  253.0   \n",
       "24687    NaN  0.5  0.6  1.0  0.094     NaN  -3.2   0.8 -2.5  -0.1   78.0   \n",
       "24688    NaN -0.1  0.1  0.0 -0.005     NaN  -7.8   0.4 -7.3  -0.1   10.0   \n",
       "24689    NaN -0.3  0.8  0.5  0.030     NaN  -3.6  -0.1 -3.7  -0.4   88.0   \n",
       "24690    NaN  0.6  0.5  1.1  0.086     NaN  -2.7   0.3 -2.5  -0.1  126.0   \n",
       "\n",
       "         FGA    FG%    3P   3PA    3P%     2P    2PA    2P%   eFG%     FT  \\\n",
       "24686  443.0  0.571   0.0   1.0  0.000  253.0  442.0  0.572  0.571  133.0   \n",
       "24687  158.0  0.494   0.0   1.0  0.000   78.0  157.0  0.497  0.494   22.0   \n",
       "24688   31.0  0.323   0.0   0.0    NaN   10.0   31.0  0.323  0.323    3.0   \n",
       "24689  221.0  0.398  33.0  99.0  0.333   55.0  122.0  0.451  0.473   31.0   \n",
       "24690  238.0  0.529   0.0   3.0  0.000  126.0  235.0  0.536  0.529   32.0   \n",
       "\n",
       "         FTA    FT%    ORB    DRB    TRB   AST   STL   BLK   TOV     PF    PTS  \n",
       "24686  196.0  0.679  135.0  270.0  405.0  99.0  62.0  58.0  65.0  189.0  639.0  \n",
       "24687   39.0  0.564   43.0   81.0  124.0  42.0   7.0  21.0  20.0   61.0  178.0  \n",
       "24688    5.0  0.600   11.0   24.0   35.0   4.0   2.0   5.0   3.0   17.0   23.0  \n",
       "24689   40.0  0.775   15.0  110.0  125.0  36.0  15.0  16.0  40.0   78.0  240.0  \n",
       "24690   49.0  0.653   41.0  118.0  159.0  30.0  14.0  33.0  30.0   66.0  284.0  "
      ]
     },
     "execution_count": 3719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18862</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>Antonio Daniels</td>\n",
       "      <td>PG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14.3</td>\n",
       "      <td>13.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>205.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>0.459</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>188.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.478</td>\n",
       "      <td>170.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.776</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>Nenad Krstic</td>\n",
       "      <td>PF</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NJN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.447</td>\n",
       "      <td>9.7</td>\n",
       "      <td>14.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>281.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>281.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.493</td>\n",
       "      <td>185.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>161.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21004</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>Garret Siler</td>\n",
       "      <td>C</td>\n",
       "      <td>24.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>18.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.548</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>1982.0</td>\n",
       "      <td>Paul Mokeski</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.326</td>\n",
       "      <td>7.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>84.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.435</td>\n",
       "      <td>48.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>59.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12355</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>Mitchell Butler</td>\n",
       "      <td>SG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>WSB</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>858.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.362</td>\n",
       "      <td>4.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.384</td>\n",
       "      <td>13.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.217</td>\n",
       "      <td>75.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.413</td>\n",
       "      <td>48.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.578</td>\n",
       "      <td>29.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>Dick Mehen</td>\n",
       "      <td>PF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.361</td>\n",
       "      <td>90.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17094</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>Gilbert Arenas</td>\n",
       "      <td>PG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.420</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>22.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>27.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>656.0</td>\n",
       "      <td>1523.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>205.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>451.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.498</td>\n",
       "      <td>521.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.814</td>\n",
       "      <td>83.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>2038.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year           Player Pos   Age   Tm     G    GS      MP   PER  \\\n",
       "18862  2008.0  Antonio Daniels  PG  32.0  WAS  71.0  63.0  2161.0  13.7   \n",
       "17377  2005.0     Nenad Krstic  PF  21.0  NJN  75.0  57.0  1965.0  13.4   \n",
       "21004  2011.0     Garret Siler   C  24.0  PHO  21.0   0.0   101.0  13.5   \n",
       "6691   1982.0     Paul Mokeski   C  25.0  TOT  67.0   4.0   868.0   8.7   \n",
       "12355  1996.0  Mitchell Butler  SG  25.0  WSB  61.0   3.0   858.0   7.4   \n",
       "423    1951.0       Dick Mehen  PF  28.0  TOT  66.0   NaN     NaN   NaN   \n",
       "17094  2005.0   Gilbert Arenas  PG  23.0  WAS  80.0  80.0  3274.0  21.3   \n",
       "\n",
       "         TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  USG%  \\\n",
       "18862  0.549  0.166  0.490   1.2  10.0   5.5  24.0   1.7   0.1  14.3  13.5   \n",
       "17377  0.547  0.004  0.447   9.7  14.9  12.3   7.1   0.9   2.6  14.1  19.0   \n",
       "21004  0.553  0.000  0.710  18.3  13.7  16.0   4.7   0.5   2.9  19.7  22.6   \n",
       "6691   0.489  0.016  0.326   7.2  19.9  13.3   5.1   1.8   2.6  19.9  12.7   \n",
       "12355  0.446  0.262  0.362   4.1  12.0   8.1  11.1   2.4   1.0  20.1  17.3   \n",
       "423    0.404    NaN  0.231   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "17094  0.565  0.369  0.420   2.8  10.5   6.5  22.9   2.2   0.5  11.8  27.3   \n",
       "\n",
       "       blanl  OWS  DWS    WS  WS/48  blank2  OBPM  DBPM  BPM  VORP     FG  \\\n",
       "18862    NaN  3.5  1.0   4.5  0.099     NaN   0.0  -1.2 -1.2   0.4  205.0   \n",
       "17377    NaN  1.9  2.5   4.4  0.108     NaN  -2.1   0.5 -1.6   0.2  281.0   \n",
       "21004    NaN  0.1  0.1   0.1  0.054     NaN  -2.4  -1.8 -4.2  -0.1   17.0   \n",
       "6691     NaN -0.2  1.0   0.8  0.045     NaN  -4.2   1.4 -2.8  -0.2   84.0   \n",
       "12355    NaN -1.2  1.0  -0.2 -0.010     NaN  -4.2   0.5 -3.7  -0.4   88.0   \n",
       "423      NaN  0.5  1.5   1.9    NaN     NaN   NaN   NaN  NaN   NaN  192.0   \n",
       "17094    NaN  9.2  2.3  11.5  0.169     NaN   5.5  -1.5  4.0   4.9  656.0   \n",
       "\n",
       "          FGA    FG%     3P    3PA    3P%     2P    2PA    2P%   eFG%     FT  \\\n",
       "18862   447.0  0.459   17.0   74.0  0.230  188.0  373.0  0.504  0.478  170.0   \n",
       "17377   570.0  0.493    0.0    2.0  0.000  281.0  568.0  0.495  0.493  185.0   \n",
       "21004    31.0  0.548    0.0    0.0    NaN   17.0   31.0  0.548  0.548   11.0   \n",
       "6691    193.0  0.435    0.0    3.0  0.000   84.0  190.0  0.442  0.435   48.0   \n",
       "12355   229.0  0.384   13.0   60.0  0.217   75.0  169.0  0.444  0.413   48.0   \n",
       "423     532.0  0.361    NaN    NaN    NaN  192.0  532.0  0.361  0.361   90.0   \n",
       "17094  1523.0  0.431  205.0  562.0  0.365  451.0  961.0  0.469  0.498  521.0   \n",
       "\n",
       "         FTA    FT%    ORB    DRB    TRB    AST    STL   BLK    TOV     PF  \\\n",
       "18862  219.0  0.776   23.0  180.0  203.0  340.0   69.0   2.0   91.0   78.0   \n",
       "17377  255.0  0.725  161.0  240.0  401.0   77.0   32.0  63.0  112.0  280.0   \n",
       "21004   22.0  0.500   16.0   12.0   28.0    3.0    1.0   4.0   10.0   20.0   \n",
       "6691    63.0  0.762   59.0  149.0  208.0   35.0   33.0  40.0   55.0  171.0   \n",
       "12355   83.0  0.578   29.0   89.0  118.0   67.0   41.0  12.0   67.0  104.0   \n",
       "423    123.0  0.732    NaN    NaN  223.0  118.0    NaN   NaN    NaN  149.0   \n",
       "17094  640.0  0.814   83.0  295.0  378.0  411.0  139.0  23.0  242.0  245.0   \n",
       "\n",
       "          PTS  \n",
       "18862   597.0  \n",
       "17377   747.0  \n",
       "21004    45.0  \n",
       "6691    216.0  \n",
       "12355   237.0  \n",
       "423     474.0  \n",
       "17094  2038.0  "
      ]
     },
     "execution_count": 3720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24616.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>18233.000000</td>\n",
       "      <td>24138.000000</td>\n",
       "      <td>24101.000000</td>\n",
       "      <td>24538.000000</td>\n",
       "      <td>18839.000000</td>\n",
       "      <td>24525.000000</td>\n",
       "      <td>20792.000000</td>\n",
       "      <td>20792.000000</td>\n",
       "      <td>21571.000000</td>\n",
       "      <td>22555.000000</td>\n",
       "      <td>20792.000000</td>\n",
       "      <td>20792.000000</td>\n",
       "      <td>19582.000000</td>\n",
       "      <td>19640.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24585.000000</td>\n",
       "      <td>24585.000000</td>\n",
       "      <td>24585.000000</td>\n",
       "      <td>24101.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24525.000000</td>\n",
       "      <td>18927.000000</td>\n",
       "      <td>18927.000000</td>\n",
       "      <td>15416.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24496.000000</td>\n",
       "      <td>24525.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>23766.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>24312.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>20797.000000</td>\n",
       "      <td>19645.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "      <td>24624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1992.594989</td>\n",
       "      <td>26.664405</td>\n",
       "      <td>50.837110</td>\n",
       "      <td>23.593375</td>\n",
       "      <td>1209.720317</td>\n",
       "      <td>12.479071</td>\n",
       "      <td>0.493001</td>\n",
       "      <td>0.158604</td>\n",
       "      <td>0.325455</td>\n",
       "      <td>6.181565</td>\n",
       "      <td>13.708657</td>\n",
       "      <td>9.949210</td>\n",
       "      <td>13.009962</td>\n",
       "      <td>1.648269</td>\n",
       "      <td>1.410624</td>\n",
       "      <td>15.085099</td>\n",
       "      <td>18.906492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.257307</td>\n",
       "      <td>1.227395</td>\n",
       "      <td>2.485796</td>\n",
       "      <td>0.065002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.778386</td>\n",
       "      <td>-0.548570</td>\n",
       "      <td>-2.326720</td>\n",
       "      <td>0.559879</td>\n",
       "      <td>195.325820</td>\n",
       "      <td>430.645752</td>\n",
       "      <td>0.430817</td>\n",
       "      <td>22.215037</td>\n",
       "      <td>63.604480</td>\n",
       "      <td>0.248796</td>\n",
       "      <td>178.250447</td>\n",
       "      <td>381.756782</td>\n",
       "      <td>0.445343</td>\n",
       "      <td>0.450658</td>\n",
       "      <td>102.389336</td>\n",
       "      <td>136.775219</td>\n",
       "      <td>0.719279</td>\n",
       "      <td>62.189210</td>\n",
       "      <td>147.199404</td>\n",
       "      <td>224.637381</td>\n",
       "      <td>114.852623</td>\n",
       "      <td>39.897052</td>\n",
       "      <td>24.470260</td>\n",
       "      <td>73.939832</td>\n",
       "      <td>116.339222</td>\n",
       "      <td>510.116350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.429594</td>\n",
       "      <td>3.841892</td>\n",
       "      <td>26.496161</td>\n",
       "      <td>28.632387</td>\n",
       "      <td>941.146575</td>\n",
       "      <td>6.039014</td>\n",
       "      <td>0.094469</td>\n",
       "      <td>0.187495</td>\n",
       "      <td>0.218971</td>\n",
       "      <td>4.872685</td>\n",
       "      <td>6.636402</td>\n",
       "      <td>5.040283</td>\n",
       "      <td>9.191843</td>\n",
       "      <td>1.017024</td>\n",
       "      <td>1.773348</td>\n",
       "      <td>6.919170</td>\n",
       "      <td>5.448157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.136256</td>\n",
       "      <td>1.269613</td>\n",
       "      <td>3.058638</td>\n",
       "      <td>0.102471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.792947</td>\n",
       "      <td>2.253106</td>\n",
       "      <td>4.691619</td>\n",
       "      <td>1.336892</td>\n",
       "      <td>188.114361</td>\n",
       "      <td>397.624715</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>38.543366</td>\n",
       "      <td>102.442769</td>\n",
       "      <td>0.176683</td>\n",
       "      <td>179.478923</td>\n",
       "      <td>371.260335</td>\n",
       "      <td>0.099803</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>113.373565</td>\n",
       "      <td>146.078918</td>\n",
       "      <td>0.141824</td>\n",
       "      <td>67.324881</td>\n",
       "      <td>145.921912</td>\n",
       "      <td>228.190203</td>\n",
       "      <td>135.863913</td>\n",
       "      <td>38.713053</td>\n",
       "      <td>36.935084</td>\n",
       "      <td>67.713803</td>\n",
       "      <td>84.791873</td>\n",
       "      <td>492.922981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1950.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.100000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>-2.519000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.800000</td>\n",
       "      <td>-30.400000</td>\n",
       "      <td>-86.700000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1981.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>-1.700000</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.657000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1996.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1053.000000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.743000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1971.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>579.250000</td>\n",
       "      <td>0.496000</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>3882.000000</td>\n",
       "      <td>129.100000</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.200000</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.400000</td>\n",
       "      <td>2.123000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.800000</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>1597.000000</td>\n",
       "      <td>3159.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "      <td>3159.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>1111.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>4029.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year           Age             G            GS            MP  \\\n",
       "count  24624.000000  24616.000000  24624.000000  18233.000000  24138.000000   \n",
       "mean    1992.594989     26.664405     50.837110     23.593375   1209.720317   \n",
       "std       17.429594      3.841892     26.496161     28.632387    941.146575   \n",
       "min     1950.000000     18.000000      1.000000      0.000000      0.000000   \n",
       "25%     1981.000000     24.000000     27.000000      0.000000    340.000000   \n",
       "50%     1996.000000     26.000000     58.000000      8.000000   1053.000000   \n",
       "75%     2007.000000     29.000000     75.000000     45.000000   1971.000000   \n",
       "max     2017.000000     44.000000     88.000000     83.000000   3882.000000   \n",
       "\n",
       "                PER           TS%          3PAr           FTr          ORB%  \\\n",
       "count  24101.000000  24538.000000  18839.000000  24525.000000  20792.000000   \n",
       "mean      12.479071      0.493001      0.158604      0.325455      6.181565   \n",
       "std        6.039014      0.094469      0.187495      0.218971      4.872685   \n",
       "min      -90.600000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        9.800000      0.458000      0.005000      0.208000      2.600000   \n",
       "50%       12.700000      0.506000      0.064000      0.296000      5.400000   \n",
       "75%       15.600000      0.544000      0.288000      0.400000      9.000000   \n",
       "max      129.100000      1.136000      1.000000      6.000000    100.000000   \n",
       "\n",
       "               DRB%          TRB%          AST%          STL%          BLK%  \\\n",
       "count  20792.000000  21571.000000  22555.000000  20792.000000  20792.000000   \n",
       "mean      13.708657      9.949210     13.009962      1.648269      1.410624   \n",
       "std        6.636402      5.040283      9.191843      1.017024      1.773348   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        8.800000      5.900000      6.500000      1.100000      0.300000   \n",
       "50%       12.700000      9.200000     10.500000      1.500000      0.900000   \n",
       "75%       18.100000     13.500000     17.600000      2.100000      1.900000   \n",
       "max      100.000000    100.000000    100.000000     24.200000     77.800000   \n",
       "\n",
       "               TOV%          USG%  blanl           OWS           DWS  \\\n",
       "count  19582.000000  19640.000000    0.0  24585.000000  24585.000000   \n",
       "mean      15.085099     18.906492    NaN      1.257307      1.227395   \n",
       "std        6.919170      5.448157    NaN      2.136256      1.269613   \n",
       "min        0.000000      0.000000    NaN     -5.100000     -1.000000   \n",
       "25%       11.400000     15.400000    NaN     -0.100000      0.200000   \n",
       "50%       14.200000     18.600000    NaN      0.400000      0.800000   \n",
       "75%       17.700000     22.200000    NaN      1.900000      1.800000   \n",
       "max      100.000000    100.000000    NaN     18.300000     16.000000   \n",
       "\n",
       "                 WS         WS/48  blank2          OBPM          DBPM  \\\n",
       "count  24585.000000  24101.000000     0.0  20797.000000  20797.000000   \n",
       "mean       2.485796      0.065002     NaN     -1.778386     -0.548570   \n",
       "std        3.058638      0.102471     NaN      3.792947      2.253106   \n",
       "min       -2.800000     -2.519000     NaN    -73.800000    -30.400000   \n",
       "25%        0.200000      0.031000     NaN     -3.400000     -1.700000   \n",
       "50%        1.400000      0.075000     NaN     -1.500000     -0.500000   \n",
       "75%        3.800000      0.115000     NaN      0.300000      0.700000   \n",
       "max       25.400000      2.123000     NaN     47.800000     46.800000   \n",
       "\n",
       "                BPM          VORP            FG           FGA           FG%  \\\n",
       "count  20797.000000  20797.000000  24624.000000  24624.000000  24525.000000   \n",
       "mean      -2.326720      0.559879    195.325820    430.645752      0.430817   \n",
       "std        4.691619      1.336892    188.114361    397.624715      0.095921   \n",
       "min      -86.700000     -2.600000      0.000000      0.000000      0.000000   \n",
       "25%       -4.200000     -0.200000     41.000000     99.000000      0.393000   \n",
       "50%       -1.800000      0.000000    141.000000    321.000000      0.439000   \n",
       "75%        0.300000      0.900000    299.000000    661.000000      0.480000   \n",
       "max       36.200000     12.400000   1597.000000   3159.000000      1.000000   \n",
       "\n",
       "                 3P           3PA           3P%            2P           2PA  \\\n",
       "count  18927.000000  18927.000000  15416.000000  24624.000000  24624.000000   \n",
       "mean      22.215037     63.604480      0.248796    178.250447    381.756782   \n",
       "std       38.543366    102.442769      0.176683    179.478923    371.260335   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      1.000000      0.100000     35.000000     82.000000   \n",
       "50%        2.000000     11.000000      0.292000    122.000000    270.000000   \n",
       "75%       27.000000     84.000000      0.363000    268.000000    579.250000   \n",
       "max      402.000000    886.000000      1.000000   1597.000000   3159.000000   \n",
       "\n",
       "                2P%          eFG%            FT           FTA           FT%  \\\n",
       "count  24496.000000  24525.000000  24624.000000  24624.000000  23766.000000   \n",
       "mean       0.445343      0.450658    102.389336    136.775219      0.719279   \n",
       "std        0.099803      0.099200    113.373565    146.078918      0.141824   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.407000      0.414000     18.000000     27.000000      0.657000   \n",
       "50%        0.456000      0.463000     63.000000     88.000000      0.743000   \n",
       "75%        0.496000      0.501000    149.000000    201.000000      0.808000   \n",
       "max        1.000000      1.500000    840.000000   1363.000000      1.000000   \n",
       "\n",
       "                ORB           DRB           TRB           AST           STL  \\\n",
       "count  20797.000000  20797.000000  24312.000000  24624.000000  20797.000000   \n",
       "mean      62.189210    147.199404    224.637381    114.852623     39.897052   \n",
       "std       67.324881    145.921912    228.190203    135.863913     38.713053   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       12.000000     33.000000     51.000000     19.000000      9.000000   \n",
       "50%       38.000000    106.000000    159.000000     68.000000     29.000000   \n",
       "75%       91.000000    212.000000    322.000000    160.000000     60.000000   \n",
       "max      587.000000   1111.000000   2149.000000   1164.000000    301.000000   \n",
       "\n",
       "                BLK           TOV            PF           PTS  \n",
       "count  20797.000000  19645.000000  24624.000000  24624.000000  \n",
       "mean      24.470260     73.939832    116.339222    510.116350  \n",
       "std       36.935084     67.713803     84.791873    492.922981  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        3.000000     18.000000     39.000000    106.000000  \n",
       "50%       11.000000     55.000000    109.000000    364.000000  \n",
       "75%       29.000000    112.000000    182.000000    778.000000  \n",
       "max      456.000000    464.000000    386.000000   4029.000000  "
      ]
     },
     "execution_count": 3721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24691 entries, 0 to 24690\n",
      "Data columns (total 52 columns):\n",
      "Year      24624 non-null float64\n",
      "Player    24624 non-null object\n",
      "Pos       24624 non-null object\n",
      "Age       24616 non-null float64\n",
      "Tm        24624 non-null object\n",
      "G         24624 non-null float64\n",
      "GS        18233 non-null float64\n",
      "MP        24138 non-null float64\n",
      "PER       24101 non-null float64\n",
      "TS%       24538 non-null float64\n",
      "3PAr      18839 non-null float64\n",
      "FTr       24525 non-null float64\n",
      "ORB%      20792 non-null float64\n",
      "DRB%      20792 non-null float64\n",
      "TRB%      21571 non-null float64\n",
      "AST%      22555 non-null float64\n",
      "STL%      20792 non-null float64\n",
      "BLK%      20792 non-null float64\n",
      "TOV%      19582 non-null float64\n",
      "USG%      19640 non-null float64\n",
      "blanl     0 non-null float64\n",
      "OWS       24585 non-null float64\n",
      "DWS       24585 non-null float64\n",
      "WS        24585 non-null float64\n",
      "WS/48     24101 non-null float64\n",
      "blank2    0 non-null float64\n",
      "OBPM      20797 non-null float64\n",
      "DBPM      20797 non-null float64\n",
      "BPM       20797 non-null float64\n",
      "VORP      20797 non-null float64\n",
      "FG        24624 non-null float64\n",
      "FGA       24624 non-null float64\n",
      "FG%       24525 non-null float64\n",
      "3P        18927 non-null float64\n",
      "3PA       18927 non-null float64\n",
      "3P%       15416 non-null float64\n",
      "2P        24624 non-null float64\n",
      "2PA       24624 non-null float64\n",
      "2P%       24496 non-null float64\n",
      "eFG%      24525 non-null float64\n",
      "FT        24624 non-null float64\n",
      "FTA       24624 non-null float64\n",
      "FT%       23766 non-null float64\n",
      "ORB       20797 non-null float64\n",
      "DRB       20797 non-null float64\n",
      "TRB       24312 non-null float64\n",
      "AST       24624 non-null float64\n",
      "STL       20797 non-null float64\n",
      "BLK       20797 non-null float64\n",
      "TOV       19645 non-null float64\n",
      "PF        24624 non-null float64\n",
      "PTS       24624 non-null float64\n",
      "dtypes: float64(49), object(3)\n",
      "memory usage: 9.8+ MB\n"
     ]
    }
   ],
   "source": [
    "seasons_stats_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## === === === === === === === === === ===\n",
    "## Matching Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasons Stats weiter aufräumen\n",
    "\n",
    "Es gibt anscheinend Spieler, die innerhalb einer Saison bei mehreren Vereinen gespielt haben. In diesem Fall wird nur der letzte Aufenthalt des Spielers (der letzte Eintrag) berücksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.256</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DNN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1950.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>WSC</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.247</td>\n",
       "      <td>24.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year      Player Pos   Age   Tm     G  GS  MP  PER    TS%  3PAr    FTr  \\\n",
       "3    1950.0  Ed Bartels   F  24.0  TOT  15.0 NaN NaN  NaN  0.312   NaN  0.395   \n",
       "4    1950.0  Ed Bartels   F  24.0  DNN  13.0 NaN NaN  NaN  0.308   NaN  0.378   \n",
       "5    1950.0  Ed Bartels   F  24.0  NYK   2.0 NaN NaN  NaN  0.376   NaN  0.750   \n",
       "317  1951.0  Ed Bartels   F  25.0  WSC  17.0 NaN NaN  NaN  0.307   NaN  0.474   \n",
       "\n",
       "     ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  USG%  blanl  OWS  DWS   WS  \\\n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.5 -0.1 -0.6   \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.5 -0.1 -0.6   \n",
       "5     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  0.0  0.0  0.0   \n",
       "317   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN -0.8  0.2 -0.5   \n",
       "\n",
       "     WS/48  blank2  OBPM  DBPM  BPM  VORP    FG   FGA    FG%  3P  3PA  3P%  \\\n",
       "3      NaN     NaN   NaN   NaN  NaN   NaN  22.0  86.0  0.256 NaN  NaN  NaN   \n",
       "4      NaN     NaN   NaN   NaN  NaN   NaN  21.0  82.0  0.256 NaN  NaN  NaN   \n",
       "5      NaN     NaN   NaN   NaN  NaN   NaN   1.0   4.0  0.250 NaN  NaN  NaN   \n",
       "317    NaN     NaN   NaN   NaN  NaN   NaN  24.0  97.0  0.247 NaN  NaN  NaN   \n",
       "\n",
       "       2P   2PA    2P%   eFG%    FT   FTA    FT%  ORB  DRB   TRB   AST  STL  \\\n",
       "3    22.0  86.0  0.256  0.256  19.0  34.0  0.559  NaN  NaN   NaN  20.0  NaN   \n",
       "4    21.0  82.0  0.256  0.256  17.0  31.0  0.548  NaN  NaN   NaN  20.0  NaN   \n",
       "5     1.0   4.0  0.250  0.250   2.0   3.0  0.667  NaN  NaN   NaN   0.0  NaN   \n",
       "317  24.0  97.0  0.247  0.247  24.0  46.0  0.522  NaN  NaN  84.0  12.0  NaN   \n",
       "\n",
       "     BLK  TOV    PF   PTS  \n",
       "3    NaN  NaN  29.0  63.0  \n",
       "4    NaN  NaN  27.0  59.0  \n",
       "5    NaN  NaN   2.0   4.0  \n",
       "317  NaN  NaN  54.0  72.0  "
      ]
     },
     "execution_count": 3723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_stats_df.loc[seasons_stats_df['Player'] == \"Ed Bartels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3724,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_indices = seasons_stats_df[seasons_stats_df.duplicated(['Player', 'Year'], keep='last')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3725,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_stats_df.drop(duplicated_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erweiterung durch Spielerdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3726,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(salaries_df, players_df, left_on='player_id', right_on='_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3727,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['_id', 'player_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>name</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>885120</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>Chase Budinger</td>\n",
       "      <td>Right</td>\n",
       "      <td>209</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11131</th>\n",
       "      <td>1070000</td>\n",
       "      <td>2004</td>\n",
       "      <td>2003</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>USA</td>\n",
       "      <td>California State University, Long Beach</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>Bryon Russell</td>\n",
       "      <td>Right</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13240</th>\n",
       "      <td>17531250</td>\n",
       "      <td>2005</td>\n",
       "      <td>2004</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>Chris Webber</td>\n",
       "      <td>Right</td>\n",
       "      <td>245</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14154</th>\n",
       "      <td>603000</td>\n",
       "      <td>1996</td>\n",
       "      <td>1995</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>George Zidek</td>\n",
       "      <td>Right</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>4500000</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of North Carolina</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>Brendan Haywood</td>\n",
       "      <td>Right</td>\n",
       "      <td>268</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10811</th>\n",
       "      <td>1000000</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>New Jersey Nets</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>Bernard Robinson</td>\n",
       "      <td>Left</td>\n",
       "      <td>210</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>6000000</td>\n",
       "      <td>2009</td>\n",
       "      <td>2008</td>\n",
       "      <td>Utah Jazz</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia Institute of Technology</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>Matt Harpring</td>\n",
       "      <td>Right</td>\n",
       "      <td>231</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         salary  season_end  season_start                    team  \\\n",
       "1834     885120        2013          2012  Minnesota Timberwolves   \n",
       "11131   1070000        2004          2003      Los Angeles Lakers   \n",
       "13240  17531250        2005          2004        Sacramento Kings   \n",
       "14154    603000        1996          1995       Charlotte Hornets   \n",
       "5497    4500000        2007          2006      Washington Wizards   \n",
       "10811   1000000        2007          2006         New Jersey Nets   \n",
       "5268    6000000        2009          2008               Utah Jazz   \n",
       "\n",
       "               birth_country                                  college  \\\n",
       "1834                     USA                    University of Arizona   \n",
       "11131                    USA  California State University, Long Beach   \n",
       "13240                    USA                   University of Michigan   \n",
       "14154         Czech Republic    University of California, Los Angeles   \n",
       "5497                     USA             University of North Carolina   \n",
       "10811   District of Columbia                   University of Michigan   \n",
       "5268                     USA          Georgia Institute of Technology   \n",
       "\n",
       "       height_in_inches  attended_high_school              name shoots  \\\n",
       "1834                 79                 False    Chase Budinger  Right   \n",
       "11131                79                 False     Bryon Russell  Right   \n",
       "13240                81                 False      Chris Webber  Right   \n",
       "14154                84                 False      George Zidek  Right   \n",
       "5497                 84                 False   Brendan Haywood  Right   \n",
       "10811                78                 False  Bernard Robinson   Left   \n",
       "5268                 79                 False     Matt Harpring  Right   \n",
       "\n",
       "       weight  born_in_usa  attended_college  drafted_player  \n",
       "1834      209         True              True           False  \n",
       "11131     225         True              True           False  \n",
       "13240     245         True              True           False  \n",
       "14154     250        False              True           False  \n",
       "5497      268         True              True           False  \n",
       "10811     210        False              True           False  \n",
       "5268      231         True              True           False  "
      ]
     },
     "execution_count": 3728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erweiterung durch Saisonstatistiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3729,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, seasons_stats_df, left_on=['name', 'season_end'], right_on=['Player', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3730,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['name', 'Player', 'Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>395000</td>\n",
       "      <td>1991</td>\n",
       "      <td>1990</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>POR</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379</td>\n",
       "      <td>10.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.474</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.568</td>\n",
       "      <td>27.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494000</td>\n",
       "      <td>1992</td>\n",
       "      <td>1991</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>POR</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>9.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.493</td>\n",
       "      <td>76.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>81.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>1993</td>\n",
       "      <td>1992</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>24.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>11.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>219.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>114.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>805000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>8.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.436</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>650000</td>\n",
       "      <td>1995</td>\n",
       "      <td>1994</td>\n",
       "      <td>Sacramento Kings</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary  season_end  season_start                    team birth_country  \\\n",
       "0  395000        1991          1990  Portland Trail Blazers         Egypt   \n",
       "1  494000        1992          1991  Portland Trail Blazers         Egypt   \n",
       "2  500000        1993          1992          Boston Celtics         Egypt   \n",
       "3  805000        1994          1993          Boston Celtics         Egypt   \n",
       "4  650000        1995          1994        Sacramento Kings         Egypt   \n",
       "\n",
       "           college  height_in_inches  attended_high_school shoots  weight  \\\n",
       "0  Duke University                82                 False  Right     240   \n",
       "1  Duke University                82                 False  Right     240   \n",
       "2  Duke University                82                 False  Right     240   \n",
       "3  Duke University                82                 False  Right     240   \n",
       "4  Duke University                82                 False  Right     240   \n",
       "\n",
       "   born_in_usa  attended_college  drafted_player Pos   Age   Tm     G    GS  \\\n",
       "0        False              True           False  PF  22.0  POR  43.0   0.0   \n",
       "1        False              True           False  PF  23.0  POR  71.0   1.0   \n",
       "2        False              True           False  PF  24.0  BOS  63.0  52.0   \n",
       "3        False              True           False  PF  25.0  BOS  13.0   0.0   \n",
       "4        False              True           False  PF  26.0  PHI   3.0   0.0   \n",
       "\n",
       "       MP   PER    TS%  3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  \\\n",
       "0   290.0  13.1  0.499   0.0  0.379  10.4  23.4  17.0   5.8   0.7   2.5  14.0   \n",
       "1   934.0  13.5  0.533   0.0  0.280   9.5  20.9  15.2   4.7   1.3   1.1  14.0   \n",
       "2  1152.0  13.4  0.557   0.0  0.240  11.3  18.1  14.8   2.2   0.8   1.2  15.4   \n",
       "3   159.0   9.2  0.485   0.0  0.455   8.5  24.2  16.3   2.7   0.6   1.2  20.5   \n",
       "4    30.0 -12.5  0.091   0.0  0.000  11.6  19.6  15.5   0.0   0.0   0.0  31.3   \n",
       "\n",
       "   USG%  blanl  OWS  DWS   WS  WS/48  blank2  OBPM  DBPM   BPM  VORP     FG  \\\n",
       "0  22.1    NaN  0.0  0.5  0.5  0.079     NaN  -4.2  -0.7  -5.0  -0.2   55.0   \n",
       "1  20.6    NaN  0.6  1.5  2.1  0.110     NaN  -3.0  -0.9  -3.9  -0.5  178.0   \n",
       "2  20.5    NaN  0.7  1.2  1.9  0.079     NaN  -2.1  -2.1  -4.1  -0.6  219.0   \n",
       "3  22.6    NaN -0.2  0.1 -0.1 -0.032     NaN  -7.1  -3.1 -10.2  -0.3   24.0   \n",
       "4  23.8    NaN -0.3  0.0 -0.3 -0.466     NaN -21.1  -6.9 -28.0  -0.2    1.0   \n",
       "\n",
       "     FGA    FG%   3P  3PA  3P%     2P    2PA    2P%   eFG%    FT    FTA  \\\n",
       "0  116.0  0.474  0.0  0.0  NaN   55.0  116.0  0.474  0.474  25.0   44.0   \n",
       "1  361.0  0.493  0.0  0.0  NaN  178.0  361.0  0.493  0.493  76.0  101.0   \n",
       "2  417.0  0.525  0.0  0.0  NaN  219.0  417.0  0.525  0.525  76.0  100.0   \n",
       "3   55.0  0.436  0.0  0.0  NaN   24.0   55.0  0.436  0.436  16.0   25.0   \n",
       "4   11.0  0.091  0.0  0.0  NaN    1.0   11.0  0.091  0.091   0.0    0.0   \n",
       "\n",
       "     FT%    ORB    DRB    TRB   AST   STL   BLK   TOV     PF    PTS  \n",
       "0  0.568   27.0   62.0   89.0  12.0   4.0  12.0  22.0   39.0  135.0  \n",
       "1  0.752   81.0  179.0  260.0  30.0  25.0  16.0  66.0  132.0  432.0  \n",
       "2  0.760  114.0  186.0  300.0  17.0  19.0  22.0  84.0  165.0  514.0  \n",
       "3  0.640   12.0   34.0   46.0   3.0   2.0   3.0  17.0   20.0   64.0  \n",
       "4    NaN    3.0    5.0    8.0   0.0   0.0   0.0   5.0    2.0    2.0  "
      ]
     },
     "execution_count": 3731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12228</th>\n",
       "      <td>694000</td>\n",
       "      <td>1997</td>\n",
       "      <td>1996</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.485</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12229</th>\n",
       "      <td>784200</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997</td>\n",
       "      <td>Denver Nuggets</td>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>University of California, Los Angeles</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>950000</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Nevada, Las Vegas</td>\n",
       "      <td>84</td>\n",
       "      <td>False</td>\n",
       "      <td>Left</td>\n",
       "      <td>240</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>10.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.323</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12231</th>\n",
       "      <td>750000</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NO_COLLEGE</td>\n",
       "      <td>80</td>\n",
       "      <td>True</td>\n",
       "      <td>Right</td>\n",
       "      <td>215</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>SF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.181</td>\n",
       "      <td>1.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>33.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>55.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.473</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12232</th>\n",
       "      <td>1034956</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>NO_COLLEGE</td>\n",
       "      <td>85</td>\n",
       "      <td>True</td>\n",
       "      <td>Right</td>\n",
       "      <td>240</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.206</td>\n",
       "      <td>7.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.653</td>\n",
       "      <td>41.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary  season_end  season_start                team  \\\n",
       "12228   694000        1997          1996   Charlotte Hornets   \n",
       "12229   784200        1998          1997      Denver Nuggets   \n",
       "12230   950000        2017          2016       Orlando Magic   \n",
       "12231   750000        2017          2016       Chicago Bulls   \n",
       "12232  1034956        2017          2016  Los Angeles Lakers   \n",
       "\n",
       "                 birth_country                                college  \\\n",
       "12228           Czech Republic  University of California, Los Angeles   \n",
       "12229           Czech Republic  University of California, Los Angeles   \n",
       "12230                      USA        University of Nevada, Las Vegas   \n",
       "12231                  Germany                             NO_COLLEGE   \n",
       "12232   Bosnia and Herzegovina                             NO_COLLEGE   \n",
       "\n",
       "       height_in_inches  attended_high_school shoots  weight  born_in_usa  \\\n",
       "12228                84                 False  Right     250        False   \n",
       "12229                84                 False  Right     250        False   \n",
       "12230                84                 False   Left     240         True   \n",
       "12231                80                  True  Right     215        False   \n",
       "12232                85                  True  Right     240        False   \n",
       "\n",
       "       attended_college  drafted_player Pos   Age   Tm     G    GS     MP  \\\n",
       "12228              True           False   C  23.0  DEN  16.0   0.0   88.0   \n",
       "12229              True           False   C  24.0  SEA   6.0   0.0   22.0   \n",
       "12230              True           False   C  20.0  ORL  19.0   0.0  108.0   \n",
       "12231             False           False  SF  22.0  CHI  44.0  18.0  843.0   \n",
       "12232             False           False   C  19.0  LAL  38.0  11.0  609.0   \n",
       "\n",
       "        PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  TOV%  \\\n",
       "12228  20.3  0.591  0.000  0.758  13.1  16.6  14.9  10.3   0.6   0.0   8.3   \n",
       "12229   2.3  0.349  0.143  0.286   0.0  21.3  10.9   7.1   0.0   0.0   6.0   \n",
       "12230   7.3  0.346  0.000  0.161  10.8  24.9  17.6   5.3   0.9   3.7   8.3   \n",
       "12231   6.9  0.503  0.448  0.181   1.9  14.2   8.0   6.1   0.9   1.5  14.4   \n",
       "12232  17.0  0.547  0.013  0.206   7.1  21.9  14.3   8.1   1.1   4.4  10.4   \n",
       "\n",
       "       USG%  blanl  OWS  DWS   WS  WS/48  blank2  OBPM  DBPM   BPM  VORP  \\\n",
       "12228  24.4    NaN  0.3  0.0  0.4  0.200     NaN   1.6  -3.9  -2.3   0.0   \n",
       "12229  35.3    NaN -0.1  0.0 -0.1 -0.120     NaN -11.6  -7.3 -18.9  -0.1   \n",
       "12230  14.8    NaN -0.1  0.1  0.0 -0.005     NaN  -7.8   0.4  -7.3  -0.1   \n",
       "12231  14.4    NaN -0.3  0.8  0.5  0.030     NaN  -3.6  -0.1  -3.7  -0.4   \n",
       "12232  20.3    NaN  0.6  0.5  1.1  0.086     NaN  -2.7   0.3  -2.5  -0.1   \n",
       "\n",
       "          FG    FGA    FG%    3P   3PA    3P%     2P    2PA    2P%   eFG%  \\\n",
       "12228   16.0   33.0  0.485   0.0   0.0    NaN   16.0   33.0  0.485  0.485   \n",
       "12229    3.0   14.0  0.214   1.0   2.0  0.500    2.0   12.0  0.167  0.250   \n",
       "12230   10.0   31.0  0.323   0.0   0.0    NaN   10.0   31.0  0.323  0.323   \n",
       "12231   88.0  221.0  0.398  33.0  99.0  0.333   55.0  122.0  0.451  0.473   \n",
       "12232  126.0  238.0  0.529   0.0   3.0  0.000  126.0  235.0  0.536  0.529   \n",
       "\n",
       "         FT   FTA    FT%   ORB    DRB    TRB   AST   STL   BLK   TOV    PF  \\\n",
       "12228  20.0  25.0  0.800  10.0   13.0   23.0   5.0   1.0   0.0   4.0  17.0   \n",
       "12229   4.0   4.0  1.000   0.0    4.0    4.0   1.0   0.0   0.0   1.0   5.0   \n",
       "12230   3.0   5.0  0.600  11.0   24.0   35.0   4.0   2.0   5.0   3.0  17.0   \n",
       "12231  31.0  40.0  0.775  15.0  110.0  125.0  36.0  15.0  16.0  40.0  78.0   \n",
       "12232  32.0  49.0  0.653  41.0  118.0  159.0  30.0  14.0  33.0  30.0  66.0   \n",
       "\n",
       "         PTS  \n",
       "12228   52.0  \n",
       "12229   11.0  \n",
       "12230   23.0  \n",
       "12231  240.0  \n",
       "12232  284.0  "
      ]
     },
     "execution_count": 3732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>team</th>\n",
       "      <th>birth_country</th>\n",
       "      <th>college</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>attended_high_school</th>\n",
       "      <th>shoots</th>\n",
       "      <th>weight</th>\n",
       "      <th>born_in_usa</th>\n",
       "      <th>attended_college</th>\n",
       "      <th>drafted_player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>15937500</td>\n",
       "      <td>2004</td>\n",
       "      <td>2003</td>\n",
       "      <td>New York Knicks</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Tennessee</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>200</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NYK</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1799.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.220</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.6</td>\n",
       "      <td>24.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>340.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>87.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>253.0</td>\n",
       "      <td>579.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.491</td>\n",
       "      <td>157.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.913</td>\n",
       "      <td>20.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6871</th>\n",
       "      <td>2038000</td>\n",
       "      <td>1996</td>\n",
       "      <td>1995</td>\n",
       "      <td>Detroit Pistons</td>\n",
       "      <td>USA</td>\n",
       "      <td>Temple University</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>185</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.164</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.433</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.485</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.818</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>5000000</td>\n",
       "      <td>2013</td>\n",
       "      <td>2012</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Connecticut</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>185</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SG</td>\n",
       "      <td>34.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.162</td>\n",
       "      <td>1.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>16.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.308</td>\n",
       "      <td>188.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.446</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>16.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>Houston Rockets</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Alabama</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>220</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>SF</td>\n",
       "      <td>23.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.224</td>\n",
       "      <td>6.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>322.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>0.459</td>\n",
       "      <td>44.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.324</td>\n",
       "      <td>278.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.490</td>\n",
       "      <td>115.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>128.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>412718</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>Miami Heat</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Miami</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>Left</td>\n",
       "      <td>184</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.200</td>\n",
       "      <td>3.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.217</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.358</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>810000</td>\n",
       "      <td>2007</td>\n",
       "      <td>2006</td>\n",
       "      <td>Phoenix Suns</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "      <td>Left</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.200</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.400</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.615</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>5200000</td>\n",
       "      <td>2008</td>\n",
       "      <td>2007</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>USA</td>\n",
       "      <td>University of Maryland</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>Right</td>\n",
       "      <td>225</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.406</td>\n",
       "      <td>10.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "      <td>45.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.652</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         salary  season_end  season_start                 team birth_country  \\\n",
       "5204   15937500        2004          2003      New York Knicks           USA   \n",
       "6871    2038000        1996          1995      Detroit Pistons           USA   \n",
       "4549    5000000        2013          2012        Chicago Bulls           USA   \n",
       "5167    1200000        1994          1993      Houston Rockets           USA   \n",
       "5072     412718        2007          2006           Miami Heat           USA   \n",
       "1684     810000        2007          2006         Phoenix Suns       Ireland   \n",
       "10105   5200000        2008          2007  Cleveland Cavaliers           USA   \n",
       "\n",
       "                         college  height_in_inches  attended_high_school  \\\n",
       "5204     University of Tennessee                78                 False   \n",
       "6871           Temple University                77                 False   \n",
       "4549   University of Connecticut                78                 False   \n",
       "5167       University of Alabama                81                 False   \n",
       "5072         University of Miami                74                 False   \n",
       "1684           Auburn University                83                 False   \n",
       "10105     University of Maryland                82                 False   \n",
       "\n",
       "      shoots  weight  born_in_usa  attended_college  drafted_player Pos   Age  \\\n",
       "5204   Right     200         True              True           False  SG  32.0   \n",
       "6871   Right     185         True              True           False  PG  26.0   \n",
       "4549   Right     185         True              True           False  SG  34.0   \n",
       "5167   Right     220         True              True           False  SF  23.0   \n",
       "5072    Left     184         True              True            True  SG  23.0   \n",
       "1684    Left     250        False              True            True   C  33.0   \n",
       "10105  Right     225         True              True           False  PF  32.0   \n",
       "\n",
       "        Tm     G    GS      MP   PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  \\\n",
       "5204   NYK  50.0  50.0  1799.0  14.8  0.539  0.259  0.220   1.3   6.4   3.9   \n",
       "6871   DET  23.0   0.0   287.0   9.5  0.515  0.224  0.164   4.4   4.9   4.6   \n",
       "4549   CHI  50.0  45.0  1088.0  10.6  0.481  0.109  0.162   1.7   7.2   4.4   \n",
       "5167   HOU  81.0  81.0  2370.0  14.2  0.521  0.194  0.224   6.4  13.9  10.3   \n",
       "5072   MIA  12.0   0.0   136.0   7.4  0.391  0.383  0.200   3.6  10.2   6.9   \n",
       "1684   PHO  23.0   0.0   164.0   9.3  0.424  0.338  0.200   9.0  23.7  16.7   \n",
       "10105  CLE  27.0   1.0   580.0  14.9  0.547  0.012  0.406  10.5  16.4  13.4   \n",
       "\n",
       "       AST%  STL%  BLK%  TOV%  USG%  blanl  OWS  DWS   WS  WS/48  blank2  \\\n",
       "5204   10.3   1.1   0.1  10.6  24.7    NaN  2.5  0.6  3.1  0.083     NaN   \n",
       "6871    9.2   2.9   0.0  11.1  13.4    NaN  0.2  0.4  0.5  0.092     NaN   \n",
       "4549   19.9   1.2   0.3  14.2  25.0    NaN -0.6  0.9  0.4  0.016     NaN   \n",
       "5167   14.5   2.5   2.0  15.1  17.0    NaN  1.6  4.3  5.9  0.120     NaN   \n",
       "5072    9.9   1.2   1.2   8.4  24.8    NaN -0.3  0.1 -0.2 -0.055     NaN   \n",
       "1684    4.3   0.9   0.9   9.0  21.3    NaN -0.1  0.2  0.1  0.015     NaN   \n",
       "10105   5.6   0.8   2.2   9.9  17.4    NaN  0.9  0.6  1.5  0.128     NaN   \n",
       "\n",
       "       OBPM  DBPM  BPM  VORP     FG    FGA    FG%    3P    3PA    3P%     2P  \\\n",
       "5204    1.3  -2.7 -1.4   0.3  340.0  781.0  0.435  87.0  202.0  0.431  253.0   \n",
       "6871   -1.5   0.3 -1.3   0.1   29.0   67.0  0.433   7.0   15.0  0.467   22.0   \n",
       "4549   -3.1  -2.4 -5.5  -1.0  204.0  475.0  0.429  16.0   52.0  0.308  188.0   \n",
       "5167   -0.6   3.1  2.5   2.7  322.0  702.0  0.459  44.0  136.0  0.324  278.0   \n",
       "5072   -4.9  -2.9 -7.9  -0.2   19.0   60.0  0.317   5.0   23.0  0.217   14.0   \n",
       "1684   -4.6  -2.3 -6.9  -0.2   23.0   65.0  0.354   6.0   22.0  0.273   17.0   \n",
       "10105  -1.7  -0.5 -2.1   0.0   87.0  170.0  0.512   0.0    2.0  0.000   87.0   \n",
       "\n",
       "         2PA    2P%   eFG%     FT    FTA    FT%    ORB    DRB    TRB    AST  \\\n",
       "5204   579.0  0.437  0.491  157.0  172.0  0.913   20.0  101.0  121.0   99.0   \n",
       "6871    52.0  0.423  0.485    9.0   11.0  0.818   10.0   12.0   22.0   16.0   \n",
       "4549   423.0  0.444  0.446   66.0   77.0  0.857   16.0   67.0   83.0  119.0   \n",
       "5167   566.0  0.491  0.490  115.0  157.0  0.732  128.0  312.0  440.0  231.0   \n",
       "5072    37.0  0.378  0.358    8.0   12.0  0.667    4.0   12.0   16.0    8.0   \n",
       "1684    43.0  0.395  0.400    8.0   13.0  0.615   12.0   35.0   47.0    5.0   \n",
       "10105  168.0  0.518  0.512   45.0   69.0  0.652   55.0   81.0  136.0   19.0   \n",
       "\n",
       "         STL   BLK    TOV     PF    PTS  \n",
       "5204    38.0   2.0  102.0  105.0  924.0  \n",
       "6871    15.0   0.0    9.0   34.0   74.0  \n",
       "4549    24.0   5.0   84.0   93.0  490.0  \n",
       "5167   119.0  75.0  137.0  186.0  803.0  \n",
       "5072     3.0   2.0    6.0    8.0   51.0  \n",
       "1684     3.0   2.0    7.0   19.0   60.0  \n",
       "10105    9.0  16.0   22.0   73.0  219.0  "
      ]
     },
     "execution_count": 3733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>blanl</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>blank2</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.223300e+04</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12194.000000</td>\n",
       "      <td>12190.000000</td>\n",
       "      <td>12190.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>12201.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12230.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12190.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>10299.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12170.000000</td>\n",
       "      <td>12190.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>11874.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.00000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.031394e+06</td>\n",
       "      <td>2003.357884</td>\n",
       "      <td>2002.357884</td>\n",
       "      <td>79.030410</td>\n",
       "      <td>217.824001</td>\n",
       "      <td>26.835200</td>\n",
       "      <td>52.998856</td>\n",
       "      <td>25.674569</td>\n",
       "      <td>1250.241968</td>\n",
       "      <td>12.748005</td>\n",
       "      <td>0.509993</td>\n",
       "      <td>0.181456</td>\n",
       "      <td>0.313901</td>\n",
       "      <td>6.075307</td>\n",
       "      <td>13.993156</td>\n",
       "      <td>10.035119</td>\n",
       "      <td>13.009992</td>\n",
       "      <td>1.633827</td>\n",
       "      <td>1.513083</td>\n",
       "      <td>14.484821</td>\n",
       "      <td>18.761390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.335151</td>\n",
       "      <td>1.264236</td>\n",
       "      <td>2.599722</td>\n",
       "      <td>0.073276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.519186</td>\n",
       "      <td>-0.421025</td>\n",
       "      <td>-1.939990</td>\n",
       "      <td>0.599681</td>\n",
       "      <td>193.312679</td>\n",
       "      <td>422.900924</td>\n",
       "      <td>0.440695</td>\n",
       "      <td>27.813946</td>\n",
       "      <td>78.608273</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>165.498733</td>\n",
       "      <td>344.292651</td>\n",
       "      <td>0.461290</td>\n",
       "      <td>0.471028</td>\n",
       "      <td>96.447642</td>\n",
       "      <td>127.966157</td>\n",
       "      <td>0.724607</td>\n",
       "      <td>62.749203</td>\n",
       "      <td>155.114363</td>\n",
       "      <td>217.863566</td>\n",
       "      <td>115.144609</td>\n",
       "      <td>40.730565</td>\n",
       "      <td>25.356004</td>\n",
       "      <td>74.43399</td>\n",
       "      <td>114.182130</td>\n",
       "      <td>510.886945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.922321e+06</td>\n",
       "      <td>8.841971</td>\n",
       "      <td>8.841971</td>\n",
       "      <td>3.679179</td>\n",
       "      <td>27.400892</td>\n",
       "      <td>4.091276</td>\n",
       "      <td>25.389561</td>\n",
       "      <td>29.195356</td>\n",
       "      <td>909.889058</td>\n",
       "      <td>5.611190</td>\n",
       "      <td>0.086252</td>\n",
       "      <td>0.194209</td>\n",
       "      <td>0.221890</td>\n",
       "      <td>4.535725</td>\n",
       "      <td>6.298117</td>\n",
       "      <td>4.852060</td>\n",
       "      <td>9.446561</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>1.647488</td>\n",
       "      <td>6.149822</td>\n",
       "      <td>5.212992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.992772</td>\n",
       "      <td>1.195955</td>\n",
       "      <td>2.882877</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.483871</td>\n",
       "      <td>2.085438</td>\n",
       "      <td>4.245327</td>\n",
       "      <td>1.314281</td>\n",
       "      <td>172.340900</td>\n",
       "      <td>367.296754</td>\n",
       "      <td>0.089236</td>\n",
       "      <td>42.852526</td>\n",
       "      <td>113.235908</td>\n",
       "      <td>0.169878</td>\n",
       "      <td>155.173812</td>\n",
       "      <td>313.580979</td>\n",
       "      <td>0.092562</td>\n",
       "      <td>0.090847</td>\n",
       "      <td>102.786317</td>\n",
       "      <td>130.386830</td>\n",
       "      <td>0.140343</td>\n",
       "      <td>64.354985</td>\n",
       "      <td>139.585459</td>\n",
       "      <td>197.581579</td>\n",
       "      <td>136.371164</td>\n",
       "      <td>36.603116</td>\n",
       "      <td>34.689186</td>\n",
       "      <td>63.50923</td>\n",
       "      <td>77.476732</td>\n",
       "      <td>461.198190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.853000e+03</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>-2.519000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.800000</td>\n",
       "      <td>-19.500000</td>\n",
       "      <td>-86.700000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.124350e+05</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-3.700000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.450000e+06</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1137.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.283000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>390.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.765000e+06</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.387750</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.096345e+07</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3533.000000</td>\n",
       "      <td>88.300000</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>1.084000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>978.000000</td>\n",
       "      <td>2173.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>916.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>894.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>464.00000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>2832.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary    season_end  season_start  height_in_inches  \\\n",
       "count  1.223300e+04  12233.000000  12233.000000      12233.000000   \n",
       "mean   3.031394e+06   2003.357884   2002.357884         79.030410   \n",
       "std    3.922321e+06      8.841971      8.841971          3.679179   \n",
       "min    2.853000e+03   1985.000000   1984.000000         63.000000   \n",
       "25%    6.124350e+05   1996.000000   1995.000000         76.000000   \n",
       "50%    1.450000e+06   2004.000000   2003.000000         80.000000   \n",
       "75%    3.765000e+06   2011.000000   2010.000000         82.000000   \n",
       "max    3.096345e+07   2017.000000   2016.000000         91.000000   \n",
       "\n",
       "             weight           Age             G            GS            MP  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean     217.824001     26.835200     52.998856     25.674569   1250.241968   \n",
       "std       27.400892      4.091276     25.389561     29.195356    909.889058   \n",
       "min      133.000000     18.000000      1.000000      0.000000      0.000000   \n",
       "25%      195.000000     24.000000     31.000000      1.000000    423.000000   \n",
       "50%      220.000000     26.000000     60.000000     11.000000   1137.000000   \n",
       "75%      237.000000     30.000000     76.000000     51.000000   1991.000000   \n",
       "max      360.000000     42.000000     82.000000     82.000000   3533.000000   \n",
       "\n",
       "                PER           TS%          3PAr           FTr          ORB%  \\\n",
       "count  12230.000000  12194.000000  12190.000000  12190.000000  12230.000000   \n",
       "mean      12.748005      0.509993      0.181456      0.313901      6.075307   \n",
       "std        5.611190      0.086252      0.194209      0.221890      4.535725   \n",
       "min      -90.600000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       10.100000      0.479000      0.007000      0.196000      2.500000   \n",
       "50%       12.900000      0.520000      0.111000      0.283000      5.100000   \n",
       "75%       15.700000      0.554000      0.323000      0.387750      9.000000   \n",
       "max       88.300000      1.136000      1.000000      6.000000    100.000000   \n",
       "\n",
       "               DRB%          TRB%          AST%          STL%          BLK%  \\\n",
       "count  12230.000000  12230.000000  12230.000000  12230.000000  12230.000000   \n",
       "mean      13.993156     10.035119     13.009992      1.633827      1.513083   \n",
       "std        6.298117      4.852060      9.446561      0.935333      1.647488   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        9.300000      6.200000      6.300000      1.100000      0.400000   \n",
       "50%       13.100000      9.200000     10.200000      1.500000      1.000000   \n",
       "75%       18.100000     13.500000     17.600000      2.000000      2.100000   \n",
       "max      100.000000    100.000000     78.500000     17.300000     26.300000   \n",
       "\n",
       "               TOV%          USG%  blanl           OWS           DWS  \\\n",
       "count  12201.000000  12230.000000    0.0  12233.000000  12233.000000   \n",
       "mean      14.484821     18.761390    NaN      1.335151      1.264236   \n",
       "std        6.149822      5.212992    NaN      1.992772      1.195955   \n",
       "min        0.000000      0.000000    NaN     -3.300000     -0.600000   \n",
       "25%       11.100000     15.300000    NaN      0.000000      0.300000   \n",
       "50%       13.800000     18.500000    NaN      0.600000      0.900000   \n",
       "75%       16.900000     22.000000    NaN      2.100000      1.900000   \n",
       "max      100.000000     88.300000    NaN     14.800000      9.100000   \n",
       "\n",
       "                 WS         WS/48  blank2          OBPM          DBPM  \\\n",
       "count  12233.000000  12230.000000     0.0  12233.000000  12233.000000   \n",
       "mean       2.599722      0.073276     NaN     -1.519186     -0.421025   \n",
       "std        2.882877      0.088705     NaN      3.483871      2.085438   \n",
       "min       -2.100000     -2.519000     NaN    -73.800000    -19.500000   \n",
       "25%        0.300000      0.040000     NaN     -3.100000     -1.600000   \n",
       "50%        1.700000      0.082000     NaN     -1.300000     -0.400000   \n",
       "75%        4.000000      0.119000     NaN      0.500000      0.800000   \n",
       "max       20.300000      1.084000     NaN     31.900000     17.100000   \n",
       "\n",
       "                BPM          VORP            FG           FGA           FG%  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12190.000000   \n",
       "mean      -1.939990      0.599681    193.312679    422.900924      0.440695   \n",
       "std        4.245327      1.314281    172.340900    367.296754      0.089236   \n",
       "min      -86.700000     -2.600000      0.000000      0.000000      0.000000   \n",
       "25%       -3.700000     -0.200000     49.000000    116.000000      0.405000   \n",
       "50%       -1.500000      0.100000    148.000000    330.000000      0.444000   \n",
       "75%        0.500000      1.000000    296.000000    646.000000      0.484000   \n",
       "max       26.600000     12.400000    978.000000   2173.000000      1.000000   \n",
       "\n",
       "                 3P           3PA           3P%            2P           2PA  \\\n",
       "count  12233.000000  12233.000000  10299.000000  12233.000000  12233.000000   \n",
       "mean      27.813946     78.608273      0.263368    165.498733    344.292651   \n",
       "std       42.852526    113.235908      0.169878    155.173812    313.580979   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      2.000000      0.161000     39.000000     88.000000   \n",
       "50%        5.000000     21.000000      0.310000    120.000000    257.000000   \n",
       "75%       41.000000    119.000000      0.370000    249.000000    515.000000   \n",
       "max      402.000000    886.000000      1.000000    802.000000   1685.000000   \n",
       "\n",
       "                2P%          eFG%            FT           FTA           FT%  \\\n",
       "count  12170.000000  12190.000000  12233.000000  12233.000000  11874.000000   \n",
       "mean       0.461290      0.471028     96.447642    127.966157      0.724607   \n",
       "std        0.092562      0.090847    102.786317    130.386830      0.140343   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.428000      0.440000     20.000000     29.000000      0.664000   \n",
       "50%        0.468000      0.479000     63.000000     87.000000      0.750000   \n",
       "75%        0.503000      0.513000    138.000000    187.000000      0.814000   \n",
       "max        1.000000      1.500000    756.000000    916.000000      1.000000   \n",
       "\n",
       "                ORB           DRB           TRB           AST           STL  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean      62.749203    155.114363    217.863566    115.144609     40.730565   \n",
       "std       64.354985    139.585459    197.581579    136.371164     36.603116   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       15.000000     45.000000     63.000000     21.000000     11.000000   \n",
       "50%       41.000000    122.000000    168.000000     68.000000     32.000000   \n",
       "75%       91.000000    224.000000    313.000000    156.000000     61.000000   \n",
       "max      443.000000    894.000000   1258.000000    991.000000    301.000000   \n",
       "\n",
       "                BLK          TOV            PF           PTS  \n",
       "count  12233.000000  12233.00000  12233.000000  12233.000000  \n",
       "mean      25.356004     74.43399    114.182130    510.886945  \n",
       "std       34.689186     63.50923     77.476732    461.198190  \n",
       "min        0.000000      0.00000      0.000000      0.000000  \n",
       "25%        4.000000     22.00000     46.000000    129.000000  \n",
       "50%       13.000000     59.00000    110.000000    390.000000  \n",
       "75%       32.000000    111.00000    173.000000    782.000000  \n",
       "max      456.000000    464.00000    371.000000   2832.000000  "
      ]
     },
     "execution_count": 3734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12233 entries, 0 to 12232\n",
      "Data columns (total 63 columns):\n",
      "salary                  12233 non-null int64\n",
      "season_end              12233 non-null int64\n",
      "season_start            12233 non-null int64\n",
      "team                    12233 non-null object\n",
      "birth_country           12233 non-null object\n",
      "college                 12233 non-null object\n",
      "height_in_inches        12233 non-null int64\n",
      "attended_high_school    12233 non-null bool\n",
      "shoots                  12233 non-null object\n",
      "weight                  12233 non-null int64\n",
      "born_in_usa             12233 non-null bool\n",
      "attended_college        12233 non-null bool\n",
      "drafted_player          12233 non-null bool\n",
      "Pos                     12233 non-null object\n",
      "Age                     12233 non-null float64\n",
      "Tm                      12233 non-null object\n",
      "G                       12233 non-null float64\n",
      "GS                      12233 non-null float64\n",
      "MP                      12233 non-null float64\n",
      "PER                     12230 non-null float64\n",
      "TS%                     12194 non-null float64\n",
      "3PAr                    12190 non-null float64\n",
      "FTr                     12190 non-null float64\n",
      "ORB%                    12230 non-null float64\n",
      "DRB%                    12230 non-null float64\n",
      "TRB%                    12230 non-null float64\n",
      "AST%                    12230 non-null float64\n",
      "STL%                    12230 non-null float64\n",
      "BLK%                    12230 non-null float64\n",
      "TOV%                    12201 non-null float64\n",
      "USG%                    12230 non-null float64\n",
      "blanl                   0 non-null float64\n",
      "OWS                     12233 non-null float64\n",
      "DWS                     12233 non-null float64\n",
      "WS                      12233 non-null float64\n",
      "WS/48                   12230 non-null float64\n",
      "blank2                  0 non-null float64\n",
      "OBPM                    12233 non-null float64\n",
      "DBPM                    12233 non-null float64\n",
      "BPM                     12233 non-null float64\n",
      "VORP                    12233 non-null float64\n",
      "FG                      12233 non-null float64\n",
      "FGA                     12233 non-null float64\n",
      "FG%                     12190 non-null float64\n",
      "3P                      12233 non-null float64\n",
      "3PA                     12233 non-null float64\n",
      "3P%                     10299 non-null float64\n",
      "2P                      12233 non-null float64\n",
      "2PA                     12233 non-null float64\n",
      "2P%                     12170 non-null float64\n",
      "eFG%                    12190 non-null float64\n",
      "FT                      12233 non-null float64\n",
      "FTA                     12233 non-null float64\n",
      "FT%                     11874 non-null float64\n",
      "ORB                     12233 non-null float64\n",
      "DRB                     12233 non-null float64\n",
      "TRB                     12233 non-null float64\n",
      "AST                     12233 non-null float64\n",
      "STL                     12233 non-null float64\n",
      "BLK                     12233 non-null float64\n",
      "TOV                     12233 non-null float64\n",
      "PF                      12233 non-null float64\n",
      "PTS                     12233 non-null float64\n",
      "dtypes: bool(4), float64(48), int64(5), object(6)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weiteres Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nicht identifizierbare Spalten\n",
    "\n",
    "Durch den zuvor erlangten Überblick der Splaten lassen sich zwei Spalten ohne Datenpunkte erkennen. Diese sollen entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3736,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['blanl', 'blank2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teamname\n",
    "\n",
    "Die Spalte, wo die Namen der Teams länger sind sollen entfernt werden. Die andere Spalte mit den kürzeren Namen wird umbenannt. Dadurch sollen die resultierenden Spaltennamen beim _One Hot Encoding_ etwas schöner werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3737,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['team'], inplace=True)\n",
    "df.rename(columns={\"Tm\": \"team\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spalten umbennen\n",
    "\n",
    "Gewisse Spaltennamen müssen noch unbenannt werden. Nun sollten alle Features, abgesehen von den Saisonstatistiken k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3738,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Pos\": \"position\", \"Age\": \"age\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12233 entries, 0 to 12232\n",
      "Data columns (total 60 columns):\n",
      "salary                  12233 non-null int64\n",
      "season_end              12233 non-null int64\n",
      "season_start            12233 non-null int64\n",
      "birth_country           12233 non-null object\n",
      "college                 12233 non-null object\n",
      "height_in_inches        12233 non-null int64\n",
      "attended_high_school    12233 non-null bool\n",
      "shoots                  12233 non-null object\n",
      "weight                  12233 non-null int64\n",
      "born_in_usa             12233 non-null bool\n",
      "attended_college        12233 non-null bool\n",
      "drafted_player          12233 non-null bool\n",
      "position                12233 non-null object\n",
      "age                     12233 non-null float64\n",
      "team                    12233 non-null object\n",
      "G                       12233 non-null float64\n",
      "GS                      12233 non-null float64\n",
      "MP                      12233 non-null float64\n",
      "PER                     12230 non-null float64\n",
      "TS%                     12194 non-null float64\n",
      "3PAr                    12190 non-null float64\n",
      "FTr                     12190 non-null float64\n",
      "ORB%                    12230 non-null float64\n",
      "DRB%                    12230 non-null float64\n",
      "TRB%                    12230 non-null float64\n",
      "AST%                    12230 non-null float64\n",
      "STL%                    12230 non-null float64\n",
      "BLK%                    12230 non-null float64\n",
      "TOV%                    12201 non-null float64\n",
      "USG%                    12230 non-null float64\n",
      "OWS                     12233 non-null float64\n",
      "DWS                     12233 non-null float64\n",
      "WS                      12233 non-null float64\n",
      "WS/48                   12230 non-null float64\n",
      "OBPM                    12233 non-null float64\n",
      "DBPM                    12233 non-null float64\n",
      "BPM                     12233 non-null float64\n",
      "VORP                    12233 non-null float64\n",
      "FG                      12233 non-null float64\n",
      "FGA                     12233 non-null float64\n",
      "FG%                     12190 non-null float64\n",
      "3P                      12233 non-null float64\n",
      "3PA                     12233 non-null float64\n",
      "3P%                     10299 non-null float64\n",
      "2P                      12233 non-null float64\n",
      "2PA                     12233 non-null float64\n",
      "2P%                     12170 non-null float64\n",
      "eFG%                    12190 non-null float64\n",
      "FT                      12233 non-null float64\n",
      "FTA                     12233 non-null float64\n",
      "FT%                     11874 non-null float64\n",
      "ORB                     12233 non-null float64\n",
      "DRB                     12233 non-null float64\n",
      "TRB                     12233 non-null float64\n",
      "AST                     12233 non-null float64\n",
      "STL                     12233 non-null float64\n",
      "BLK                     12233 non-null float64\n",
      "TOV                     12233 non-null float64\n",
      "PF                      12233 non-null float64\n",
      "PTS                     12233 non-null float64\n",
      "dtypes: bool(4), float64(46), int64(5), object(5)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fehlende Datenpunkte behandeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3P%                     1934\n",
       "FT%                      359\n",
       "2P%                       63\n",
       "FTr                       43\n",
       "FG%                       43\n",
       "eFG%                      43\n",
       "3PAr                      43\n",
       "TS%                       39\n",
       "TOV%                      32\n",
       "ORB%                       3\n",
       "TRB%                       3\n",
       "DRB%                       3\n",
       "WS/48                      3\n",
       "BLK%                       3\n",
       "PER                        3\n",
       "STL%                       3\n",
       "USG%                       3\n",
       "AST%                       3\n",
       "age                        0\n",
       "shoots                     0\n",
       "season_end                 0\n",
       "season_start               0\n",
       "birth_country              0\n",
       "college                    0\n",
       "height_in_inches           0\n",
       "attended_high_school       0\n",
       "weight                     0\n",
       "drafted_player             0\n",
       "born_in_usa                0\n",
       "attended_college           0\n",
       "MP                         0\n",
       "GS                         0\n",
       "G                          0\n",
       "team                       0\n",
       "position                   0\n",
       "PTS                        0\n",
       "PF                         0\n",
       "OWS                        0\n",
       "TOV                        0\n",
       "BLK                        0\n",
       "STL                        0\n",
       "AST                        0\n",
       "TRB                        0\n",
       "DRB                        0\n",
       "ORB                        0\n",
       "FTA                        0\n",
       "FT                         0\n",
       "2PA                        0\n",
       "2P                         0\n",
       "3PA                        0\n",
       "3P                         0\n",
       "FGA                        0\n",
       "FG                         0\n",
       "VORP                       0\n",
       "BPM                        0\n",
       "DBPM                       0\n",
       "OBPM                       0\n",
       "WS                         0\n",
       "DWS                        0\n",
       "salary                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es existieren nur fehlende Daten in den Saisonstatistiken. Diese werden mit dem Durchschnittswert befüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3741,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_missing_data = [\n",
    "    \"3P%\",\n",
    "    \"FT%\",                   \n",
    "    \"2P%\",                     \n",
    "    \"FTr\",                 \n",
    "    \"FG%\",                     \n",
    "    \"eFG%\",                   \n",
    "    \"3PAr\",                   \n",
    "    \"TS%\",                     \n",
    "    \"TOV%\",                     \n",
    "    \"ORB%\",                    \n",
    "    \"TRB%\",                     \n",
    "    \"DRB%\",                     \n",
    "    \"WS/48\",                  \n",
    "    \"BLK%\",                    \n",
    "    \"PER\",                       \n",
    "    \"STL%\",                      \n",
    "    \"USG%\",                       \n",
    "    \"AST%\",                     \n",
    "]\n",
    "\n",
    "for feature in features_with_missing_data:\n",
    "    df[feature] = df[feature].fillna(df[feature].mean())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTS                     0\n",
       "PF                      0\n",
       "BLK%                    0\n",
       "STL%                    0\n",
       "AST%                    0\n",
       "TRB%                    0\n",
       "DRB%                    0\n",
       "ORB%                    0\n",
       "FTr                     0\n",
       "3PAr                    0\n",
       "TS%                     0\n",
       "PER                     0\n",
       "MP                      0\n",
       "GS                      0\n",
       "G                       0\n",
       "team                    0\n",
       "age                     0\n",
       "position                0\n",
       "drafted_player          0\n",
       "attended_college        0\n",
       "born_in_usa             0\n",
       "weight                  0\n",
       "shoots                  0\n",
       "attended_high_school    0\n",
       "height_in_inches        0\n",
       "college                 0\n",
       "birth_country           0\n",
       "season_start            0\n",
       "season_end              0\n",
       "TOV%                    0\n",
       "USG%                    0\n",
       "OWS                     0\n",
       "2PA                     0\n",
       "TOV                     0\n",
       "BLK                     0\n",
       "STL                     0\n",
       "AST                     0\n",
       "TRB                     0\n",
       "DRB                     0\n",
       "ORB                     0\n",
       "FT%                     0\n",
       "FTA                     0\n",
       "FT                      0\n",
       "eFG%                    0\n",
       "2P%                     0\n",
       "2P                      0\n",
       "DWS                     0\n",
       "3P%                     0\n",
       "3PA                     0\n",
       "3P                      0\n",
       "FG%                     0\n",
       "FGA                     0\n",
       "FG                      0\n",
       "VORP                    0\n",
       "BPM                     0\n",
       "DBPM                    0\n",
       "OBPM                    0\n",
       "WS/48                   0\n",
       "WS                      0\n",
       "salary                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding (& Feature-Auswahl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['attended_high_school', 'born_in_usa', 'attended_college',\n",
       "       'drafted_player'], dtype=object)"
      ]
     },
     "execution_count": 3743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes('bool').columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['birth_country', 'college', 'shoots', 'position', 'team'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes('object').columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attended High School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3745,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['attended_high_school'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drafted Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3746,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['drafted_player'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shoots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3747,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['shoots'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position\n",
    "\n",
    "Ohne Verwendung von diesem Feature würde der _Linear Regression Score_ etwas veringert sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['position'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3749,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team\n",
    "\n",
    "Ohne Verwendung von diesem Feature würde der _Linear Regression Score_ etwas veringert sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['team'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3751,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['team'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### college vs. attended_college"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verwendung des College-Feature\n",
    "\n",
    "Die Verwendung von diesem Feature resultiert in einem negativen _Linear Regression Score_. Das Feature kann somit ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3752,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['college'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=['college'])\n",
    "# df.drop(columns=['attended_college'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verwendung des Attended-College-Feature\n",
    "\n",
    "Die Verwendung von diesem Feature resultiert in einer 1-2% Steigerung des _Linear Regression Score_. Das Feature kann somit verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=['attended_college'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3755,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['attended_college'])\n",
    "# df.drop(columns=['college'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### birth_country vs. born_in_usa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verwendung des Birth-Country Feature\n",
    "\n",
    "Die Verwendung von diesem Feature resultiert in einem negativen _Linear Regression Score_. Das Feature kann somit ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3756,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['birth_country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=['birth_country'])\n",
    "# df.drop(columns=['born_in_usa'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verwendung des Born-In-Usa-Feature\n",
    "\n",
    "Die Verwendung von diesem Feature führt zu einer minimalen Verringerung (~0.02%) des _Linear Regression Score_. Es liefert somit jedoch keinen Mehrwert und kann somit ignoriert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3758,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['born_in_usa'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3759,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.get_dummies(df, columns=['born_in_usa'])\n",
    "# df.drop(columns=['birth_country'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>attended_high_school_False</th>\n",
       "      <th>attended_high_school_True</th>\n",
       "      <th>drafted_player_False</th>\n",
       "      <th>drafted_player_True</th>\n",
       "      <th>shoots_Left</th>\n",
       "      <th>shoots_Left Right</th>\n",
       "      <th>shoots_Right</th>\n",
       "      <th>position_C</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>position_SG</th>\n",
       "      <th>team_ATL</th>\n",
       "      <th>team_BOS</th>\n",
       "      <th>team_BRK</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>team_CHH</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>team_CHO</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>team_DEN</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>team_IND</th>\n",
       "      <th>team_KCK</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>team_MEM</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>team_MIL</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>team_NJN</th>\n",
       "      <th>team_NOH</th>\n",
       "      <th>team_NOK</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>team_NYK</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>team_ORL</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>team_PHO</th>\n",
       "      <th>team_POR</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>team_SAS</th>\n",
       "      <th>team_SEA</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>team_UTA</th>\n",
       "      <th>team_VAN</th>\n",
       "      <th>team_WAS</th>\n",
       "      <th>team_WSB</th>\n",
       "      <th>attended_college_False</th>\n",
       "      <th>attended_college_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>395000</td>\n",
       "      <td>1991</td>\n",
       "      <td>1990</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379</td>\n",
       "      <td>10.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>55.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.474</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494000</td>\n",
       "      <td>1992</td>\n",
       "      <td>1991</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>9.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>15.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>178.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>178.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.493</td>\n",
       "      <td>76.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>1993</td>\n",
       "      <td>1992</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240</td>\n",
       "      <td>11.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.079</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>219.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>219.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.525</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>805000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>8.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>16.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.436</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>650000</td>\n",
       "      <td>1995</td>\n",
       "      <td>1994</td>\n",
       "      <td>82</td>\n",
       "      <td>240</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724607</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary  season_end  season_start  height_in_inches  weight   age     G  \\\n",
       "0  395000        1991          1990                82     240  22.0  43.0   \n",
       "1  494000        1992          1991                82     240  23.0  71.0   \n",
       "2  500000        1993          1992                82     240  24.0  63.0   \n",
       "3  805000        1994          1993                82     240  25.0  13.0   \n",
       "4  650000        1995          1994                82     240  26.0   3.0   \n",
       "\n",
       "     GS      MP   PER    TS%  3PAr    FTr  ORB%  DRB%  TRB%  AST%  STL%  BLK%  \\\n",
       "0   0.0   290.0  13.1  0.499   0.0  0.379  10.4  23.4  17.0   5.8   0.7   2.5   \n",
       "1   1.0   934.0  13.5  0.533   0.0  0.280   9.5  20.9  15.2   4.7   1.3   1.1   \n",
       "2  52.0  1152.0  13.4  0.557   0.0  0.240  11.3  18.1  14.8   2.2   0.8   1.2   \n",
       "3   0.0   159.0   9.2  0.485   0.0  0.455   8.5  24.2  16.3   2.7   0.6   1.2   \n",
       "4   0.0    30.0 -12.5  0.091   0.0  0.000  11.6  19.6  15.5   0.0   0.0   0.0   \n",
       "\n",
       "   TOV%  USG%  OWS  DWS   WS  WS/48  OBPM  DBPM   BPM  VORP     FG    FGA  \\\n",
       "0  14.0  22.1  0.0  0.5  0.5  0.079  -4.2  -0.7  -5.0  -0.2   55.0  116.0   \n",
       "1  14.0  20.6  0.6  1.5  2.1  0.110  -3.0  -0.9  -3.9  -0.5  178.0  361.0   \n",
       "2  15.4  20.5  0.7  1.2  1.9  0.079  -2.1  -2.1  -4.1  -0.6  219.0  417.0   \n",
       "3  20.5  22.6 -0.2  0.1 -0.1 -0.032  -7.1  -3.1 -10.2  -0.3   24.0   55.0   \n",
       "4  31.3  23.8 -0.3  0.0 -0.3 -0.466 -21.1  -6.9 -28.0  -0.2    1.0   11.0   \n",
       "\n",
       "     FG%   3P  3PA       3P%     2P    2PA    2P%   eFG%    FT    FTA  \\\n",
       "0  0.474  0.0  0.0  0.263368   55.0  116.0  0.474  0.474  25.0   44.0   \n",
       "1  0.493  0.0  0.0  0.263368  178.0  361.0  0.493  0.493  76.0  101.0   \n",
       "2  0.525  0.0  0.0  0.263368  219.0  417.0  0.525  0.525  76.0  100.0   \n",
       "3  0.436  0.0  0.0  0.263368   24.0   55.0  0.436  0.436  16.0   25.0   \n",
       "4  0.091  0.0  0.0  0.263368    1.0   11.0  0.091  0.091   0.0    0.0   \n",
       "\n",
       "        FT%    ORB    DRB    TRB   AST   STL   BLK   TOV     PF    PTS  \\\n",
       "0  0.568000   27.0   62.0   89.0  12.0   4.0  12.0  22.0   39.0  135.0   \n",
       "1  0.752000   81.0  179.0  260.0  30.0  25.0  16.0  66.0  132.0  432.0   \n",
       "2  0.760000  114.0  186.0  300.0  17.0  19.0  22.0  84.0  165.0  514.0   \n",
       "3  0.640000   12.0   34.0   46.0   3.0   2.0   3.0  17.0   20.0   64.0   \n",
       "4  0.724607    3.0    5.0    8.0   0.0   0.0   0.0   5.0    2.0    2.0   \n",
       "\n",
       "   attended_high_school_False  attended_high_school_True  \\\n",
       "0                           1                          0   \n",
       "1                           1                          0   \n",
       "2                           1                          0   \n",
       "3                           1                          0   \n",
       "4                           1                          0   \n",
       "\n",
       "   drafted_player_False  drafted_player_True  shoots_Left  shoots_Left Right  \\\n",
       "0                     1                    0            0                  0   \n",
       "1                     1                    0            0                  0   \n",
       "2                     1                    0            0                  0   \n",
       "3                     1                    0            0                  0   \n",
       "4                     1                    0            0                  0   \n",
       "\n",
       "   shoots_Right  position_C  position_PF  position_PG  position_SF  \\\n",
       "0             1           0            1            0            0   \n",
       "1             1           0            1            0            0   \n",
       "2             1           0            1            0            0   \n",
       "3             1           0            1            0            0   \n",
       "4             1           0            1            0            0   \n",
       "\n",
       "   position_SG  team_ATL  team_BOS  team_BRK  team_CHA  team_CHH  team_CHI  \\\n",
       "0            0         0         0         0         0         0         0   \n",
       "1            0         0         0         0         0         0         0   \n",
       "2            0         0         1         0         0         0         0   \n",
       "3            0         0         1         0         0         0         0   \n",
       "4            0         0         0         0         0         0         0   \n",
       "\n",
       "   team_CHO  team_CLE  team_DAL  team_DEN  team_DET  team_GSW  team_HOU  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   team_IND  team_KCK  team_LAC  team_LAL  team_MEM  team_MIA  team_MIL  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   team_MIN  team_NJN  team_NOH  team_NOK  team_NOP  team_NYK  team_OKC  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   team_ORL  team_PHI  team_PHO  team_POR  team_SAC  team_SAS  team_SEA  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         1         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         1         0         0         0         0         0   \n",
       "\n",
       "   team_TOR  team_UTA  team_VAN  team_WAS  team_WSB  attended_college_False  \\\n",
       "0         0         0         0         0         0                       0   \n",
       "1         0         0         0         0         0                       0   \n",
       "2         0         0         0         0         0                       0   \n",
       "3         0         0         0         0         0                       0   \n",
       "4         0         0         0         0         0                       0   \n",
       "\n",
       "   attended_college_True  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  "
      ]
     },
     "execution_count": 3760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>attended_high_school_False</th>\n",
       "      <th>attended_high_school_True</th>\n",
       "      <th>drafted_player_False</th>\n",
       "      <th>drafted_player_True</th>\n",
       "      <th>shoots_Left</th>\n",
       "      <th>shoots_Left Right</th>\n",
       "      <th>shoots_Right</th>\n",
       "      <th>position_C</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>position_SG</th>\n",
       "      <th>team_ATL</th>\n",
       "      <th>team_BOS</th>\n",
       "      <th>team_BRK</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>team_CHH</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>team_CHO</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>team_DEN</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>team_IND</th>\n",
       "      <th>team_KCK</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>team_MEM</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>team_MIL</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>team_NJN</th>\n",
       "      <th>team_NOH</th>\n",
       "      <th>team_NOK</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>team_NYK</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>team_ORL</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>team_PHO</th>\n",
       "      <th>team_POR</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>team_SAS</th>\n",
       "      <th>team_SEA</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>team_UTA</th>\n",
       "      <th>team_VAN</th>\n",
       "      <th>team_WAS</th>\n",
       "      <th>team_WSB</th>\n",
       "      <th>attended_college_False</th>\n",
       "      <th>attended_college_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12228</th>\n",
       "      <td>694000</td>\n",
       "      <td>1997</td>\n",
       "      <td>1996</td>\n",
       "      <td>84</td>\n",
       "      <td>250</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>13.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.485</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12229</th>\n",
       "      <td>784200</td>\n",
       "      <td>1998</td>\n",
       "      <td>1997</td>\n",
       "      <td>84</td>\n",
       "      <td>250</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.250</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12230</th>\n",
       "      <td>950000</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>84</td>\n",
       "      <td>240</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>10.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.323</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12231</th>\n",
       "      <td>750000</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>80</td>\n",
       "      <td>215</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.181</td>\n",
       "      <td>1.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>33.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.473</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>15.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12232</th>\n",
       "      <td>1034956</td>\n",
       "      <td>2017</td>\n",
       "      <td>2016</td>\n",
       "      <td>85</td>\n",
       "      <td>240</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.206</td>\n",
       "      <td>7.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>14.3</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.653</td>\n",
       "      <td>41.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary  season_end  season_start  height_in_inches  weight   age  \\\n",
       "12228   694000        1997          1996                84     250  23.0   \n",
       "12229   784200        1998          1997                84     250  24.0   \n",
       "12230   950000        2017          2016                84     240  20.0   \n",
       "12231   750000        2017          2016                80     215  22.0   \n",
       "12232  1034956        2017          2016                85     240  19.0   \n",
       "\n",
       "          G    GS     MP   PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  \\\n",
       "12228  16.0   0.0   88.0  20.3  0.591  0.000  0.758  13.1  16.6  14.9  10.3   \n",
       "12229   6.0   0.0   22.0   2.3  0.349  0.143  0.286   0.0  21.3  10.9   7.1   \n",
       "12230  19.0   0.0  108.0   7.3  0.346  0.000  0.161  10.8  24.9  17.6   5.3   \n",
       "12231  44.0  18.0  843.0   6.9  0.503  0.448  0.181   1.9  14.2   8.0   6.1   \n",
       "12232  38.0  11.0  609.0  17.0  0.547  0.013  0.206   7.1  21.9  14.3   8.1   \n",
       "\n",
       "       STL%  BLK%  TOV%  USG%  OWS  DWS   WS  WS/48  OBPM  DBPM   BPM  VORP  \\\n",
       "12228   0.6   0.0   8.3  24.4  0.3  0.0  0.4  0.200   1.6  -3.9  -2.3   0.0   \n",
       "12229   0.0   0.0   6.0  35.3 -0.1  0.0 -0.1 -0.120 -11.6  -7.3 -18.9  -0.1   \n",
       "12230   0.9   3.7   8.3  14.8 -0.1  0.1  0.0 -0.005  -7.8   0.4  -7.3  -0.1   \n",
       "12231   0.9   1.5  14.4  14.4 -0.3  0.8  0.5  0.030  -3.6  -0.1  -3.7  -0.4   \n",
       "12232   1.1   4.4  10.4  20.3  0.6  0.5  1.1  0.086  -2.7   0.3  -2.5  -0.1   \n",
       "\n",
       "          FG    FGA    FG%    3P   3PA       3P%     2P    2PA    2P%   eFG%  \\\n",
       "12228   16.0   33.0  0.485   0.0   0.0  0.263368   16.0   33.0  0.485  0.485   \n",
       "12229    3.0   14.0  0.214   1.0   2.0  0.500000    2.0   12.0  0.167  0.250   \n",
       "12230   10.0   31.0  0.323   0.0   0.0  0.263368   10.0   31.0  0.323  0.323   \n",
       "12231   88.0  221.0  0.398  33.0  99.0  0.333000   55.0  122.0  0.451  0.473   \n",
       "12232  126.0  238.0  0.529   0.0   3.0  0.000000  126.0  235.0  0.536  0.529   \n",
       "\n",
       "         FT   FTA    FT%   ORB    DRB    TRB   AST   STL   BLK   TOV    PF  \\\n",
       "12228  20.0  25.0  0.800  10.0   13.0   23.0   5.0   1.0   0.0   4.0  17.0   \n",
       "12229   4.0   4.0  1.000   0.0    4.0    4.0   1.0   0.0   0.0   1.0   5.0   \n",
       "12230   3.0   5.0  0.600  11.0   24.0   35.0   4.0   2.0   5.0   3.0  17.0   \n",
       "12231  31.0  40.0  0.775  15.0  110.0  125.0  36.0  15.0  16.0  40.0  78.0   \n",
       "12232  32.0  49.0  0.653  41.0  118.0  159.0  30.0  14.0  33.0  30.0  66.0   \n",
       "\n",
       "         PTS  attended_high_school_False  attended_high_school_True  \\\n",
       "12228   52.0                           1                          0   \n",
       "12229   11.0                           1                          0   \n",
       "12230   23.0                           1                          0   \n",
       "12231  240.0                           0                          1   \n",
       "12232  284.0                           0                          1   \n",
       "\n",
       "       drafted_player_False  drafted_player_True  shoots_Left  \\\n",
       "12228                     1                    0            0   \n",
       "12229                     1                    0            0   \n",
       "12230                     1                    0            1   \n",
       "12231                     1                    0            0   \n",
       "12232                     1                    0            0   \n",
       "\n",
       "       shoots_Left Right  shoots_Right  position_C  position_PF  position_PG  \\\n",
       "12228                  0             1           1            0            0   \n",
       "12229                  0             1           1            0            0   \n",
       "12230                  0             0           1            0            0   \n",
       "12231                  0             1           0            0            0   \n",
       "12232                  0             1           1            0            0   \n",
       "\n",
       "       position_SF  position_SG  team_ATL  team_BOS  team_BRK  team_CHA  \\\n",
       "12228            0            0         0         0         0         0   \n",
       "12229            0            0         0         0         0         0   \n",
       "12230            0            0         0         0         0         0   \n",
       "12231            1            0         0         0         0         0   \n",
       "12232            0            0         0         0         0         0   \n",
       "\n",
       "       team_CHH  team_CHI  team_CHO  team_CLE  team_DAL  team_DEN  team_DET  \\\n",
       "12228         0         0         0         0         0         1         0   \n",
       "12229         0         0         0         0         0         0         0   \n",
       "12230         0         0         0         0         0         0         0   \n",
       "12231         0         1         0         0         0         0         0   \n",
       "12232         0         0         0         0         0         0         0   \n",
       "\n",
       "       team_GSW  team_HOU  team_IND  team_KCK  team_LAC  team_LAL  team_MEM  \\\n",
       "12228         0         0         0         0         0         0         0   \n",
       "12229         0         0         0         0         0         0         0   \n",
       "12230         0         0         0         0         0         0         0   \n",
       "12231         0         0         0         0         0         0         0   \n",
       "12232         0         0         0         0         0         1         0   \n",
       "\n",
       "       team_MIA  team_MIL  team_MIN  team_NJN  team_NOH  team_NOK  team_NOP  \\\n",
       "12228         0         0         0         0         0         0         0   \n",
       "12229         0         0         0         0         0         0         0   \n",
       "12230         0         0         0         0         0         0         0   \n",
       "12231         0         0         0         0         0         0         0   \n",
       "12232         0         0         0         0         0         0         0   \n",
       "\n",
       "       team_NYK  team_OKC  team_ORL  team_PHI  team_PHO  team_POR  team_SAC  \\\n",
       "12228         0         0         0         0         0         0         0   \n",
       "12229         0         0         0         0         0         0         0   \n",
       "12230         0         0         1         0         0         0         0   \n",
       "12231         0         0         0         0         0         0         0   \n",
       "12232         0         0         0         0         0         0         0   \n",
       "\n",
       "       team_SAS  team_SEA  team_TOR  team_UTA  team_VAN  team_WAS  team_WSB  \\\n",
       "12228         0         0         0         0         0         0         0   \n",
       "12229         0         1         0         0         0         0         0   \n",
       "12230         0         0         0         0         0         0         0   \n",
       "12231         0         0         0         0         0         0         0   \n",
       "12232         0         0         0         0         0         0         0   \n",
       "\n",
       "       attended_college_False  attended_college_True  \n",
       "12228                       0                      1  \n",
       "12229                       0                      1  \n",
       "12230                       0                      1  \n",
       "12231                       1                      0  \n",
       "12232                       1                      0  "
      ]
     },
     "execution_count": 3761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>attended_high_school_False</th>\n",
       "      <th>attended_high_school_True</th>\n",
       "      <th>drafted_player_False</th>\n",
       "      <th>drafted_player_True</th>\n",
       "      <th>shoots_Left</th>\n",
       "      <th>shoots_Left Right</th>\n",
       "      <th>shoots_Right</th>\n",
       "      <th>position_C</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>position_SG</th>\n",
       "      <th>team_ATL</th>\n",
       "      <th>team_BOS</th>\n",
       "      <th>team_BRK</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>team_CHH</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>team_CHO</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>team_DEN</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>team_IND</th>\n",
       "      <th>team_KCK</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>team_MEM</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>team_MIL</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>team_NJN</th>\n",
       "      <th>team_NOH</th>\n",
       "      <th>team_NOK</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>team_NYK</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>team_ORL</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>team_PHO</th>\n",
       "      <th>team_POR</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>team_SAS</th>\n",
       "      <th>team_SEA</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>team_UTA</th>\n",
       "      <th>team_VAN</th>\n",
       "      <th>team_WAS</th>\n",
       "      <th>team_WSB</th>\n",
       "      <th>attended_college_False</th>\n",
       "      <th>attended_college_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>893400</td>\n",
       "      <td>2003</td>\n",
       "      <td>2002</td>\n",
       "      <td>81</td>\n",
       "      <td>220</td>\n",
       "      <td>21.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2213.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.576</td>\n",
       "      <td>8.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.199</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>315.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0.491</td>\n",
       "      <td>37.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>278.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.519</td>\n",
       "      <td>296.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>147.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>963.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>2350820</td>\n",
       "      <td>2014</td>\n",
       "      <td>2013</td>\n",
       "      <td>80</td>\n",
       "      <td>228</td>\n",
       "      <td>26.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.189</td>\n",
       "      <td>10.9</td>\n",
       "      <td>17.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>222.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.551</td>\n",
       "      <td>47.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.618</td>\n",
       "      <td>149.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1118520</td>\n",
       "      <td>2010</td>\n",
       "      <td>2009</td>\n",
       "      <td>72</td>\n",
       "      <td>161</td>\n",
       "      <td>25.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.224</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>575.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>0.432</td>\n",
       "      <td>209.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>366.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.511</td>\n",
       "      <td>245.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.822</td>\n",
       "      <td>54.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>2429000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1993</td>\n",
       "      <td>80</td>\n",
       "      <td>195</td>\n",
       "      <td>28.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.169</td>\n",
       "      <td>5.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>17.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.089</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>356.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>354.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.461</td>\n",
       "      <td>84.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.641</td>\n",
       "      <td>109.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11119</th>\n",
       "      <td>614000</td>\n",
       "      <td>1997</td>\n",
       "      <td>1996</td>\n",
       "      <td>81</td>\n",
       "      <td>240</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>13.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.431</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.633</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2000000</td>\n",
       "      <td>1991</td>\n",
       "      <td>1990</td>\n",
       "      <td>85</td>\n",
       "      <td>235</td>\n",
       "      <td>29.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.320</td>\n",
       "      <td>9.3</td>\n",
       "      <td>17.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>314.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>310.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.437</td>\n",
       "      <td>169.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>176.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>135000</td>\n",
       "      <td>1992</td>\n",
       "      <td>1991</td>\n",
       "      <td>83</td>\n",
       "      <td>235</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.247</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-9.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>33.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.429</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.842</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary  season_end  season_start  height_in_inches  weight   age  \\\n",
       "6246    893400        2003          2002                81     220  21.0   \n",
       "1213   2350820        2014          2013                80     228  26.0   \n",
       "1445   1118520        2010          2009                72     161  25.0   \n",
       "4290   2429000        1994          1993                80     195  28.0   \n",
       "11119   614000        1997          1996                81     240  23.0   \n",
       "1300   2000000        1991          1990                85     235  29.0   \n",
       "3543    135000        1992          1991                83     235  29.0   \n",
       "\n",
       "          G    GS      MP   PER    TS%   3PAr    FTr  ORB%  DRB%  TRB%  AST%  \\\n",
       "6246   80.0  11.0  2213.0  21.1  0.598  0.178  0.576   8.4  14.4  11.5  10.6   \n",
       "1213   72.0  45.0  1553.0  15.0  0.563  0.005  0.189  10.9  17.5  14.1   6.3   \n",
       "1445   82.0  82.0  2919.0  16.0  0.549  0.394  0.224   2.0   6.6   4.2  25.6   \n",
       "4290   77.0  73.0  2112.0  12.3  0.480  0.009  0.169   5.4  13.0   9.0   7.4   \n",
       "11119  35.0   6.0   298.0  10.3  0.475  0.000  0.417  13.4  24.2  18.7   3.8   \n",
       "1300   62.0  51.0  1916.0  14.1  0.486  0.030  0.320   9.3  17.3  13.1  11.4   \n",
       "3543   34.0   0.0   175.0  11.9  0.480  0.000  0.247  12.3  25.1  18.4   5.0   \n",
       "\n",
       "       STL%  BLK%  TOV%  USG%  OWS  DWS   WS  WS/48  OBPM  DBPM  BPM  VORP  \\\n",
       "6246    2.9   6.1  14.5  19.6  5.3  3.8  9.2  0.199   2.6   4.0  6.6   4.8   \n",
       "1213    1.4   2.4  11.7  14.4  2.3  2.0  4.3  0.132  -1.1   1.3  0.2   0.8   \n",
       "1445    1.2   0.3  13.7  25.7  3.9  1.6  5.5  0.091   2.7  -2.5  0.2   1.6   \n",
       "4290    1.6   1.5   6.3  17.1  1.7  2.2  3.9  0.089  -1.6   0.5 -1.1   0.5   \n",
       "11119   1.5   3.9  25.4  17.7 -0.4  0.5  0.1  0.019  -6.8   0.8 -6.0  -0.3   \n",
       "1300    1.1   2.8  14.6  20.3  0.4  2.2  2.6  0.066  -1.8   1.2 -0.6   0.7   \n",
       "3543    0.6   1.0  18.2  23.9 -0.1  0.2  0.1  0.019  -5.8  -3.5 -9.3  -0.3   \n",
       "\n",
       "          FG     FGA    FG%     3P    3PA       3P%     2P    2PA    2P%  \\\n",
       "6246   315.0   642.0  0.491   37.0  114.0  0.325000  278.0  528.0  0.527   \n",
       "1213   222.0   403.0  0.551    0.0    2.0  0.000000  222.0  401.0  0.554   \n",
       "1445   575.0  1331.0  0.432  209.0  525.0  0.398000  366.0  806.0  0.454   \n",
       "4290   356.0   774.0  0.460    2.0    7.0  0.286000  354.0  767.0  0.462   \n",
       "11119   31.0    72.0  0.431    0.0    0.0  0.263368   31.0   72.0  0.431   \n",
       "1300   314.0   723.0  0.434    4.0   22.0  0.182000  310.0  701.0  0.442   \n",
       "3543    33.0    77.0  0.429    0.0    0.0  0.263368   33.0   77.0  0.429   \n",
       "\n",
       "        eFG%     FT    FTA    FT%    ORB    DRB    TRB    AST    STL    BLK  \\\n",
       "6246   0.519  296.0  370.0  0.800  147.0  273.0  420.0  138.0  118.0  175.0   \n",
       "1213   0.551   47.0   76.0  0.618  149.0  230.0  379.0   64.0   41.0   45.0   \n",
       "1445   0.511  245.0  298.0  0.822   54.0  161.0  215.0  434.0   69.0   14.0   \n",
       "4290   0.461   84.0  131.0  0.641  109.0  242.0  351.0  107.0   70.0   49.0   \n",
       "11119  0.431   19.0   30.0  0.633   35.0   60.0   95.0    7.0    8.0   15.0   \n",
       "1300   0.437  169.0  231.0  0.732  176.0  304.0  480.0  147.0   43.0   90.0   \n",
       "3543   0.429   16.0   19.0  0.842   21.0   40.0   61.0    6.0    2.0    3.0   \n",
       "\n",
       "         TOV     PF     PTS  attended_high_school_False  \\\n",
       "6246   136.0  185.0   963.0                           1   \n",
       "1213    58.0  131.0   491.0                           1   \n",
       "1445   232.0  199.0  1604.0                           1   \n",
       "4290    56.0  179.0   798.0                           1   \n",
       "11119   29.0   43.0    81.0                           1   \n",
       "1300   141.0  175.0   801.0                           1   \n",
       "3543    19.0   22.0    82.0                           1   \n",
       "\n",
       "       attended_high_school_True  drafted_player_False  drafted_player_True  \\\n",
       "6246                           0                     1                    0   \n",
       "1213                           0                     1                    0   \n",
       "1445                           0                     1                    0   \n",
       "4290                           0                     1                    0   \n",
       "11119                          0                     1                    0   \n",
       "1300                           0                     1                    0   \n",
       "3543                           0                     1                    0   \n",
       "\n",
       "       shoots_Left  shoots_Left Right  shoots_Right  position_C  position_PF  \\\n",
       "6246             0                  0             1           0            0   \n",
       "1213             1                  0             0           0            1   \n",
       "1445             0                  0             1           0            0   \n",
       "4290             0                  0             1           0            0   \n",
       "11119            0                  0             1           0            1   \n",
       "1300             0                  0             1           1            0   \n",
       "3543             0                  0             1           1            0   \n",
       "\n",
       "       position_PG  position_SF  position_SG  team_ATL  team_BOS  team_BRK  \\\n",
       "6246             0            1            0         0         0         0   \n",
       "1213             0            0            0         0         0         0   \n",
       "1445             1            0            0         0         0         0   \n",
       "4290             0            1            0         0         0         0   \n",
       "11119            0            0            0         0         0         0   \n",
       "1300             0            0            0         0         0         0   \n",
       "3543             0            0            0         0         0         0   \n",
       "\n",
       "       team_CHA  team_CHH  team_CHI  team_CHO  team_CLE  team_DAL  team_DEN  \\\n",
       "6246          0         0         0         0         0         0         0   \n",
       "1213          0         0         0         0         0         0         0   \n",
       "1445          0         0         0         0         0         0         0   \n",
       "4290          0         0         0         0         0         0         0   \n",
       "11119         0         0         0         0         0         0         0   \n",
       "1300          0         0         0         0         0         0         0   \n",
       "3543          0         0         0         0         0         0         0   \n",
       "\n",
       "       team_DET  team_GSW  team_HOU  team_IND  team_KCK  team_LAC  team_LAL  \\\n",
       "6246          0         0         0         0         0         0         0   \n",
       "1213          0         0         0         0         0         0         0   \n",
       "1445          0         0         1         0         0         0         0   \n",
       "4290          0         0         0         0         0         0         0   \n",
       "11119         0         0         0         0         0         0         0   \n",
       "1300          0         0         0         0         0         0         0   \n",
       "3543          0         0         0         0         0         0         0   \n",
       "\n",
       "       team_MEM  team_MIA  team_MIL  team_MIN  team_NJN  team_NOH  team_NOK  \\\n",
       "6246          0         0         0         0         0         0         0   \n",
       "1213          0         0         0         0         0         0         0   \n",
       "1445          0         0         0         0         0         0         0   \n",
       "4290          0         0         0         0         0         0         0   \n",
       "11119         0         0         0         0         0         0         0   \n",
       "1300          0         0         0         0         1         0         0   \n",
       "3543          0         0         0         0         1         0         0   \n",
       "\n",
       "       team_NOP  team_NYK  team_OKC  team_ORL  team_PHI  team_PHO  team_POR  \\\n",
       "6246          0         0         0         0         0         0         0   \n",
       "1213          0         0         0         0         0         0         0   \n",
       "1445          0         0         0         0         0         0         0   \n",
       "4290          0         0         0         0         0         0         1   \n",
       "11119         0         0         0         1         0         0         0   \n",
       "1300          0         0         0         0         0         0         0   \n",
       "3543          0         0         0         0         0         0         0   \n",
       "\n",
       "       team_SAC  team_SAS  team_SEA  team_TOR  team_UTA  team_VAN  team_WAS  \\\n",
       "6246          0         0         0         0         1         0         0   \n",
       "1213          0         0         0         0         0         0         1   \n",
       "1445          0         0         0         0         0         0         0   \n",
       "4290          0         0         0         0         0         0         0   \n",
       "11119         0         0         0         0         0         0         0   \n",
       "1300          0         0         0         0         0         0         0   \n",
       "3543          0         0         0         0         0         0         0   \n",
       "\n",
       "       team_WSB  attended_college_False  attended_college_True  \n",
       "6246          0                       1                      0  \n",
       "1213          0                       0                      1  \n",
       "1445          0                       0                      1  \n",
       "4290          0                       0                      1  \n",
       "11119         0                       0                      1  \n",
       "1300          0                       0                      1  \n",
       "3543          0                       0                      1  "
      ]
     },
     "execution_count": 3762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>season_end</th>\n",
       "      <th>season_start</th>\n",
       "      <th>height_in_inches</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>FTr</th>\n",
       "      <th>ORB%</th>\n",
       "      <th>DRB%</th>\n",
       "      <th>TRB%</th>\n",
       "      <th>AST%</th>\n",
       "      <th>STL%</th>\n",
       "      <th>BLK%</th>\n",
       "      <th>TOV%</th>\n",
       "      <th>USG%</th>\n",
       "      <th>OWS</th>\n",
       "      <th>DWS</th>\n",
       "      <th>WS</th>\n",
       "      <th>WS/48</th>\n",
       "      <th>OBPM</th>\n",
       "      <th>DBPM</th>\n",
       "      <th>BPM</th>\n",
       "      <th>VORP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>attended_high_school_False</th>\n",
       "      <th>attended_high_school_True</th>\n",
       "      <th>drafted_player_False</th>\n",
       "      <th>drafted_player_True</th>\n",
       "      <th>shoots_Left</th>\n",
       "      <th>shoots_Left Right</th>\n",
       "      <th>shoots_Right</th>\n",
       "      <th>position_C</th>\n",
       "      <th>position_PF</th>\n",
       "      <th>position_PG</th>\n",
       "      <th>position_SF</th>\n",
       "      <th>position_SG</th>\n",
       "      <th>team_ATL</th>\n",
       "      <th>team_BOS</th>\n",
       "      <th>team_BRK</th>\n",
       "      <th>team_CHA</th>\n",
       "      <th>team_CHH</th>\n",
       "      <th>team_CHI</th>\n",
       "      <th>team_CHO</th>\n",
       "      <th>team_CLE</th>\n",
       "      <th>team_DAL</th>\n",
       "      <th>team_DEN</th>\n",
       "      <th>team_DET</th>\n",
       "      <th>team_GSW</th>\n",
       "      <th>team_HOU</th>\n",
       "      <th>team_IND</th>\n",
       "      <th>team_KCK</th>\n",
       "      <th>team_LAC</th>\n",
       "      <th>team_LAL</th>\n",
       "      <th>team_MEM</th>\n",
       "      <th>team_MIA</th>\n",
       "      <th>team_MIL</th>\n",
       "      <th>team_MIN</th>\n",
       "      <th>team_NJN</th>\n",
       "      <th>team_NOH</th>\n",
       "      <th>team_NOK</th>\n",
       "      <th>team_NOP</th>\n",
       "      <th>team_NYK</th>\n",
       "      <th>team_OKC</th>\n",
       "      <th>team_ORL</th>\n",
       "      <th>team_PHI</th>\n",
       "      <th>team_PHO</th>\n",
       "      <th>team_POR</th>\n",
       "      <th>team_SAC</th>\n",
       "      <th>team_SAS</th>\n",
       "      <th>team_SEA</th>\n",
       "      <th>team_TOR</th>\n",
       "      <th>team_UTA</th>\n",
       "      <th>team_VAN</th>\n",
       "      <th>team_WAS</th>\n",
       "      <th>team_WSB</th>\n",
       "      <th>attended_college_False</th>\n",
       "      <th>attended_college_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.223300e+04</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.00000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "      <td>12233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.031394e+06</td>\n",
       "      <td>2003.357884</td>\n",
       "      <td>2002.357884</td>\n",
       "      <td>79.030410</td>\n",
       "      <td>217.824001</td>\n",
       "      <td>26.835200</td>\n",
       "      <td>52.998856</td>\n",
       "      <td>25.674569</td>\n",
       "      <td>1250.241968</td>\n",
       "      <td>12.748005</td>\n",
       "      <td>0.509993</td>\n",
       "      <td>0.181456</td>\n",
       "      <td>0.313901</td>\n",
       "      <td>6.075307</td>\n",
       "      <td>13.993156</td>\n",
       "      <td>10.035119</td>\n",
       "      <td>13.009992</td>\n",
       "      <td>1.633827</td>\n",
       "      <td>1.513083</td>\n",
       "      <td>14.484821</td>\n",
       "      <td>18.761390</td>\n",
       "      <td>1.335151</td>\n",
       "      <td>1.264236</td>\n",
       "      <td>2.599722</td>\n",
       "      <td>0.073276</td>\n",
       "      <td>-1.519186</td>\n",
       "      <td>-0.421025</td>\n",
       "      <td>-1.939990</td>\n",
       "      <td>0.599681</td>\n",
       "      <td>193.312679</td>\n",
       "      <td>422.900924</td>\n",
       "      <td>0.440695</td>\n",
       "      <td>27.813946</td>\n",
       "      <td>78.608273</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>165.498733</td>\n",
       "      <td>344.292651</td>\n",
       "      <td>0.461290</td>\n",
       "      <td>0.471028</td>\n",
       "      <td>96.447642</td>\n",
       "      <td>127.966157</td>\n",
       "      <td>0.724607</td>\n",
       "      <td>62.749203</td>\n",
       "      <td>155.114363</td>\n",
       "      <td>217.863566</td>\n",
       "      <td>115.144609</td>\n",
       "      <td>40.730565</td>\n",
       "      <td>25.356004</td>\n",
       "      <td>74.43399</td>\n",
       "      <td>114.182130</td>\n",
       "      <td>510.886945</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.065233</td>\n",
       "      <td>0.866754</td>\n",
       "      <td>0.133246</td>\n",
       "      <td>0.083871</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.915638</td>\n",
       "      <td>0.204283</td>\n",
       "      <td>0.216382</td>\n",
       "      <td>0.196599</td>\n",
       "      <td>0.189978</td>\n",
       "      <td>0.192757</td>\n",
       "      <td>0.035233</td>\n",
       "      <td>0.033434</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.012752</td>\n",
       "      <td>0.014224</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.036786</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>0.035314</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.034906</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.035233</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.030410</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.034333</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.031145</td>\n",
       "      <td>0.034006</td>\n",
       "      <td>0.035560</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>0.026976</td>\n",
       "      <td>0.031717</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.024115</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>0.111910</td>\n",
       "      <td>0.888090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.922321e+06</td>\n",
       "      <td>8.841971</td>\n",
       "      <td>8.841971</td>\n",
       "      <td>3.679179</td>\n",
       "      <td>27.400892</td>\n",
       "      <td>4.091276</td>\n",
       "      <td>25.389561</td>\n",
       "      <td>29.195356</td>\n",
       "      <td>909.889058</td>\n",
       "      <td>5.610502</td>\n",
       "      <td>0.086114</td>\n",
       "      <td>0.193867</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>4.535169</td>\n",
       "      <td>6.297344</td>\n",
       "      <td>4.851464</td>\n",
       "      <td>9.445402</td>\n",
       "      <td>0.935218</td>\n",
       "      <td>1.647286</td>\n",
       "      <td>6.141772</td>\n",
       "      <td>5.212353</td>\n",
       "      <td>1.992772</td>\n",
       "      <td>1.195955</td>\n",
       "      <td>2.882877</td>\n",
       "      <td>0.088694</td>\n",
       "      <td>3.483871</td>\n",
       "      <td>2.085438</td>\n",
       "      <td>4.245327</td>\n",
       "      <td>1.314281</td>\n",
       "      <td>172.340900</td>\n",
       "      <td>367.296754</td>\n",
       "      <td>0.089079</td>\n",
       "      <td>42.852526</td>\n",
       "      <td>113.235908</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>155.173812</td>\n",
       "      <td>313.580979</td>\n",
       "      <td>0.092323</td>\n",
       "      <td>0.090687</td>\n",
       "      <td>102.786317</td>\n",
       "      <td>130.386830</td>\n",
       "      <td>0.138268</td>\n",
       "      <td>64.354985</td>\n",
       "      <td>139.585459</td>\n",
       "      <td>197.581579</td>\n",
       "      <td>136.371164</td>\n",
       "      <td>36.603116</td>\n",
       "      <td>34.689186</td>\n",
       "      <td>63.50923</td>\n",
       "      <td>77.476732</td>\n",
       "      <td>461.198190</td>\n",
       "      <td>0.246947</td>\n",
       "      <td>0.246947</td>\n",
       "      <td>0.339854</td>\n",
       "      <td>0.339854</td>\n",
       "      <td>0.277206</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.277941</td>\n",
       "      <td>0.403194</td>\n",
       "      <td>0.411794</td>\n",
       "      <td>0.397443</td>\n",
       "      <td>0.392299</td>\n",
       "      <td>0.394480</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.083070</td>\n",
       "      <td>0.112209</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.179350</td>\n",
       "      <td>0.061868</td>\n",
       "      <td>0.190639</td>\n",
       "      <td>0.188243</td>\n",
       "      <td>0.180832</td>\n",
       "      <td>0.178924</td>\n",
       "      <td>0.184581</td>\n",
       "      <td>0.173496</td>\n",
       "      <td>0.183548</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>0.190639</td>\n",
       "      <td>0.176776</td>\n",
       "      <td>0.143419</td>\n",
       "      <td>0.180621</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.176125</td>\n",
       "      <td>0.171718</td>\n",
       "      <td>0.104856</td>\n",
       "      <td>0.051081</td>\n",
       "      <td>0.080105</td>\n",
       "      <td>0.182091</td>\n",
       "      <td>0.106744</td>\n",
       "      <td>0.173717</td>\n",
       "      <td>0.181253</td>\n",
       "      <td>0.185197</td>\n",
       "      <td>0.180832</td>\n",
       "      <td>0.179987</td>\n",
       "      <td>0.186219</td>\n",
       "      <td>0.150076</td>\n",
       "      <td>0.162020</td>\n",
       "      <td>0.175254</td>\n",
       "      <td>0.081106</td>\n",
       "      <td>0.153413</td>\n",
       "      <td>0.106369</td>\n",
       "      <td>0.315269</td>\n",
       "      <td>0.315269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.853000e+03</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>-2.519000</td>\n",
       "      <td>-73.800000</td>\n",
       "      <td>-19.500000</td>\n",
       "      <td>-86.700000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.124350e+05</td>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>-1.600000</td>\n",
       "      <td>-3.700000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.450000e+06</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1137.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.765000e+06</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1991.000000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.359000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>782.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.096345e+07</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3533.000000</td>\n",
       "      <td>88.300000</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.300000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>1.084000</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>978.000000</td>\n",
       "      <td>2173.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>916.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>894.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>464.00000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>2832.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             salary    season_end  season_start  height_in_inches  \\\n",
       "count  1.223300e+04  12233.000000  12233.000000      12233.000000   \n",
       "mean   3.031394e+06   2003.357884   2002.357884         79.030410   \n",
       "std    3.922321e+06      8.841971      8.841971          3.679179   \n",
       "min    2.853000e+03   1985.000000   1984.000000         63.000000   \n",
       "25%    6.124350e+05   1996.000000   1995.000000         76.000000   \n",
       "50%    1.450000e+06   2004.000000   2003.000000         80.000000   \n",
       "75%    3.765000e+06   2011.000000   2010.000000         82.000000   \n",
       "max    3.096345e+07   2017.000000   2016.000000         91.000000   \n",
       "\n",
       "             weight           age             G            GS            MP  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean     217.824001     26.835200     52.998856     25.674569   1250.241968   \n",
       "std       27.400892      4.091276     25.389561     29.195356    909.889058   \n",
       "min      133.000000     18.000000      1.000000      0.000000      0.000000   \n",
       "25%      195.000000     24.000000     31.000000      1.000000    423.000000   \n",
       "50%      220.000000     26.000000     60.000000     11.000000   1137.000000   \n",
       "75%      237.000000     30.000000     76.000000     51.000000   1991.000000   \n",
       "max      360.000000     42.000000     82.000000     82.000000   3533.000000   \n",
       "\n",
       "                PER           TS%          3PAr           FTr          ORB%  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean      12.748005      0.509993      0.181456      0.313901      6.075307   \n",
       "std        5.610502      0.086114      0.193867      0.221500      4.535169   \n",
       "min      -90.600000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       10.100000      0.480000      0.007000      0.197000      2.500000   \n",
       "50%       12.900000      0.520000      0.112000      0.284000      5.100000   \n",
       "75%       15.700000      0.553000      0.322000      0.387000      9.000000   \n",
       "max       88.300000      1.136000      1.000000      6.000000    100.000000   \n",
       "\n",
       "               DRB%          TRB%          AST%          STL%          BLK%  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean      13.993156     10.035119     13.009992      1.633827      1.513083   \n",
       "std        6.297344      4.851464      9.445402      0.935218      1.647286   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        9.300000      6.200000      6.300000      1.100000      0.400000   \n",
       "50%       13.100000      9.200000     10.200000      1.500000      1.000000   \n",
       "75%       18.100000     13.500000     17.600000      2.000000      2.100000   \n",
       "max      100.000000    100.000000     78.500000     17.300000     26.300000   \n",
       "\n",
       "               TOV%          USG%           OWS           DWS            WS  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean      14.484821     18.761390      1.335151      1.264236      2.599722   \n",
       "std        6.141772      5.212353      1.992772      1.195955      2.882877   \n",
       "min        0.000000      0.000000     -3.300000     -0.600000     -2.100000   \n",
       "25%       11.100000     15.300000      0.000000      0.300000      0.300000   \n",
       "50%       13.800000     18.500000      0.600000      0.900000      1.700000   \n",
       "75%       16.900000     22.000000      2.100000      1.900000      4.000000   \n",
       "max      100.000000     88.300000     14.800000      9.100000     20.300000   \n",
       "\n",
       "              WS/48          OBPM          DBPM           BPM          VORP  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.073276     -1.519186     -0.421025     -1.939990      0.599681   \n",
       "std        0.088694      3.483871      2.085438      4.245327      1.314281   \n",
       "min       -2.519000    -73.800000    -19.500000    -86.700000     -2.600000   \n",
       "25%        0.040000     -3.100000     -1.600000     -3.700000     -0.200000   \n",
       "50%        0.082000     -1.300000     -0.400000     -1.500000      0.100000   \n",
       "75%        0.119000      0.500000      0.800000      0.500000      1.000000   \n",
       "max        1.084000     31.900000     17.100000     26.600000     12.400000   \n",
       "\n",
       "                 FG           FGA           FG%            3P           3PA  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean     193.312679    422.900924      0.440695     27.813946     78.608273   \n",
       "std      172.340900    367.296754      0.089079     42.852526    113.235908   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       49.000000    116.000000      0.405000      0.000000      2.000000   \n",
       "50%      148.000000    330.000000      0.443000      5.000000     21.000000   \n",
       "75%      296.000000    646.000000      0.484000     41.000000    119.000000   \n",
       "max      978.000000   2173.000000      1.000000    402.000000    886.000000   \n",
       "\n",
       "                3P%            2P           2PA           2P%          eFG%  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.263368    165.498733    344.292651      0.461290      0.471028   \n",
       "std        0.155871    155.173812    313.580979      0.092323      0.090687   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.200000     39.000000     88.000000      0.428000      0.440000   \n",
       "50%        0.273000    120.000000    257.000000      0.468000      0.479000   \n",
       "75%        0.359000    249.000000    515.000000      0.503000      0.513000   \n",
       "max        1.000000    802.000000   1685.000000      1.000000      1.500000   \n",
       "\n",
       "                 FT           FTA           FT%           ORB           DRB  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean      96.447642    127.966157      0.724607     62.749203    155.114363   \n",
       "std      102.786317    130.386830      0.138268     64.354985    139.585459   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       20.000000     29.000000      0.667000     15.000000     45.000000   \n",
       "50%       63.000000     87.000000      0.746000     41.000000    122.000000   \n",
       "75%      138.000000    187.000000      0.812000     91.000000    224.000000   \n",
       "max      756.000000    916.000000      1.000000    443.000000    894.000000   \n",
       "\n",
       "                TRB           AST           STL           BLK          TOV  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.00000   \n",
       "mean     217.863566    115.144609     40.730565     25.356004     74.43399   \n",
       "std      197.581579    136.371164     36.603116     34.689186     63.50923   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
       "25%       63.000000     21.000000     11.000000      4.000000     22.00000   \n",
       "50%      168.000000     68.000000     32.000000     13.000000     59.00000   \n",
       "75%      313.000000    156.000000     61.000000     32.000000    111.00000   \n",
       "max     1258.000000    991.000000    301.000000    456.000000    464.00000   \n",
       "\n",
       "                 PF           PTS  attended_high_school_False  \\\n",
       "count  12233.000000  12233.000000                12233.000000   \n",
       "mean     114.182130    510.886945                    0.934767   \n",
       "std       77.476732    461.198190                    0.246947   \n",
       "min        0.000000      0.000000                    0.000000   \n",
       "25%       46.000000    129.000000                    1.000000   \n",
       "50%      110.000000    390.000000                    1.000000   \n",
       "75%      173.000000    782.000000                    1.000000   \n",
       "max      371.000000   2832.000000                    1.000000   \n",
       "\n",
       "       attended_high_school_True  drafted_player_False  drafted_player_True  \\\n",
       "count               12233.000000          12233.000000         12233.000000   \n",
       "mean                    0.065233              0.866754             0.133246   \n",
       "std                     0.246947              0.339854             0.339854   \n",
       "min                     0.000000              0.000000             0.000000   \n",
       "25%                     0.000000              1.000000             0.000000   \n",
       "50%                     0.000000              1.000000             0.000000   \n",
       "75%                     0.000000              1.000000             0.000000   \n",
       "max                     1.000000              1.000000             1.000000   \n",
       "\n",
       "        shoots_Left  shoots_Left Right  shoots_Right    position_C  \\\n",
       "count  12233.000000       12233.000000  12233.000000  12233.000000   \n",
       "mean       0.083871           0.000490      0.915638      0.204283   \n",
       "std        0.277206           0.022142      0.277941      0.403194   \n",
       "min        0.000000           0.000000      0.000000      0.000000   \n",
       "25%        0.000000           0.000000      1.000000      0.000000   \n",
       "50%        0.000000           0.000000      1.000000      0.000000   \n",
       "75%        0.000000           0.000000      1.000000      0.000000   \n",
       "max        1.000000           1.000000      1.000000      1.000000   \n",
       "\n",
       "        position_PF   position_PG   position_SF   position_SG      team_ATL  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.216382      0.196599      0.189978      0.192757      0.035233   \n",
       "std        0.411794      0.397443      0.392299      0.394480      0.184375   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_BOS      team_BRK      team_CHA      team_CHH      team_CHI  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.033434      0.006948      0.012752      0.014224      0.033271   \n",
       "std        0.179775      0.083070      0.112209      0.118417      0.179350   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_CHO      team_CLE      team_DAL      team_DEN      team_DET  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.003842      0.037767      0.036786      0.033843      0.033107   \n",
       "std        0.061868      0.190639      0.188243      0.180832      0.178924   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_GSW      team_HOU      team_IND      team_KCK      team_LAC  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.035314      0.031064      0.034906      0.000981      0.037767   \n",
       "std        0.184581      0.173496      0.183548      0.031306      0.190639   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_LAL      team_MEM      team_MIA      team_MIL      team_MIN  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.032290      0.021009      0.033761      0.035233      0.032044   \n",
       "std        0.176776      0.143419      0.180621      0.184375      0.176125   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_NJN      team_NOH      team_NOK      team_NOP      team_NYK  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.030410      0.011117      0.002616      0.006458      0.034333   \n",
       "std        0.171718      0.104856      0.051081      0.080105      0.182091   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_OKC      team_ORL      team_PHI      team_PHO      team_POR  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.011526      0.031145      0.034006      0.035560      0.033843   \n",
       "std        0.106744      0.173717      0.181253      0.185197      0.180832   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_SAC      team_SAS      team_SEA      team_TOR      team_UTA  \\\n",
       "count  12233.000000  12233.000000  12233.000000  12233.000000  12233.000000   \n",
       "mean       0.033516      0.035968      0.023052      0.026976      0.031717   \n",
       "std        0.179987      0.186219      0.150076      0.162020      0.175254   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           team_VAN      team_WAS      team_WSB  attended_college_False  \\\n",
       "count  12233.000000  12233.000000  12233.000000            12233.000000   \n",
       "mean       0.006621      0.024115      0.011444                0.111910   \n",
       "std        0.081106      0.153413      0.106369                0.315269   \n",
       "min        0.000000      0.000000      0.000000                0.000000   \n",
       "25%        0.000000      0.000000      0.000000                0.000000   \n",
       "50%        0.000000      0.000000      0.000000                0.000000   \n",
       "75%        0.000000      0.000000      0.000000                0.000000   \n",
       "max        1.000000      1.000000      1.000000                1.000000   \n",
       "\n",
       "       attended_college_True  \n",
       "count           12233.000000  \n",
       "mean                0.888090  \n",
       "std                 0.315269  \n",
       "min                 0.000000  \n",
       "25%                 1.000000  \n",
       "50%                 1.000000  \n",
       "75%                 1.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 3763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12233 entries, 0 to 12232\n",
      "Columns: 104 entries, salary to attended_college_True\n",
      "dtypes: float64(46), int64(5), uint8(53)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['salary', 'season_end', 'season_start', 'height_in_inches', 'weight',\n",
       "       'age', 'G', 'GS', 'MP', 'PER',\n",
       "       ...\n",
       "       'team_SAC', 'team_SAS', 'team_SEA', 'team_TOR', 'team_UTA', 'team_VAN',\n",
       "       'team_WAS', 'team_WSB', 'attended_college_False',\n",
       "       'attended_college_True'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 3765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS</th>\n",
       "      <td>0.426963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VORP</th>\n",
       "      <td>0.415971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>0.414596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRB</th>\n",
       "      <td>0.408879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGA</th>\n",
       "      <td>0.400793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG</th>\n",
       "      <td>0.400359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWS</th>\n",
       "      <td>0.395474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0.389620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTA</th>\n",
       "      <td>0.385824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          salary\n",
       "salary  1.000000\n",
       "WS      0.426963\n",
       "VORP    0.415971\n",
       "PTS     0.414596\n",
       "DRB     0.408879\n",
       "FGA     0.400793\n",
       "FG      0.400359\n",
       "OWS     0.395474\n",
       "FT      0.389620\n",
       "FTA     0.385824"
      ]
     },
     "execution_count": 3766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations_df = pd.DataFrame(abs(df.corr().salary).sort_values(ascending = False))\n",
    "correlations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3767,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_correlations = [\n",
    "    \"WS\",\n",
    "    \"VORP\",\n",
    "    \"PTS\",\n",
    "    \"DRB\",\n",
    "    \"FGA\", \n",
    "    \"FG\",\n",
    "    \"OWS\", \n",
    "    \"FT\",\n",
    "    \"FTA\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS</th>\n",
       "      <td>0.426963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VORP</th>\n",
       "      <td>0.415971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>0.414596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRB</th>\n",
       "      <td>0.408879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGA</th>\n",
       "      <td>0.400793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG</th>\n",
       "      <td>0.400359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWS</th>\n",
       "      <td>0.395474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0.389620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTA</th>\n",
       "      <td>0.385824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>0.385299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_start</th>\n",
       "      <td>0.381525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_end</th>\n",
       "      <td>0.381525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DWS</th>\n",
       "      <td>0.370328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2P</th>\n",
       "      <td>0.359798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>0.358161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRB</th>\n",
       "      <td>0.357673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2PA</th>\n",
       "      <td>0.355068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOV</th>\n",
       "      <td>0.338252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.328980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                salary\n",
       "salary        1.000000\n",
       "WS            0.426963\n",
       "VORP          0.415971\n",
       "PTS           0.414596\n",
       "DRB           0.408879\n",
       "FGA           0.400793\n",
       "FG            0.400359\n",
       "OWS           0.395474\n",
       "FT            0.389620\n",
       "FTA           0.385824\n",
       "GS            0.385299\n",
       "season_start  0.381525\n",
       "season_end    0.381525\n",
       "DWS           0.370328\n",
       "2P            0.359798\n",
       "MP            0.358161\n",
       "TRB           0.357673\n",
       "2PA           0.355068\n",
       "TOV           0.338252\n",
       "PER           0.328980"
      ]
     },
     "execution_count": 3768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3769,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3770,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = split_df.drop(columns = [\"salary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Ten Correlation Features\n",
    "\n",
    "Die zuvor berechneten top 10 Correlation Features zu nehmen würde in einem schlechteren _Linear Regression Score_ resultieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[top_10_correlations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 Linear Regression Score Features\n",
    "\n",
    "Die später berechneten top 30 Linear Regression Features zu nehmen würde in einem schlechteren _Linear Regression Score_ resultieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntop_30 = [\\n    'TRB', 'PTS', 'DRB', 'drafted_player_False', 'drafted_player_True',\\n    'FG', 'FGA', '2PA', 'attended_college_False',\\n    'attended_college_True', 'ORB', 'FT', '3PA',\\n    'attended_high_school_False', 'attended_high_school_True', '3P',\\n    '2P', 'position_PF', 'shoots_Right', 'shoots_Left', 'position_C',\\n    'position_PG', 'position_SF', 'position_SG', 'team_LAC',\\n    'team_CLE', 'team_PHO', 'team_IND', 'team_GSW', 'team_NYK'\\n]\\nX = X[top_30]\\n\""
      ]
     },
     "execution_count": 3772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "top_30 = [\n",
    "    'TRB', 'PTS', 'DRB', 'drafted_player_False', 'drafted_player_True',\n",
    "    'FG', 'FGA', '2PA', 'attended_college_False',\n",
    "    'attended_college_True', 'ORB', 'FT', '3PA',\n",
    "    'attended_high_school_False', 'attended_high_school_True', '3P',\n",
    "    '2P', 'position_PF', 'shoots_Right', 'shoots_Left', 'position_C',\n",
    "    'position_PG', 'position_SF', 'position_SG', 'team_LAC',\n",
    "    'team_CLE', 'team_PHO', 'team_IND', 'team_GSW', 'team_NYK'\n",
    "]\n",
    "X = X[top_30]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausschließlich Saisonstatistiken \n",
    "\n",
    "Die ausschließliche Verwendung der Saisonstatistiken würde in einem schlechteren _Linear Regression Score_ resultieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3773,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = [\n",
    "    \"3P%\",\n",
    "    \"FT%\",                   \n",
    "    \"2P%\",                      \n",
    "    \"FTr\",                       \n",
    "    \"FG%\",                     \n",
    "    \"eFG%\",                  \n",
    "    \"3PAr\",                   \n",
    "    \"TS%\",                    \n",
    "    \"TOV%\",                  \n",
    "    \"ORB%\",                      \n",
    "    \"TRB%\",                      \n",
    "    \"DRB%\",                      \n",
    "    \"WS/48\",                     \n",
    "    \"BLK%\",                       \n",
    "    \"PER\",                        \n",
    "    \"STL%\",                     \n",
    "    \"USG%\",                      \n",
    "    \"AST%\",\n",
    "    \"MP\",                         \n",
    "    \"GS\",                         \n",
    "    \"G\",                                                           \n",
    "    \"PTS\",                        \n",
    "    \"PF\",                         \n",
    "    \"OWS\",                        \n",
    "    \"TOV\",                        \n",
    "    \"BLK\",                        \n",
    "    \"STL\",                        \n",
    "    \"AST\",                        \n",
    "    \"TRB\",                        \n",
    "    \"DRB\",                        \n",
    "    \"ORB\",                        \n",
    "    \"FTA\",                        \n",
    "    \"FT\",                         \n",
    "    \"2PA\",                        \n",
    "    \"2P\",                         \n",
    "    \"3PA\",                        \n",
    "    \"3P\",                         \n",
    "    \"FGA\",                        \n",
    "    \"FG\",                         \n",
    "    \"VORP\",                       \n",
    "    \"BPM\",                        \n",
    "    \"DBPM\",                       \n",
    "    \"OBPM\",                       \n",
    "    \"WS\",                         \n",
    "    \"DWS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3774,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[statistics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verwerfen von Features\n",
    "\n",
    "Das Verwerfen der folgenden Features führt zu leichten Verbesserungen des _Linear Regression Score_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3775,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns = [\"season_start\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3776,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns = [\"3P%\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3777,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = split_df[\"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ((X-X.min())/(X.max()-X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3779,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3780,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With StandardScaler\n",
    "X_train_linear = X_train_std\n",
    "X_test_linear = X_test_std\n",
    "\n",
    "# Without StandardScaler\n",
    "# X_train_linear = X_train\n",
    "# X_test_linear = X_test\n",
    "\n",
    "y_train_linear = y_train\n",
    "y_test_linear = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3782,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train_linear, y_train_linear)\n",
    "y_pred = model.predict(X_test_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3049754.12766144\n",
      "[ 1.38585438e+06  1.60205532e+05  2.85769512e+05  1.03535252e+06\n",
      " -2.29149879e+05  5.51319043e+05 -9.32846701e+05  1.00224174e+05\n",
      "  4.46686035e+04 -5.81012187e+05 -2.00744312e+04 -7.20844196e+05\n",
      " -3.93138278e+05  7.93564831e+05  1.68353727e+05 -9.51419778e+04\n",
      " -8.47836047e+04  1.58460828e+05  4.85721963e+05  2.27386398e+05\n",
      "  5.37086960e+05  6.32677807e+04 -6.88064073e+05  7.64761538e+05\n",
      "  2.85196789e+03  5.64549805e+05 -2.51275782e+05 -3.33687253e+17\n",
      "  1.51325563e+17  2.75622649e+05 -1.09666020e+17 -4.66677761e+16\n",
      " -1.65543422e+17 -1.29485664e+17 -6.79760000e+04 -4.61764000e+05\n",
      " -1.54368626e+17  9.18311500e+05 -3.29140000e+04  2.52400532e+17\n",
      "  5.48563767e+17 -7.75702900e+17  4.84533875e+05 -4.70312000e+05\n",
      "  2.42412000e+05 -4.63136000e+05 -5.62048000e+05  6.91508919e+17\n",
      " -5.42138762e+17 -5.42138762e+17  5.20742658e+17  5.20742658e+17\n",
      "  3.81251313e+17  3.38805492e+16  3.82500694e+17 -3.45880874e+17\n",
      " -3.54131682e+17 -3.41534369e+17 -3.39589513e+17 -3.39098631e+17\n",
      "  2.62870672e+16  2.66532138e+16  1.26483452e+16  1.62614461e+16\n",
      "  1.74616108e+16  2.63791525e+16  8.66794325e+15  2.78048747e+16\n",
      "  2.68341300e+16  2.65165911e+16  2.56792613e+16  2.72361165e+16\n",
      "  2.53931172e+16  2.72361165e+16  5.34430785e+15  2.80200446e+16\n",
      "  2.48587737e+16  2.11606645e+16  2.62870672e+16  2.69688971e+16\n",
      "  2.60552172e+16  2.49568925e+16  1.55433930e+16  7.55291226e+15\n",
      "  1.19180720e+16  2.71473824e+16  1.52961801e+16  2.57265994e+16\n",
      "  2.63791525e+16  2.77616063e+16  2.66532138e+16  2.61482403e+16\n",
      "  2.69240615e+16  2.23027703e+16  2.30653518e+16  2.53931172e+16\n",
      "  1.12533721e+16  2.17969502e+16  1.50447158e+16 -2.21988258e+16\n",
      " -2.21988258e+16]\n"
     ]
    }
   ],
   "source": [
    "# print the coefficients\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WS</th>\n",
       "      <td>0.426963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VORP</th>\n",
       "      <td>0.415971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>0.414596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRB</th>\n",
       "      <td>0.408879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_MIN</th>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_NOK</th>\n",
       "      <td>0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_DET</th>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_CLE</th>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team_IND</th>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            salary\n",
       "salary    1.000000\n",
       "WS        0.426963\n",
       "VORP      0.415971\n",
       "PTS       0.414596\n",
       "DRB       0.408879\n",
       "...            ...\n",
       "team_MIN  0.001989\n",
       "team_NOK  0.001679\n",
       "team_DET  0.000843\n",
       "team_CLE  0.000121\n",
       "team_IND  0.000014\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 3784,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(abs(df.corr().salary).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3785,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(X_train.columns, model.coef_))\n",
    "data = pd.DataFrame(zipped, columns=['feature', 'coef'])\n",
    "data = data.reindex(data.coef.abs().sort_values(ascending = False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>TRB</td>\n",
       "      <td>-7.757029e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PTS</td>\n",
       "      <td>6.915089e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DRB</td>\n",
       "      <td>5.485638e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>attended_high_school_True</td>\n",
       "      <td>-5.421388e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>attended_high_school_False</td>\n",
       "      <td>-5.421388e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>drafted_player_False</td>\n",
       "      <td>5.207427e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>drafted_player_True</td>\n",
       "      <td>5.207427e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>shoots_Right</td>\n",
       "      <td>3.825007e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>shoots_Left</td>\n",
       "      <td>3.812513e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>position_PF</td>\n",
       "      <td>-3.541317e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>position_C</td>\n",
       "      <td>-3.458809e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>position_PG</td>\n",
       "      <td>-3.415344e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>position_SF</td>\n",
       "      <td>-3.395895e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>position_SG</td>\n",
       "      <td>-3.390986e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FG</td>\n",
       "      <td>-3.336873e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ORB</td>\n",
       "      <td>2.524005e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2P</td>\n",
       "      <td>-1.655434e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FT</td>\n",
       "      <td>-1.543686e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FGA</td>\n",
       "      <td>1.513256e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2PA</td>\n",
       "      <td>-1.294857e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3P</td>\n",
       "      <td>-1.096660e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3PA</td>\n",
       "      <td>-4.666778e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>shoots_Left Right</td>\n",
       "      <td>3.388055e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>team_LAC</td>\n",
       "      <td>2.802004e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>team_CLE</td>\n",
       "      <td>2.780487e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>team_PHO</td>\n",
       "      <td>2.776161e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>team_GSW</td>\n",
       "      <td>2.723612e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>team_IND</td>\n",
       "      <td>2.723612e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>team_NYK</td>\n",
       "      <td>2.714738e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>team_MIL</td>\n",
       "      <td>2.696890e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>team_SAS</td>\n",
       "      <td>2.692406e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>team_DAL</td>\n",
       "      <td>2.683413e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>team_BOS</td>\n",
       "      <td>2.665321e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>team_POR</td>\n",
       "      <td>2.665321e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>team_DEN</td>\n",
       "      <td>2.651659e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>team_CHI</td>\n",
       "      <td>2.637915e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>team_PHI</td>\n",
       "      <td>2.637915e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>team_MIA</td>\n",
       "      <td>2.628707e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>team_ATL</td>\n",
       "      <td>2.628707e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>team_SAC</td>\n",
       "      <td>2.614824e+16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature          coef\n",
       "41                         TRB -7.757029e+17\n",
       "47                         PTS  6.915089e+17\n",
       "40                         DRB  5.485638e+17\n",
       "49   attended_high_school_True -5.421388e+17\n",
       "48  attended_high_school_False -5.421388e+17\n",
       "50        drafted_player_False  5.207427e+17\n",
       "51         drafted_player_True  5.207427e+17\n",
       "54                shoots_Right  3.825007e+17\n",
       "52                 shoots_Left  3.812513e+17\n",
       "56                 position_PF -3.541317e+17\n",
       "55                  position_C -3.458809e+17\n",
       "57                 position_PG -3.415344e+17\n",
       "58                 position_SF -3.395895e+17\n",
       "59                 position_SG -3.390986e+17\n",
       "27                          FG -3.336873e+17\n",
       "39                         ORB  2.524005e+17\n",
       "32                          2P -1.655434e+17\n",
       "36                          FT -1.543686e+17\n",
       "28                         FGA  1.513256e+17\n",
       "33                         2PA -1.294857e+17\n",
       "30                          3P -1.096660e+17\n",
       "31                         3PA -4.666778e+16\n",
       "53           shoots_Left Right  3.388055e+16\n",
       "75                    team_LAC  2.802004e+16\n",
       "67                    team_CLE  2.780487e+16\n",
       "89                    team_PHO  2.776161e+16\n",
       "71                    team_GSW  2.723612e+16\n",
       "73                    team_IND  2.723612e+16\n",
       "85                    team_NYK  2.714738e+16\n",
       "79                    team_MIL  2.696890e+16\n",
       "92                    team_SAS  2.692406e+16\n",
       "68                    team_DAL  2.683413e+16\n",
       "61                    team_BOS  2.665321e+16\n",
       "90                    team_POR  2.665321e+16\n",
       "69                    team_DEN  2.651659e+16\n",
       "65                    team_CHI  2.637915e+16\n",
       "88                    team_PHI  2.637915e+16\n",
       "78                    team_MIA  2.628707e+16\n",
       "60                    team_ATL  2.628707e+16\n",
       "91                    team_SAC  2.614824e+16"
      ]
     },
     "execution_count": 3786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3787,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>team_CHO</td>\n",
       "      <td>8.667943e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>team_NOK</td>\n",
       "      <td>7.552912e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>team_KCK</td>\n",
       "      <td>5.344308e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>season_end</td>\n",
       "      <td>1.385854e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age</td>\n",
       "      <td>1.035353e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MP</td>\n",
       "      <td>-9.328467e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>FTA</td>\n",
       "      <td>9.183115e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TRB%</td>\n",
       "      <td>7.935648e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OBPM</td>\n",
       "      <td>7.647615e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORB%</td>\n",
       "      <td>-7.208442e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WS/48</td>\n",
       "      <td>-6.880641e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3PAr</td>\n",
       "      <td>-5.810122e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BPM</td>\n",
       "      <td>5.645498e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PF</td>\n",
       "      <td>-5.620480e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GS</td>\n",
       "      <td>5.513190e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DWS</td>\n",
       "      <td>5.370870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USG%</td>\n",
       "      <td>4.857220e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AST</td>\n",
       "      <td>4.845339e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>STL</td>\n",
       "      <td>-4.703120e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TOV</td>\n",
       "      <td>-4.631360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>eFG%</td>\n",
       "      <td>-4.617640e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DRB%</td>\n",
       "      <td>-3.931383e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weight</td>\n",
       "      <td>2.857695e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>FG%</td>\n",
       "      <td>2.756226e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>VORP</td>\n",
       "      <td>-2.512758e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BLK</td>\n",
       "      <td>2.424120e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>-2.291499e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OWS</td>\n",
       "      <td>2.273864e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AST%</td>\n",
       "      <td>1.683537e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>height_in_inches</td>\n",
       "      <td>1.602055e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOV%</td>\n",
       "      <td>1.584608e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PER</td>\n",
       "      <td>1.002242e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>STL%</td>\n",
       "      <td>-9.514198e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BLK%</td>\n",
       "      <td>-8.478360e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2P%</td>\n",
       "      <td>-6.797600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WS</td>\n",
       "      <td>6.326778e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TS%</td>\n",
       "      <td>4.466860e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>FT%</td>\n",
       "      <td>-3.291400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FTr</td>\n",
       "      <td>-2.007443e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DBPM</td>\n",
       "      <td>2.851968e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature          coef\n",
       "66          team_CHO  8.667943e+15\n",
       "83          team_NOK  7.552912e+15\n",
       "74          team_KCK  5.344308e+15\n",
       "0         season_end  1.385854e+06\n",
       "3                age  1.035353e+06\n",
       "6                 MP -9.328467e+05\n",
       "37               FTA  9.183115e+05\n",
       "13              TRB%  7.935648e+05\n",
       "23              OBPM  7.647615e+05\n",
       "11              ORB% -7.208442e+05\n",
       "22             WS/48 -6.880641e+05\n",
       "9               3PAr -5.810122e+05\n",
       "25               BPM  5.645498e+05\n",
       "46                PF -5.620480e+05\n",
       "5                 GS  5.513190e+05\n",
       "20               DWS  5.370870e+05\n",
       "18              USG%  4.857220e+05\n",
       "42               AST  4.845339e+05\n",
       "43               STL -4.703120e+05\n",
       "45               TOV -4.631360e+05\n",
       "35              eFG% -4.617640e+05\n",
       "12              DRB% -3.931383e+05\n",
       "2             weight  2.857695e+05\n",
       "29               FG%  2.756226e+05\n",
       "26              VORP -2.512758e+05\n",
       "44               BLK  2.424120e+05\n",
       "4                  G -2.291499e+05\n",
       "19               OWS  2.273864e+05\n",
       "14              AST%  1.683537e+05\n",
       "1   height_in_inches  1.602055e+05\n",
       "17              TOV%  1.584608e+05\n",
       "7                PER  1.002242e+05\n",
       "15              STL% -9.514198e+04\n",
       "16              BLK% -8.478360e+04\n",
       "34               2P% -6.797600e+04\n",
       "21                WS  6.326778e+04\n",
       "8                TS%  4.466860e+04\n",
       "38               FT% -3.291400e+04\n",
       "10               FTr -2.007443e+04\n",
       "24              DBPM  2.851968e+03"
      ]
     },
     "execution_count": 3787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.5143331429780994\n"
     ]
    }
   ],
   "source": [
    "print('coefficient of determination: {}'.format(model.score(X_test_linear, y_test_linear)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression score: 51.46%\n"
     ]
    }
   ],
   "source": [
    "linear_score = round(explained_variance_score(np.array(y_test_linear), y_pred) * 100, 2)\n",
    "print('linear regression score: {}%'.format(linear_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7159946649606.725\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(np.array(y_test_linear), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3791,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn = X_train_std\n",
    "X_test_knn = X_test_std\n",
    "\n",
    "y_train_knn = y_train\n",
    "y_test_knn = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3792,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [50, 75, 100, 125, 150, 175, 200]\n",
    "second = [100, 112, 125, 127, 150]\n",
    "third = [100, 106, 112, 119, 125]\n",
    "fourth = [111, 112, 113]\n",
    "fifth = [112, 113, 114, 115]\n",
    "sixth = [113]\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': sixth,\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3793,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    verbose = 1,\n",
    "    cv = 3,\n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:   24.8s remaining:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   25.3s finished\n"
     ]
    }
   ],
   "source": [
    "classifier_grid = classifier_grid.fit(X_train_knn, y_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 113, 'weights': 'distance'}"
      ]
     },
     "execution_count": 3795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024646168862859932"
      ]
     },
     "execution_count": 3796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.46"
      ]
     },
     "execution_count": 3797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(classifier_grid.best_score_ * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
       "                         'n_neighbors': [113],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 3798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_metric</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361010</td>\n",
       "      <td>0.037275</td>\n",
       "      <td>8.479400</td>\n",
       "      <td>0.842835</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>113</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 113, 'w...</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.355424</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>15.839344</td>\n",
       "      <td>0.559612</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>113</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'euclidean', 'n_neighbors': 113, 'w...</td>\n",
       "      <td>0.021230</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>0.021962</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.307032</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>7.994050</td>\n",
       "      <td>0.806290</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>113</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 113, 'w...</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>0.018668</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.323128</td>\n",
       "      <td>0.110557</td>\n",
       "      <td>12.658779</td>\n",
       "      <td>0.627495</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>113</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 113, 'w...</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.024646</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_metric  \\\n",
       "0       0.361010      0.037275         8.479400        0.842835    euclidean   \n",
       "1       0.355424      0.042956        15.839344        0.559612    euclidean   \n",
       "2       0.307032      0.053458         7.994050        0.806290    manhattan   \n",
       "3       0.323128      0.110557        12.658779        0.627495    manhattan   \n",
       "\n",
       "  param_n_neighbors param_weights  \\\n",
       "0               113       uniform   \n",
       "1               113      distance   \n",
       "2               113       uniform   \n",
       "3               113      distance   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'metric': 'euclidean', 'n_neighbors': 113, 'w...           0.010615   \n",
       "1  {'metric': 'euclidean', 'n_neighbors': 113, 'w...           0.021230   \n",
       "2  {'metric': 'manhattan', 'n_neighbors': 113, 'w...           0.013177   \n",
       "3  {'metric': 'manhattan', 'n_neighbors': 113, 'w...           0.023060   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.015739           0.013177         0.013177        0.002092   \n",
       "1           0.024890           0.021962         0.022694        0.001581   \n",
       "2           0.017204           0.018668         0.016349        0.002321   \n",
       "3           0.025256           0.025622         0.024646        0.001131   \n",
       "\n",
       "   rank_test_score  \n",
       "0                4  \n",
       "1                2  \n",
       "2                3  \n",
       "3                1  "
      ]
     },
     "execution_count": 3799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classifier_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/the-basics-knn-for-classification-and-regression-c1e8a6c955\n",
    "\n",
    "--> Letzter Absatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === === === === === === === === === ===\n",
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3804,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train_std\n",
    "X_test_nn = X_test_std\n",
    "\n",
    "y_train_nn = y_train\n",
    "y_test_nn = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3808,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = [\n",
    "    (1,),  (8,), (16,), (32,), (64,), (128,), (256,), (512,),\n",
    "    (1, 1),  (8, 8), (16, 16), (32, 32), (64, 64), (128, 128), (256, 256), (512, 512),\n",
    "    (1, 1, 1),  (8, 8, 8), (16, 16, 16), (32, 32, 32), (64, 64, 64), (128, 128, 128), (256, 256, 256), (512, 512, 512),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3805,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (1,),  (8,), (16,), (32,), (64,), (128,), (256,), (512,),\n",
    "        (1, 1),  (8, 8), (16, 16), (32, 32), (64, 64), (128, 128), (256, 256), (512, 512),\n",
    "        (1, 1, 1),  (8, 8, 8), (16, 16, 16), (32, 32, 32), (64, 64, 64), (128, 128, 128), (256, 256, 256), (512, 512, 512),\n",
    "    ],\n",
    "    'activation': ['tanh', 'relu', 'logistic', 'identity'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3806,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_fun=15000,\n",
       "                                     max_iter=200, momentum=0.9,\n",
       "                                     n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state...\n",
       "             param_grid={'activation': ['tanh', 'relu', 'logistic', 'identity'],\n",
       "                         'hidden_layer_sizes': [(1,), (8,), (16,), (32,), (64,),\n",
       "                                                (128,), (256,), (512,), (1, 1),\n",
       "                                                (8, 8), (16, 16), (32, 32),\n",
       "                                                (64, 64), (128, 128),\n",
       "                                                (256, 256), (512, 512),\n",
       "                                                (1, 1, 1), (8, 8, 8),\n",
       "                                                (16, 16, 16), (32, 32, 32),\n",
       "                                                (64, 64, 64), (128, 128, 128),\n",
       "                                                (256, 256, 256),\n",
       "                                                (512, 512, 512)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 3806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(max_iter=200)\n",
    "clf = GridSearchCV(mlp, parameter_space, cv=3, scoring='accuracy')\n",
    "clf.fit(X_train_nn, y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'logistic', 'hidden_layer_sizes': (32, 32)}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Best parameters found:\n",
    " {'activation': 'logistic', 'hidden_layer_sizes': (32, 32)}\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3809,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03038067349926794"
      ]
     },
     "execution_count": 3809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 473604,  845059, 1000000, ..., 1206600, 1000000, 2020200])"
      ]
     },
     "execution_count": 3813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_nn)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        2853       0.00      0.00      0.00         1\n",
      "        6140       0.00      0.00      0.00         1\n",
      "        8819       0.00      0.00      0.00         1\n",
      "        8950       0.00      0.00      0.00         1\n",
      "       15800       0.00      0.00      0.00         1\n",
      "       15982       0.00      0.00      0.00         1\n",
      "       17546       0.00      0.00      0.00         1\n",
      "       20000       0.00      0.00      0.00         1\n",
      "       20133       0.00      0.00      0.00         1\n",
      "       23852       0.00      0.00      0.00         1\n",
      "       24300       0.00      0.00      0.00         1\n",
      "       25000       0.00      0.00      0.00         3\n",
      "       26007       0.00      0.00      0.00         1\n",
      "       26316       0.00      0.00      0.00         1\n",
      "       28191       0.00      0.00      0.00         1\n",
      "       29843       0.00      0.00      0.00         2\n",
      "       30000       0.00      0.00      0.00         3\n",
      "       31969       0.00      0.00      0.00         2\n",
      "       34118       0.00      0.00      0.00         1\n",
      "       35000       0.00      0.00      0.00         2\n",
      "       35819       0.00      0.00      0.00         1\n",
      "       36643       0.00      0.00      0.00         1\n",
      "       37344       0.00      0.00      0.00         1\n",
      "       40588       0.00      0.00      0.00         1\n",
      "       42009       0.00      0.00      0.00         1\n",
      "       44748       0.00      0.00      0.00         1\n",
      "       44765       0.00      0.00      0.00         1\n",
      "       46642       0.00      0.00      0.00         1\n",
      "       48056       0.00      0.00      0.00         1\n",
      "       48559       0.00      0.00      0.00         1\n",
      "       49721       0.00      0.00      0.00         1\n",
      "       50000       0.00      0.00      0.00         4\n",
      "       51449       0.00      0.00      0.00         1\n",
      "       53834       0.00      0.00      0.00         1\n",
      "       53838       0.00      0.00      0.00         1\n",
      "       54410       0.00      0.00      0.00         1\n",
      "       55000       0.00      0.00      0.00         1\n",
      "       55402       0.00      0.00      0.00         1\n",
      "       55718       0.00      0.00      0.00         1\n",
      "       55722       0.00      0.00      0.00         1\n",
      "       58393       0.00      0.00      0.00         1\n",
      "       59686       0.00      0.00      0.00         1\n",
      "       61290       0.00      0.00      0.00         1\n",
      "       61433       0.00      0.00      0.00         1\n",
      "       61776       0.00      0.00      0.00         1\n",
      "       62552       0.00      0.00      0.00         1\n",
      "       63938       0.00      0.00      0.00         1\n",
      "       64028       0.00      0.00      0.00         1\n",
      "       64622       0.00      0.00      0.00         1\n",
      "       64978       0.00      0.00      0.00         1\n",
      "       65000       0.00      0.00      0.00         1\n",
      "       69518       0.00      0.00      0.00         1\n",
      "       70000       0.00      0.00      0.00         7\n",
      "       71736       0.00      0.00      0.00         1\n",
      "       75000       0.20      0.25      0.22         8\n",
      "       75615       0.00      0.00      0.00         1\n",
      "       76850       0.00      0.00      0.00         1\n",
      "       80000       0.00      0.00      0.00         2\n",
      "       80500       0.00      0.00      0.00         1\n",
      "       82979       0.00      0.00      0.00         1\n",
      "       83119       0.00      0.00      0.00         1\n",
      "       83708       0.00      0.00      0.00         1\n",
      "       84573       0.00      0.00      0.00         1\n",
      "       85000       0.00      0.00      0.00         1\n",
      "       86000       0.00      0.00      0.00         1\n",
      "       86052       0.00      0.00      0.00         1\n",
      "       86638       0.00      0.00      0.00         1\n",
      "       87406       0.00      0.00      0.00         1\n",
      "       88223       0.00      0.00      0.00         1\n",
      "       88324       0.00      0.00      0.00         1\n",
      "       88441       0.00      0.00      0.00         1\n",
      "       89101       0.00      0.00      0.00         1\n",
      "       89670       0.00      0.00      0.00         1\n",
      "       90000       0.00      0.00      0.00         1\n",
      "       91642       0.00      0.00      0.00         1\n",
      "       92338       0.00      0.00      0.00         1\n",
      "       92396       0.00      0.00      0.00         1\n",
      "       94000       0.00      0.00      0.00         1\n",
      "       95000       0.00      0.00      0.00         2\n",
      "       95600       0.00      0.00      0.00         1\n",
      "       96056       0.00      0.00      0.00         1\n",
      "       96100       0.00      0.00      0.00         1\n",
      "       96969       0.00      0.00      0.00         1\n",
      "       98637       0.00      0.00      0.00         1\n",
      "       99418       0.00      0.00      0.00         1\n",
      "      100000       0.02      0.05      0.03        22\n",
      "      101451       0.00      0.00      0.00         1\n",
      "      102824       0.00      0.00      0.00         1\n",
      "      103443       0.00      0.00      0.00         1\n",
      "      103992       0.00      0.00      0.00         1\n",
      "      105532       0.00      0.00      0.00         1\n",
      "      105696       0.00      0.00      0.00         1\n",
      "      107674       0.00      0.00      0.00         1\n",
      "      109750       0.00      0.00      0.00         1\n",
      "      110000       0.00      0.00      0.00         2\n",
      "      112130       0.00      0.00      0.00         1\n",
      "      112500       0.00      0.00      0.00         1\n",
      "      113400       0.00      0.00      0.00         1\n",
      "      114285       0.00      0.00      0.00         1\n",
      "      115000       0.00      0.00      0.00         5\n",
      "      115422       0.00      0.00      0.00         1\n",
      "      116768       0.00      0.00      0.00         1\n",
      "      117000       0.00      0.00      0.00         1\n",
      "      118000       0.00      0.00      0.00         1\n",
      "      118974       0.00      0.00      0.00         1\n",
      "      119462       0.00      0.00      0.00         1\n",
      "      119494       0.00      0.00      0.00         1\n",
      "      120000       0.00      0.00      0.00        11\n",
      "      120796       0.00      0.00      0.00         1\n",
      "      122625       0.00      0.00      0.00         1\n",
      "      124700       0.00      0.00      0.00         1\n",
      "      125000       0.00      0.00      0.00         8\n",
      "      125104       0.00      0.00      0.00         1\n",
      "      125562       0.00      0.00      0.00         1\n",
      "      126300       0.00      0.00      0.00         1\n",
      "      129000       0.00      0.00      0.00         1\n",
      "      130000       0.00      0.00      0.00        12\n",
      "      134000       0.00      0.00      0.00         1\n",
      "      134863       0.00      0.00      0.00         1\n",
      "      134956       0.00      0.00      0.00         1\n",
      "      135000       0.00      0.00      0.00         2\n",
      "      136509       0.00      0.00      0.00         1\n",
      "      137466       0.00      0.00      0.00         1\n",
      "      137500       0.00      0.00      0.00         1\n",
      "      138171       0.00      0.00      0.00         1\n",
      "      139500       0.00      0.00      0.00         1\n",
      "      140000       0.00      0.00      0.00        13\n",
      "      140350       0.00      0.00      0.00         1\n",
      "      143277       0.00      0.00      0.00         1\n",
      "      143860       0.00      0.00      0.00         1\n",
      "      144468       0.00      0.00      0.00         1\n",
      "      144867       0.00      0.00      0.00         1\n",
      "      145000       0.00      0.00      0.00         2\n",
      "      148238       0.00      0.00      0.00         1\n",
      "      150000       0.08      0.49      0.14        41\n",
      "      150566       0.00      0.00      0.00         1\n",
      "      151089       0.00      0.00      0.00         1\n",
      "      152900       0.00      0.00      0.00         1\n",
      "      155000       0.00      0.00      0.00         1\n",
      "      158000       0.00      0.00      0.00         2\n",
      "      158071       0.00      0.00      0.00         1\n",
      "      160000       0.00      0.00      0.00         1\n",
      "      167406       0.00      0.00      0.00         1\n",
      "      167500       0.00      0.00      0.00         1\n",
      "      168000       0.00      0.00      0.00         1\n",
      "      168035       0.00      0.00      0.00         1\n",
      "      169000       0.00      0.00      0.00         1\n",
      "      170000       0.00      0.00      0.00         2\n",
      "      172739       0.00      0.00      0.00         1\n",
      "      174598       0.00      0.00      0.00         1\n",
      "      175000       0.00      0.00      0.00         5\n",
      "      177830       0.00      0.00      0.00         1\n",
      "      178675       0.00      0.00      0.00         1\n",
      "      181100       0.00      0.00      0.00         2\n",
      "      182000       0.00      0.00      0.00         1\n",
      "      185000       0.00      0.00      0.00         1\n",
      "      186656       0.00      0.00      0.00         1\n",
      "      188558       0.00      0.00      0.00         1\n",
      "      190100       0.00      0.00      0.00         1\n",
      "      191456       0.00      0.00      0.00         1\n",
      "      191666       0.00      0.00      0.00         1\n",
      "      192228       0.00      0.00      0.00         2\n",
      "      192791       0.00      0.00      0.00         1\n",
      "      193802       0.00      0.00      0.00         1\n",
      "      200000       0.07      0.12      0.09        24\n",
      "      202300       0.00      0.00      0.00         1\n",
      "      205200       0.00      0.00      0.00         1\n",
      "      210000       0.00      0.00      0.00         4\n",
      "      211000       0.00      0.00      0.00         1\n",
      "      212000       0.00      0.00      0.00         1\n",
      "      214300       0.00      0.00      0.00         1\n",
      "      214500       0.00      0.00      0.00         1\n",
      "      215000       0.00      0.00      0.00         2\n",
      "      217301       0.00      0.00      0.00         1\n",
      "      218750       0.00      0.00      0.00         1\n",
      "      220000       0.00      0.00      0.00         8\n",
      "      222500       0.00      0.00      0.00         1\n",
      "      223000       0.00      0.00      0.00         1\n",
      "      225000       0.00      0.00      0.00        12\n",
      "      225341       0.00      0.00      0.00         1\n",
      "      228946       0.00      0.00      0.00         1\n",
      "      229059       0.00      0.00      0.00         1\n",
      "      230000       0.00      0.00      0.00         2\n",
      "      232500       0.00      0.00      0.00         1\n",
      "      235762       0.00      0.00      0.00         1\n",
      "      236457       0.00      0.00      0.00         1\n",
      "      239000       0.00      0.00      0.00         1\n",
      "      239767       0.00      0.00      0.00         1\n",
      "      240000       0.00      0.00      0.00         1\n",
      "      242000       0.00      0.00      0.00         5\n",
      "      242374       0.00      0.00      0.00         1\n",
      "      242640       0.00      0.00      0.00         1\n",
      "      242793       0.00      0.00      0.00         1\n",
      "      244000       0.00      0.00      0.00         1\n",
      "      245633       0.00      0.00      0.00         1\n",
      "      247000       0.00      0.00      0.00         1\n",
      "      247500       0.15      0.11      0.13        18\n",
      "      250000       0.01      0.07      0.01        14\n",
      "      251700       0.00      0.00      0.00         1\n",
      "      253499       0.00      0.00      0.00         1\n",
      "      255000       0.00      0.00      0.00         1\n",
      "      255054       0.00      0.00      0.00         1\n",
      "      257500       0.00      0.00      0.00         1\n",
      "      259204       0.00      0.00      0.00         1\n",
      "      260000       0.00      0.00      0.00         4\n",
      "      262000       0.00      0.00      0.00         2\n",
      "      264897       0.00      0.00      0.00         1\n",
      "      265000       0.00      0.00      0.00         3\n",
      "      267111       0.00      0.00      0.00         1\n",
      "      267500       0.00      0.00      0.00         1\n",
      "      268974       0.00      0.00      0.00         1\n",
      "      269000       0.00      0.00      0.00         2\n",
      "      270000       0.00      0.00      0.00         3\n",
      "      270436       0.00      0.00      0.00         1\n",
      "      271666       0.00      0.00      0.00         1\n",
      "      272250       0.00      0.00      0.00        18\n",
      "      272500       0.00      0.00      0.00         1\n",
      "      275000       0.00      0.00      0.00        10\n",
      "      275404       0.00      0.00      0.00         1\n",
      "      276827       0.00      0.00      0.00         1\n",
      "      279415       0.00      0.00      0.00         1\n",
      "      280000       0.00      0.00      0.00         1\n",
      "      283000       0.00      0.00      0.00         1\n",
      "      283953       0.00      0.00      0.00         1\n",
      "      284000       0.00      0.00      0.00         1\n",
      "      285000       0.00      0.00      0.00         1\n",
      "      287500       0.13      0.69      0.23        13\n",
      "      297311       0.00      0.00      0.00         1\n",
      "      298000       0.00      0.00      0.00         1\n",
      "      300000       0.00      0.00      0.00        17\n",
      "      301666       0.00      0.00      0.00         1\n",
      "      301875       0.33      0.20      0.25         5\n",
      "      302875       0.00      0.00      0.00         1\n",
      "      303000       0.00      0.00      0.00         1\n",
      "      303232       0.00      0.00      0.00         1\n",
      "      304897       0.00      0.00      0.00         1\n",
      "      305000       0.00      0.00      0.00         1\n",
      "      308333       0.00      0.00      0.00         1\n",
      "      310000       0.00      0.00      0.00         3\n",
      "      311000       0.00      0.00      0.00         1\n",
      "      312000       0.00      0.00      0.00         2\n",
      "      312500       0.00      0.00      0.00         1\n",
      "      313000       0.00      0.00      0.00         2\n",
      "      315000       0.00      0.00      0.00         3\n",
      "      316969       0.03      0.17      0.05        12\n",
      "      320000       0.00      0.00      0.00         1\n",
      "      320142       0.00      0.00      0.00         1\n",
      "      322000       0.00      0.00      0.00         1\n",
      "      325000       0.00      0.00      0.00         6\n",
      "      326700       0.00      0.00      0.00         1\n",
      "      332817       0.50      0.06      0.11        16\n",
      "      335000       0.00      0.00      0.00         4\n",
      "      337500       0.00      0.00      0.00         0\n",
      "      342666       0.00      0.00      0.00         1\n",
      "      345000       0.00      0.00      0.00         1\n",
      "      347500       0.00      0.00      0.00         1\n",
      "      349458       0.01      0.33      0.02         3\n",
      "      350000       0.00      0.00      0.00        21\n",
      "      350179       0.00      0.00      0.00         1\n",
      "      351091       0.00      0.00      0.00         1\n",
      "      352000       0.00      0.00      0.00         1\n",
      "      355000       0.00      0.00      0.00         1\n",
      "      359546       0.00      0.00      0.00         1\n",
      "      360000       0.00      0.00      0.00         1\n",
      "      363000       0.00      0.00      0.00         1\n",
      "      366337       0.00      0.00      0.00         1\n",
      "      366931       0.07      0.33      0.11         6\n",
      "      369000       0.00      0.00      0.00         1\n",
      "      374289       0.00      0.00      0.00         1\n",
      "      375000       0.00      0.00      0.00         8\n",
      "      381830       0.00      0.00      0.00         1\n",
      "      382000       0.00      0.00      0.00         1\n",
      "      383351       0.00      0.00      0.00         1\n",
      "      384766       0.00      0.00      0.00         1\n",
      "      385000       0.00      0.00      0.00         3\n",
      "      385277       0.00      0.00      0.00         6\n",
      "      390000       0.00      0.00      0.00         1\n",
      "      392000       0.00      0.00      0.00         1\n",
      "      395000       0.00      0.00      0.00         3\n",
      "      396844       0.00      0.00      0.00         1\n",
      "      396905       0.00      0.00      0.00         1\n",
      "      398762       0.08      0.15      0.11        13\n",
      "      400000       0.00      0.00      0.00        16\n",
      "      400850       0.00      0.00      0.00         1\n",
      "      401875       0.00      0.00      0.00         1\n",
      "      405000       0.00      0.00      0.00         1\n",
      "      406000       0.00      0.00      0.00         1\n",
      "      408000       0.00      0.00      0.00         1\n",
      "      410000       0.00      0.00      0.00         4\n",
      "      411000       0.00      0.00      0.00         1\n",
      "      412000       0.00      0.00      0.00         3\n",
      "      412718       0.02      0.10      0.03        10\n",
      "      414443       0.00      0.00      0.00         1\n",
      "      414481       0.00      0.00      0.00         1\n",
      "      415000       0.00      0.00      0.00         2\n",
      "      420000       0.00      0.00      0.00         3\n",
      "      423000       0.00      0.00      0.00         1\n",
      "      423500       0.00      0.00      0.00         3\n",
      "      423762       0.00      0.00      0.00         1\n",
      "      425000       0.00      0.00      0.00         7\n",
      "      427163       0.00      0.00      0.00         6\n",
      "      429111       0.00      0.00      0.00         1\n",
      "      430000       0.00      0.00      0.00         1\n",
      "      437000       0.00      0.00      0.00         1\n",
      "      438000       0.00      0.00      0.00         1\n",
      "      440000       0.00      0.00      0.00         1\n",
      "      440078       0.00      0.00      0.00         1\n",
      "      442114       0.00      0.00      0.00         1\n",
      "      450000       0.00      0.00      0.00        15\n",
      "      450060       0.00      0.00      0.00         1\n",
      "      451866       0.00      0.00      0.00         1\n",
      "      455000       0.00      0.00      0.00         2\n",
      "      456000       0.00      0.00      0.00         1\n",
      "      457588       0.00      0.00      0.00         3\n",
      "      460000       0.00      0.00      0.00         1\n",
      "      463000       0.00      0.00      0.00         1\n",
      "      465143       0.00      0.00      0.00         1\n",
      "      465850       0.00      0.00      0.00         6\n",
      "      468297       0.00      0.00      0.00         1\n",
      "      469841       0.00      0.00      0.00         1\n",
      "      473504       0.00      0.00      0.00         1\n",
      "      473604       0.06      0.46      0.11        24\n",
      "      473640       0.00      0.00      0.00         2\n",
      "      474000       0.00      0.00      0.00         1\n",
      "      475000       0.00      0.00      0.00         7\n",
      "      477000       0.00      0.00      0.00         2\n",
      "      478558       0.00      0.00      0.00         1\n",
      "      480000       0.00      0.00      0.00         2\n",
      "      481488       0.00      0.00      0.00         1\n",
      "      485000       0.00      0.00      0.00         3\n",
      "      488000       0.00      0.00      0.00         1\n",
      "      489500       0.00      0.00      0.00         1\n",
      "      495000       0.00      0.00      0.00         2\n",
      "      498500       0.00      0.00      0.00         2\n",
      "      500000       0.05      0.10      0.06        29\n",
      "      501106       0.00      0.00      0.00         1\n",
      "      504000       0.00      0.00      0.00         1\n",
      "      507000       0.00      0.00      0.00         1\n",
      "      507336       0.00      0.00      0.00         3\n",
      "      510000       0.00      0.00      0.00        11\n",
      "      510529       0.00      0.00      0.00         1\n",
      "      512435       0.00      0.00      0.00         1\n",
      "      515000       0.00      0.00      0.00         2\n",
      "      517360       0.00      0.00      0.00         1\n",
      "      520000       0.00      0.00      0.00         1\n",
      "      522486       0.00      0.00      0.00         1\n",
      "      523500       0.00      0.00      0.00         4\n",
      "      524964       0.00      0.00      0.00         1\n",
      "      525000       0.00      0.00      0.00         5\n",
      "      525090       0.00      0.00      0.00         1\n",
      "      525093       0.00      0.00      0.00         5\n",
      "      527185       0.00      0.00      0.00         1\n",
      "      530000       0.00      0.00      0.00         1\n",
      "      535000       0.00      0.00      0.00         1\n",
      "      536100       0.00      0.00      0.00         1\n",
      "      537500       0.00      0.00      0.00         3\n",
      "      540850       0.00      0.00      0.00         3\n",
      "      543000       0.00      0.00      0.00         1\n",
      "      543471       0.00      0.00      0.00         5\n",
      "      544331       0.00      0.00      0.00         1\n",
      "      547000       0.00      0.00      0.00         1\n",
      "      548000       0.00      0.00      0.00         1\n",
      "      548500       0.00      0.00      0.00         2\n",
      "      549000       0.00      0.00      0.00         1\n",
      "      550000       0.00      0.00      0.00         7\n",
      "      551000       0.00      0.00      0.00         1\n",
      "      556438       0.00      0.00      0.00         1\n",
      "      559000       0.00      0.00      0.00         1\n",
      "      560000       0.00      0.00      0.00         2\n",
      "      561716       0.00      0.00      0.00         1\n",
      "      563302       0.00      0.00      0.00         1\n",
      "      563679       0.00      0.00      0.00         3\n",
      "      564518       0.00      0.00      0.00         1\n",
      "      565000       0.00      0.00      0.00         1\n",
      "      565180       0.00      0.00      0.00         1\n",
      "      565850       0.00      0.00      0.00         4\n",
      "      570000       0.00      0.00      0.00         1\n",
      "      575000       0.00      0.00      0.00         4\n",
      "      576380       0.00      0.00      0.00         1\n",
      "      583944       0.00      0.00      0.00         1\n",
      "      584000       0.00      0.00      0.00         1\n",
      "      585000       0.00      0.00      0.00         1\n",
      "      587435       0.00      0.00      0.00         3\n",
      "      588000       0.00      0.00      0.00         2\n",
      "      589769       0.00      0.00      0.00         1\n",
      "      590850       0.00      0.00      0.00         6\n",
      "      593056       0.00      0.00      0.00         1\n",
      "      597600       0.00      0.00      0.00         1\n",
      "      600000       0.00      0.00      0.00        23\n",
      "      601000       0.00      0.00      0.00         1\n",
      "      603558       0.00      0.00      0.00         1\n",
      "      605000       0.00      0.00      0.00         4\n",
      "      605500       0.00      0.00      0.00         1\n",
      "      606000       0.00      0.00      0.00         1\n",
      "      607545       0.00      0.00      0.00         1\n",
      "      608000       0.00      0.00      0.00         1\n",
      "      610000       0.00      0.00      0.00         1\n",
      "      611000       0.00      0.00      0.00         1\n",
      "      612435       0.00      0.00      0.00         1\n",
      "      612500       0.00      0.00      0.00         1\n",
      "      615000       0.00      0.00      0.00         3\n",
      "      620000       0.00      0.00      0.00         2\n",
      "      620046       0.00      0.00      0.00         3\n",
      "      621520       0.00      0.00      0.00         1\n",
      "      625000       0.00      0.00      0.00        10\n",
      "      625132       0.00      0.00      0.00         1\n",
      "      626240       0.00      0.00      0.00         1\n",
      "      630000       0.00      0.00      0.00         2\n",
      "      630850       0.00      0.00      0.00         1\n",
      "      632455       0.00      0.00      0.00         1\n",
      "      633000       0.00      0.00      0.00         1\n",
      "      633974       0.00      0.00      0.00         1\n",
      "      636679       0.00      0.00      0.00         2\n",
      "      637435       0.00      0.00      0.00         2\n",
      "      638000       0.00      0.00      0.00         1\n",
      "      638679       0.00      0.00      0.00         4\n",
      "      639300       0.00      0.00      0.00         1\n",
      "      640000       0.00      0.00      0.00         1\n",
      "      641000       0.00      0.00      0.00         1\n",
      "      641748       0.00      0.00      0.00         4\n",
      "      644166       0.00      0.00      0.00         1\n",
      "      645000       0.00      0.00      0.00         1\n",
      "      650000       0.00      0.00      0.00        17\n",
      "      652800       0.00      0.00      0.00         1\n",
      "      653350       0.00      0.00      0.00         1\n",
      "      660000       0.00      0.00      0.00         1\n",
      "      662500       0.00      0.00      0.00         1\n",
      "      663679       0.00      0.00      0.00         1\n",
      "      664000       0.00      0.00      0.00         1\n",
      "      664209       0.00      0.00      0.00         7\n",
      "      665000       0.00      0.00      0.00         1\n",
      "      667000       0.00      0.00      0.00         1\n",
      "      670000       0.00      0.00      0.00         1\n",
      "      670800       0.00      0.00      0.00         1\n",
      "      672000       0.00      0.00      0.00         1\n",
      "      673500       0.00      0.00      0.00         1\n",
      "      674000       0.00      0.00      0.00         1\n",
      "      675000       0.00      0.00      0.00         5\n",
      "      675120       0.00      0.00      0.00         1\n",
      "      678000       0.00      0.00      0.00         1\n",
      "      685000       0.00      0.00      0.00         1\n",
      "      686838       0.00      0.00      0.00         1\n",
      "      687456       1.00      0.20      0.33         5\n",
      "      688679       0.00      0.00      0.00         3\n",
      "      690000       0.00      0.00      0.00         3\n",
      "      690960       0.00      0.00      0.00         1\n",
      "      694000       0.00      0.00      0.00         1\n",
      "      694920       0.00      0.00      0.00         0\n",
      "      695046       0.00      0.00      0.00         7\n",
      "      699935       0.00      0.00      0.00         1\n",
      "      700000       0.00      0.00      0.00        11\n",
      "      700320       0.00      0.00      0.00         1\n",
      "      702756       0.00      0.00      0.00         1\n",
      "      703200       0.00      0.00      0.00         1\n",
      "      705000       0.00      0.00      0.00         1\n",
      "      706300       0.00      0.00      0.00         1\n",
      "      707040       0.00      0.00      0.00         1\n",
      "      710000       0.00      0.00      0.00         2\n",
      "      711517       0.00      0.00      0.00         4\n",
      "      712000       0.00      0.00      0.00         1\n",
      "      715000       0.00      0.00      0.00         3\n",
      "      715850       0.00      0.00      0.00         5\n",
      "      716600       0.00      0.00      0.00         1\n",
      "      719373       0.00      0.00      0.00         2\n",
      "      720046       0.00      0.00      0.00         1\n",
      "      721080       0.00      0.00      0.00         1\n",
      "      723000       0.00      0.00      0.00         1\n",
      "      723840       0.00      0.00      0.00         1\n",
      "      725000       0.00      0.00      0.00         4\n",
      "      728520       0.00      0.00      0.00         1\n",
      "      729000       0.00      0.00      0.00         1\n",
      "      730000       0.00      0.00      0.00         1\n",
      "      735000       0.00      0.00      0.00         2\n",
      "      735960       0.00      0.00      0.00         1\n",
      "      736000       0.00      0.00      0.00         1\n",
      "      736420       0.00      0.00      0.00         4\n",
      "      737880       0.00      0.00      0.00         1\n",
      "      739080       0.00      0.00      0.00         1\n",
      "      743000       0.00      0.00      0.00         1\n",
      "      744480       0.00      0.00      0.00         1\n",
      "      744551       0.00      0.00      0.00         2\n",
      "      745046       0.00      0.00      0.00         3\n",
      "      745248       0.00      0.00      0.00         2\n",
      "      745800       0.00      0.00      0.00         1\n",
      "      748656       0.00      0.00      0.00         1\n",
      "      749160       0.00      0.00      0.00         1\n",
      "      750000       0.00      0.00      0.00        13\n",
      "      751179       0.00      0.00      0.00         4\n",
      "      752000       0.00      0.00      0.00         1\n",
      "      753133       0.00      0.00      0.00         1\n",
      "      754080       0.00      0.00      0.00         1\n",
      "      755000       0.00      0.00      0.00         1\n",
      "      759250       0.00      0.00      0.00         1\n",
      "      759960       0.00      0.00      0.00         1\n",
      "      760000       0.00      0.00      0.00         3\n",
      "      762195       0.00      0.00      0.00        10\n",
      "      762196       0.00      0.00      0.00         1\n",
      "      763000       0.00      0.00      0.00         1\n",
      "      768718       0.00      0.00      0.00         1\n",
      "      769881       0.00      0.00      0.00         1\n",
      "      770610       0.00      0.00      0.00         4\n",
      "      771123       0.00      0.00      0.00         1\n",
      "      771331       0.00      0.00      0.00         2\n",
      "      771480       0.00      0.00      0.00         1\n",
      "      773400       0.00      0.00      0.00         1\n",
      "      775000       0.00      0.00      0.00         1\n",
      "      777000       0.00      0.00      0.00         1\n",
      "      778350       0.00      0.00      0.00         1\n",
      "      780000       0.00      0.00      0.00         2\n",
      "      781800       0.00      0.00      0.00         1\n",
      "      783000       0.00      0.00      0.00         2\n",
      "      786600       0.00      0.00      0.00         1\n",
      "      788872       0.00      0.00      0.00         5\n",
      "      790000       0.00      0.00      0.00         3\n",
      "      790440       0.00      0.00      0.00         1\n",
      "      794880       0.00      0.00      0.00         1\n",
      "      795000       0.00      0.00      0.00         3\n",
      "      795401       0.00      0.00      0.00         1\n",
      "      797581       0.00      0.00      0.00         3\n",
      "      797880       0.00      0.00      0.00         2\n",
      "      798112       0.00      0.00      0.00         1\n",
      "      798500       0.00      0.00      0.00         1\n",
      "      800000       0.00      0.00      0.00        16\n",
      "      804131       0.00      0.00      0.00         1\n",
      "      805000       0.00      0.00      0.00         2\n",
      "      805320       0.00      0.00      0.00         1\n",
      "      806452       0.00      0.00      0.00         1\n",
      "      807546       0.00      0.00      0.00         2\n",
      "      808000       0.00      0.00      0.00         1\n",
      "      809280       0.00      0.00      0.00         1\n",
      "      810000       0.00      0.00      0.00         3\n",
      "      813679       0.00      0.00      0.00         2\n",
      "      814320       0.00      0.00      0.00         1\n",
      "      816482       0.02      0.20      0.03         5\n",
      "      818160       0.00      0.00      0.00         1\n",
      "      819550       0.00      0.00      0.00         1\n",
      "      821000       0.00      0.00      0.00         1\n",
      "      823440       0.00      0.00      0.00         0\n",
      "      824200       0.00      0.00      0.00         1\n",
      "      824935       0.00      0.00      0.00         2\n",
      "      825000       0.00      0.00      0.00         2\n",
      "      826046       0.00      0.00      0.00         1\n",
      "      826269       0.00      0.00      0.00         1\n",
      "      827197       0.00      0.00      0.00         1\n",
      "      828000       0.00      0.00      0.00         0\n",
      "      830000       0.00      0.00      0.00         2\n",
      "      830745       0.00      0.00      0.00         1\n",
      "      830947       0.00      0.00      0.00         1\n",
      "      831120       0.00      0.00      0.00         1\n",
      "      833000       0.00      0.00      0.00         2\n",
      "      835000       0.00      0.00      0.00         1\n",
      "      835200       0.00      0.00      0.00         1\n",
      "      835810       0.00      0.00      0.00         2\n",
      "      837000       0.00      0.00      0.00         1\n",
      "      840360       0.00      0.00      0.00         1\n",
      "      845000       0.00      0.00      0.00         5\n",
      "      845059       0.00      0.00      0.00         5\n",
      "      845122       0.00      0.00      0.00         1\n",
      "      846840       0.00      0.00      0.00         1\n",
      "      848266       0.00      0.00      0.00         1\n",
      "      848520       0.00      0.00      0.00         1\n",
      "      849720       0.00      0.00      0.00         1\n",
      "      850000       0.00      0.00      0.00         5\n",
      "      854389       0.00      0.00      0.00         9\n",
      "      854957       0.00      0.00      0.00         2\n",
      "      857000       0.00      0.00      0.00         1\n",
      "      857760       0.00      0.00      0.00         1\n",
      "      862560       0.00      0.00      0.00         1\n",
      "      863640       0.00      0.00      0.00         1\n",
      "      865800       0.00      0.00      0.00         1\n",
      "      866000       0.00      0.00      0.00         2\n",
      "      866800       0.00      0.00      0.00         0\n",
      "      870000       0.00      0.00      0.00         1\n",
      "      870046       0.00      0.00      0.00         3\n",
      "      874636       0.00      0.00      0.00         2\n",
      "      875000       0.00      0.00      0.00         3\n",
      "      875500       0.00      0.00      0.00         1\n",
      "      876179       0.00      0.00      0.00         1\n",
      "      877680       0.00      0.00      0.00         1\n",
      "      884000       0.00      0.00      0.00         2\n",
      "      884293       0.00      0.00      0.00         3\n",
      "      884879       0.00      0.00      0.00         0\n",
      "      884881       0.00      0.00      0.00         1\n",
      "      885120       0.00      0.00      0.00         2\n",
      "      886000       0.00      0.00      0.00         1\n",
      "      887160       0.00      0.00      0.00         1\n",
      "      887435       0.00      0.00      0.00         1\n",
      "      887500       0.00      0.00      0.00         0\n",
      "      890000       0.00      0.00      0.00         1\n",
      "      890693       0.00      0.00      0.00         1\n",
      "      893400       0.00      0.00      0.00         0\n",
      "      893750       0.00      0.00      0.00         1\n",
      "      895000       0.00      0.00      0.00         1\n",
      "      895248       0.00      0.00      0.00         1\n",
      "      895341       0.00      0.00      0.00         1\n",
      "      898200       0.00      0.00      0.00         1\n",
      "      899880       0.00      0.00      0.00         1\n",
      "      900000       0.00      0.00      0.00         8\n",
      "      902000       0.00      0.00      0.00         1\n",
      "      903000       0.00      0.00      0.00         1\n",
      "      903360       0.00      0.00      0.00         2\n",
      "      905000       0.00      0.00      0.00         1\n",
      "      906000       0.00      0.00      0.00         1\n",
      "      906480       0.00      0.00      0.00         1\n",
      "      910000       0.00      0.00      0.00         2\n",
      "      915000       0.00      0.00      0.00         1\n",
      "      915243       0.03      0.33      0.06         3\n",
      "      915852       0.00      0.00      0.00         0\n",
      "      916099       0.00      0.00      0.00         2\n",
      "      918369       0.00      0.00      0.00         1\n",
      "      922000       0.00      0.00      0.00         2\n",
      "      923670       0.00      0.00      0.00         1\n",
      "      923880       0.00      0.00      0.00         1\n",
      "      925000       0.00      0.00      0.00         2\n",
      "      926678       0.00      0.00      0.00         2\n",
      "      927360       0.00      0.00      0.00         1\n",
      "      930000       0.00      0.00      0.00         1\n",
      "      930720       0.00      0.00      0.00         1\n",
      "      932015       0.00      0.00      0.00         1\n",
      "      932546       0.00      0.00      0.00         3\n",
      "      936000       0.00      0.00      0.00         1\n",
      "      936600       0.00      0.00      0.00         0\n",
      "      937440       0.00      0.00      0.00         1\n",
      "      938679       0.00      0.00      0.00         1\n",
      "      938760       0.00      0.00      0.00         1\n",
      "      939360       0.00      0.00      0.00         1\n",
      "      940000       0.00      0.00      0.00         1\n",
      "      941040       0.00      0.00      0.00         1\n",
      "      944520       0.00      0.00      0.00         1\n",
      "      945000       0.00      0.00      0.00         1\n",
      "      946920       0.00      0.00      0.00         1\n",
      "      947276       0.00      0.00      0.00         2\n",
      "      947278       0.00      0.00      0.00         1\n",
      "      947907       0.00      0.00      0.00         1\n",
      "      948163       0.00      0.00      0.00         3\n",
      "      950000       0.00      0.00      0.00         5\n",
      "      950640       0.00      0.00      0.00         0\n",
      "      956000       0.00      0.00      0.00         1\n",
      "      960000       0.00      0.00      0.00         1\n",
      "      962195       0.00      0.00      0.00         1\n",
      "      962500       0.00      0.00      0.00         1\n",
      "      963415       0.00      0.00      0.00         1\n",
      "      964080       0.00      0.00      0.00         0\n",
      "      966000       0.00      0.00      0.00         1\n",
      "      967320       0.00      0.00      0.00         1\n",
      "      967920       0.00      0.00      0.00         0\n",
      "      971000       0.00      0.00      0.00         1\n",
      "      971160       0.00      0.00      0.00         1\n",
      "      971280       0.00      0.00      0.00         1\n",
      "      972581       0.00      0.00      0.00         2\n",
      "      973440       0.00      0.00      0.00         1\n",
      "      974520       0.00      0.00      0.00         1\n",
      "      975600       0.00      0.00      0.00         1\n",
      "      976920       0.00      0.00      0.00         1\n",
      "      978600       0.00      0.00      0.00         1\n",
      "      980000       0.00      0.00      0.00         2\n",
      "      980280       0.00      0.00      0.00         1\n",
      "      980431       0.00      0.00      0.00         3\n",
      "      981084       0.00      0.00      0.00         4\n",
      "      981348       0.00      0.00      0.00         4\n",
      "      983000       0.00      0.00      0.00         1\n",
      "      983307       0.00      0.00      0.00         1\n",
      "      985000       0.00      0.00      0.00         1\n",
      "      986000       0.00      0.00      0.00         1\n",
      "      987000       0.00      0.00      0.00         1\n",
      "      987500       0.00      0.00      0.00         1\n",
      "      990000       0.00      0.00      0.00         2\n",
      "      990600       0.00      0.00      0.00         1\n",
      "      992040       0.00      0.00      0.00         1\n",
      "      992680       0.00      0.00      0.00         4\n",
      "      995650       0.00      0.00      0.00         1\n",
      "      997000       0.00      0.00      0.00         1\n",
      "      998398       0.00      0.00      0.00         3\n",
      "     1000000       0.04      0.42      0.08        52\n",
      "     1000680       0.00      0.00      0.00         1\n",
      "     1001880       0.00      0.00      0.00         1\n",
      "     1002000       0.00      0.00      0.00         2\n",
      "     1002840       0.00      0.00      0.00         1\n",
      "     1006200       0.00      0.00      0.00         2\n",
      "     1010040       0.00      0.00      0.00         1\n",
      "     1011360       0.00      0.00      0.00         1\n",
      "     1015000       0.00      0.00      0.00         1\n",
      "     1015421       0.00      0.00      0.00         1\n",
      "     1015696       0.00      0.00      0.00         2\n",
      "     1016400       0.00      0.00      0.00         1\n",
      "     1020960       0.00      0.00      0.00         3\n",
      "     1021080       0.00      0.00      0.00         1\n",
      "     1022000       0.00      0.00      0.00         1\n",
      "     1025000       0.00      0.00      0.00         4\n",
      "     1025831       0.00      0.00      0.00         1\n",
      "     1027424       0.00      0.00      0.00         1\n",
      "     1027440       0.00      0.00      0.00         1\n",
      "     1028400       0.00      0.00      0.00         1\n",
      "     1030000       0.00      0.00      0.00         2\n",
      "     1033000       0.00      0.00      0.00         1\n",
      "     1033320       0.00      0.00      0.00         1\n",
      "     1033342       0.00      0.00      0.00         1\n",
      "     1034760       0.00      0.00      0.00         1\n",
      "     1034956       0.00      0.00      0.00         1\n",
      "     1035000       0.00      0.00      0.00         2\n",
      "     1036440       0.00      0.00      0.00         1\n",
      "     1037000       0.00      0.00      0.00         1\n",
      "     1039800       0.00      0.00      0.00         1\n",
      "     1040000       0.00      0.00      0.00         7\n",
      "     1041360       0.00      0.00      0.00         1\n",
      "     1042320       0.00      0.00      0.00         3\n",
      "     1042440       0.00      0.00      0.00         1\n",
      "     1044120       0.00      0.00      0.00         1\n",
      "     1045000       0.00      0.00      0.00         1\n",
      "     1045560       0.00      0.00      0.00         1\n",
      "     1047600       0.00      0.00      0.00         1\n",
      "     1048080       0.00      0.00      0.00         0\n",
      "     1048800       0.00      0.00      0.00         2\n",
      "     1050000       0.00      0.00      0.00         2\n",
      "     1050480       0.00      0.00      0.00         1\n",
      "     1051000       0.00      0.00      0.00         1\n",
      "     1053720       0.00      0.00      0.00         2\n",
      "     1053960       0.00      0.00      0.00         1\n",
      "     1054389       0.00      0.00      0.00         1\n",
      "     1055000       0.00      0.00      0.00         1\n",
      "     1056225       0.00      0.00      0.00         1\n",
      "     1059500       0.00      0.00      0.00         1\n",
      "     1060000       0.00      0.00      0.00         1\n",
      "     1061880       0.00      0.00      0.00         1\n",
      "     1063000       0.00      0.00      0.00         1\n",
      "     1063384       0.00      0.00      0.00         3\n",
      "     1063680       0.00      0.00      0.00         1\n",
      "     1067000       0.00      0.00      0.00         1\n",
      "     1069509       0.00      0.00      0.00         2\n",
      "     1070000       0.00      0.00      0.00         3\n",
      "     1071000       0.00      0.00      0.00         1\n",
      "     1071225       0.00      0.00      0.00         1\n",
      "     1071720       0.00      0.00      0.00         1\n",
      "     1074145       0.00      0.00      0.00         1\n",
      "     1074720       0.00      0.00      0.00         1\n",
      "     1075000       0.00      0.00      0.00         4\n",
      "     1075440       0.00      0.00      0.00         1\n",
      "     1080000       0.00      0.00      0.00         2\n",
      "     1080480       0.00      0.00      0.00         2\n",
      "     1082160       0.00      0.00      0.00         0\n",
      "     1082520       0.00      0.00      0.00         3\n",
      "     1085120       0.00      0.00      0.00         1\n",
      "     1089240       0.00      0.00      0.00         1\n",
      "     1091640       0.00      0.00      0.00         1\n",
      "     1093680       0.00      0.00      0.00         1\n",
      "     1095720       0.00      0.00      0.00         0\n",
      "     1097520       0.00      0.00      0.00         1\n",
      "     1100000       0.00      0.00      0.00        28\n",
      "     1100602       0.00      0.00      0.00         1\n",
      "     1105000       0.00      0.00      0.00         1\n",
      "     1105560       0.00      0.00      0.00         1\n",
      "     1106942       0.00      0.00      0.00         1\n",
      "     1107572       0.00      0.00      0.00         2\n",
      "     1108000       0.00      0.00      0.00         1\n",
      "     1110120       0.00      0.00      0.00         1\n",
      "     1110840       0.00      0.00      0.00         1\n",
      "     1112000       0.00      0.00      0.00         2\n",
      "     1113600       0.00      0.00      0.00         1\n",
      "     1117000       0.00      0.00      0.00         1\n",
      "     1119000       0.00      0.00      0.00         1\n",
      "     1120200       0.00      0.00      0.00         1\n",
      "     1120440       0.00      0.00      0.00         1\n",
      "     1123680       0.00      0.00      0.00         1\n",
      "     1128000       0.00      0.00      0.00         1\n",
      "     1131000       0.00      0.00      0.00         1\n",
      "     1133950       0.00      0.00      0.00         1\n",
      "     1135000       0.00      0.00      0.00         1\n",
      "     1137960       0.00      0.00      0.00         1\n",
      "     1138500       0.00      0.00      0.00         4\n",
      "     1140240       0.00      0.00      0.00         1\n",
      "     1143360       0.00      0.00      0.00         1\n",
      "     1143473       0.00      0.00      0.00         1\n",
      "     1146337       0.00      0.00      0.00         4\n",
      "     1147280       0.00      0.00      0.00         1\n",
      "     1148760       0.00      0.00      0.00         1\n",
      "     1149000       0.00      0.00      0.00         1\n",
      "     1149720       0.00      0.00      0.00         1\n",
      "     1150000       0.00      0.00      0.00         6\n",
      "     1152240       0.00      0.00      0.00         1\n",
      "     1155000       0.00      0.00      0.00         1\n",
      "     1156320       0.00      0.00      0.00         1\n",
      "     1163520       0.00      0.00      0.00         1\n",
      "     1164858       0.00      0.00      0.00         1\n",
      "     1165000       0.00      0.00      0.00         2\n",
      "     1165320       0.00      0.00      0.00         1\n",
      "     1165440       0.00      0.00      0.00         1\n",
      "     1167240       0.00      0.00      0.00         1\n",
      "     1171560       0.00      0.00      0.00         1\n",
      "     1172400       0.00      0.00      0.00         1\n",
      "     1173480       0.00      0.00      0.00         1\n",
      "     1174080       0.00      0.00      0.00         1\n",
      "     1174200       0.00      0.00      0.00         1\n",
      "     1175000       0.00      0.00      0.00         2\n",
      "     1175880       0.00      0.00      0.00         1\n",
      "     1176000       0.00      0.00      0.00         1\n",
      "     1177000       0.00      0.00      0.00         1\n",
      "     1178348       0.00      0.00      0.00         2\n",
      "     1180200       0.00      0.00      0.00         1\n",
      "     1182600       0.00      0.00      0.00         1\n",
      "     1183000       0.00      0.00      0.00         1\n",
      "     1184400       0.00      0.00      0.00         1\n",
      "     1185784       0.00      0.00      0.00         1\n",
      "     1186459       0.00      0.00      0.00         2\n",
      "     1187686       0.00      0.00      0.00         1\n",
      "     1188000       0.00      0.00      0.00         1\n",
      "     1189200       0.00      0.00      0.00         1\n",
      "     1191180       0.00      0.00      0.00         1\n",
      "     1191240       0.00      0.00      0.00         1\n",
      "     1191480       0.00      0.00      0.00         2\n",
      "     1192080       0.00      0.00      0.00         1\n",
      "     1193280       0.00      0.00      0.00         1\n",
      "     1195000       0.00      0.00      0.00         1\n",
      "     1195680       0.00      0.00      0.00         1\n",
      "     1196520       0.00      0.00      0.00         2\n",
      "     1199520       0.00      0.00      0.00         1\n",
      "     1200000       0.00      0.00      0.00        18\n",
      "     1204200       0.00      0.00      0.00         1\n",
      "     1204560       0.00      0.00      0.00         1\n",
      "     1206600       0.00      0.00      0.00         0\n",
      "     1207800       0.00      0.00      0.00         1\n",
      "     1208400       0.00      0.00      0.00         1\n",
      "     1210080       0.00      0.00      0.00         1\n",
      "     1210800       0.00      0.00      0.00         1\n",
      "     1211705       0.00      0.00      0.00         1\n",
      "     1212000       0.00      0.00      0.00         1\n",
      "     1212120       0.00      0.00      0.00         1\n",
      "     1219590       0.00      0.00      0.00         3\n",
      "     1223116       0.00      0.00      0.00         1\n",
      "     1223160       0.00      0.00      0.00         1\n",
      "     1223166       0.06      0.67      0.12         3\n",
      "     1226880       0.00      0.00      0.00         1\n",
      "     1227000       0.00      0.00      0.00         1\n",
      "     1229225       0.00      0.00      0.00         1\n",
      "     1229255       0.00      0.00      0.00         4\n",
      "     1229280       0.00      0.00      0.00         1\n",
      "     1232000       0.00      0.00      0.00         2\n",
      "     1233000       0.00      0.00      0.00         1\n",
      "     1235000       0.00      0.00      0.00         4\n",
      "     1236720       0.00      0.00      0.00         1\n",
      "     1238000       0.00      0.00      0.00         1\n",
      "     1238640       0.00      0.00      0.00         1\n",
      "     1240000       0.00      0.00      0.00         2\n",
      "     1240920       0.00      0.00      0.00         1\n",
      "     1244880       0.00      0.00      0.00         1\n",
      "     1246680       0.00      0.00      0.00         1\n",
      "     1250000       0.00      0.00      0.00         7\n",
      "     1258000       0.00      0.00      0.00         1\n",
      "     1260000       0.00      0.00      0.00         3\n",
      "     1260360       0.00      0.00      0.00         1\n",
      "     1262000       0.00      0.00      0.00         1\n",
      "     1262275       0.00      0.00      0.00         4\n",
      "     1262520       0.00      0.00      0.00         1\n",
      "     1262640       0.00      0.00      0.00         1\n",
      "     1264440       0.00      0.00      0.00         1\n",
      "     1265977       0.00      0.00      0.00         1\n",
      "     1266120       0.00      0.00      0.00         1\n",
      "     1268000       0.00      0.00      0.00         0\n",
      "     1268160       0.00      0.00      0.00         1\n",
      "     1269000       0.00      0.00      0.00         1\n",
      "     1270080       0.00      0.00      0.00         1\n",
      "     1270964       0.00      0.00      0.00         1\n",
      "     1272279       0.00      0.00      0.00         1\n",
      "     1273200       0.00      0.00      0.00         1\n",
      "     1275000       0.00      0.00      0.00         4\n",
      "     1276061       0.00      0.00      0.00         1\n",
      "     1276320       0.00      0.00      0.00         1\n",
      "     1278000       0.00      0.00      0.00         1\n",
      "     1280040       0.00      0.00      0.00         1\n",
      "     1280640       0.00      0.00      0.00         1\n",
      "     1280880       0.00      0.00      0.00         1\n",
      "     1283000       0.00      0.00      0.00         1\n",
      "     1286160       0.00      0.00      0.00         1\n",
      "     1288200       0.00      0.00      0.00         2\n",
      "     1289000       0.00      0.00      0.00         1\n",
      "     1289400       0.00      0.00      0.00         1\n",
      "     1291440       0.00      0.00      0.00         1\n",
      "     1293240       0.00      0.00      0.00         1\n",
      "     1300000       0.00      0.00      0.00        14\n",
      "     1300920       0.00      0.00      0.00         1\n",
      "     1302840       0.00      0.00      0.00         1\n",
      "     1304000       0.00      0.00      0.00         1\n",
      "     1306455       0.00      0.00      0.00         3\n",
      "     1306920       0.00      0.00      0.00         1\n",
      "     1307640       0.00      0.00      0.00         1\n",
      "     1308000       0.00      0.00      0.00         1\n",
      "     1309000       0.00      0.00      0.00         2\n",
      "     1310000       0.00      0.00      0.00         1\n",
      "     1312920       0.00      0.00      0.00         1\n",
      "     1315000       0.00      0.00      0.00         1\n",
      "     1315448       0.00      0.00      0.00         1\n",
      "     1316809       0.00      0.00      0.00         1\n",
      "     1319000       0.00      0.00      0.00         1\n",
      "     1320000       0.00      0.00      0.00         2\n",
      "     1326960       0.00      0.00      0.00         1\n",
      "     1329009       0.00      0.00      0.00         1\n",
      "     1329480       0.00      0.00      0.00         1\n",
      "     1330000       0.00      0.00      0.00         5\n",
      "     1332000       0.00      0.00      0.00         1\n",
      "     1333000       0.00      0.00      0.00         1\n",
      "     1333920       0.00      0.00      0.00         1\n",
      "     1335480       0.00      0.00      0.00         1\n",
      "     1337000       0.00      0.00      0.00         1\n",
      "     1338240       0.00      0.00      0.00         1\n",
      "     1340000       0.00      0.00      0.00         2\n",
      "     1345000       0.00      0.00      0.00         1\n",
      "     1347000       0.00      0.00      0.00         1\n",
      "     1348200       0.00      0.00      0.00         1\n",
      "     1350000       0.00      0.00      0.00         2\n",
      "     1351000       0.00      0.00      0.00         1\n",
      "     1352181       0.06      0.75      0.12        12\n",
      "     1353960       0.00      0.00      0.00         1\n",
      "     1356000       0.00      0.00      0.00         1\n",
      "     1356146       0.00      0.00      0.00         1\n",
      "     1357320       0.00      0.00      0.00         1\n",
      "     1359360       0.00      0.00      0.00         1\n",
      "     1360000       0.00      0.00      0.00         2\n",
      "     1363000       0.00      0.00      0.00         1\n",
      "     1365000       0.00      0.00      0.00         3\n",
      "     1365360       0.00      0.00      0.00         1\n",
      "     1365720       0.00      0.00      0.00         1\n",
      "     1367640       0.00      0.00      0.00         1\n",
      "     1369000       0.00      0.00      0.00         1\n",
      "     1369229       0.00      0.00      0.00         1\n",
      "     1372080       0.00      0.00      0.00         1\n",
      "     1373880       0.00      0.00      0.00         1\n",
      "     1375000       0.00      0.00      0.00         3\n",
      "     1377000       0.00      0.00      0.00         1\n",
      "     1377500       0.00      0.00      0.00         1\n",
      "     1379400       0.00      0.00      0.00         0\n",
      "     1380000       0.00      0.00      0.00         1\n",
      "     1381560       0.00      0.00      0.00         1\n",
      "     1386000       0.00      0.00      0.00         1\n",
      "     1390000       0.00      0.00      0.00         2\n",
      "     1391160       0.00      0.00      0.00         1\n",
      "     1392240       0.00      0.00      0.00         1\n",
      "     1398960       0.00      0.00      0.00         1\n",
      "     1399507       0.00      0.00      0.00         4\n",
      "     1400000       0.00      0.00      0.00         9\n",
      "     1402000       0.00      0.00      0.00         2\n",
      "     1403611       0.00      0.00      0.00         1\n",
      "     1404600       0.00      0.00      0.00         1\n",
      "     1404960       0.00      0.00      0.00         1\n",
      "     1407240       0.00      0.00      0.00         0\n",
      "     1408680       0.00      0.00      0.00         1\n",
      "     1409040       0.00      0.00      0.00         2\n",
      "     1413480       0.00      0.00      0.00         1\n",
      "     1416600       0.00      0.00      0.00         1\n",
      "     1419240       0.00      0.00      0.00         1\n",
      "     1422720       0.00      0.00      0.00         0\n",
      "     1424000       0.00      0.00      0.00         1\n",
      "     1427040       0.00      0.00      0.00         1\n",
      "     1428000       0.00      0.00      0.00         1\n",
      "     1429200       0.00      0.00      0.00         1\n",
      "     1430000       0.00      0.00      0.00         2\n",
      "     1431000       0.00      0.00      0.00         1\n",
      "     1431600       0.00      0.00      0.00         1\n",
      "     1437240       0.00      0.00      0.00         1\n",
      "     1438690       0.00      0.00      0.00         1\n",
      "     1439760       0.00      0.00      0.00         1\n",
      "     1439880       0.00      0.00      0.00         1\n",
      "     1440000       0.00      0.00      0.00         1\n",
      "     1440960       0.00      0.00      0.00         1\n",
      "     1441440       0.00      0.00      0.00         1\n",
      "     1444000       0.00      0.00      0.00         1\n",
      "     1448000       0.00      0.00      0.00         1\n",
      "     1448400       0.00      0.00      0.00         1\n",
      "     1448490       0.00      0.00      0.00         2\n",
      "     1450000       0.00      0.00      0.00         1\n",
      "     1452000       0.00      0.00      0.00         1\n",
      "     1453680       0.00      0.00      0.00         1\n",
      "     1454640       0.00      0.00      0.00         1\n",
      "     1458000       0.00      0.00      0.00         1\n",
      "     1461360       0.00      0.00      0.00         1\n",
      "     1463520       0.00      0.00      0.00         1\n",
      "     1464000       0.00      0.00      0.00         0\n",
      "     1467840       0.00      0.00      0.00         1\n",
      "     1468920       0.00      0.00      0.00         1\n",
      "     1472400       0.00      0.00      0.00         1\n",
      "     1474000       0.00      0.00      0.00         0\n",
      "     1474440       0.00      0.00      0.00         1\n",
      "     1475106       0.00      0.00      0.00         1\n",
      "     1476840       0.00      0.00      0.00         1\n",
      "     1481400       0.00      0.00      0.00         1\n",
      "     1482000       0.00      0.00      0.00         1\n",
      "     1485000       0.00      0.00      0.00         2\n",
      "     1485300       0.00      0.00      0.00         1\n",
      "     1490120       0.00      0.00      0.00         1\n",
      "     1491240       0.00      0.00      0.00         1\n",
      "     1496400       0.00      0.00      0.00         1\n",
      "     1496640       0.00      0.00      0.00         1\n",
      "     1499000       0.00      0.00      0.00         2\n",
      "     1499187       0.00      0.00      0.00         3\n",
      "     1500000       0.00      0.00      0.00        18\n",
      "     1500120       0.00      0.00      0.00         1\n",
      "     1502000       0.00      0.00      0.00         1\n",
      "     1506000       0.00      0.00      0.00         1\n",
      "     1509000       0.00      0.00      0.00         1\n",
      "     1509360       0.00      0.00      0.00         1\n",
      "     1510000       0.00      0.00      0.00         2\n",
      "     1514280       0.00      0.00      0.00         1\n",
      "     1516680       0.00      0.00      0.00         1\n",
      "     1519200       0.00      0.00      0.00         1\n",
      "     1520000       0.00      0.00      0.00         1\n",
      "     1524000       0.00      0.00      0.00         1\n",
      "     1528440       0.00      0.00      0.00         1\n",
      "     1537000       0.00      0.00      0.00         1\n",
      "     1538000       0.00      0.00      0.00         1\n",
      "     1540000       0.00      0.00      0.00         6\n",
      "     1544000       0.00      0.00      0.00         1\n",
      "     1547640       0.00      0.00      0.00         0\n",
      "     1547760       0.00      0.00      0.00         1\n",
      "     1550000       0.00      0.00      0.00         2\n",
      "     1551659       0.00      0.00      0.00         4\n",
      "     1551840       0.00      0.00      0.00         1\n",
      "     1552500       0.00      0.00      0.00         1\n",
      "     1559280       0.00      0.00      0.00         1\n",
      "     1560000       0.00      0.00      0.00         5\n",
      "     1563000       0.00      0.00      0.00         0\n",
      "     1563120       0.00      0.00      0.00         1\n",
      "     1570920       0.00      0.00      0.00         1\n",
      "     1572360       0.00      0.00      0.00         1\n",
      "     1575000       0.00      0.00      0.00         1\n",
      "     1580000       0.00      0.00      0.00         1\n",
      "     1580702       0.00      0.00      0.00         1\n",
      "     1581000       0.00      0.00      0.00         1\n",
      "     1590000       0.00      0.00      0.00         1\n",
      "     1594920       0.00      0.00      0.00         1\n",
      "     1596360       0.00      0.00      0.00         1\n",
      "     1600000       0.00      0.00      0.00        10\n",
      "     1602120       0.00      0.00      0.00         1\n",
      "     1606080       0.00      0.00      0.00         1\n",
      "     1608840       0.00      0.00      0.00         1\n",
      "     1610000       0.00      0.00      0.00         1\n",
      "     1611840       0.00      0.00      0.00         1\n",
      "     1616000       0.00      0.00      0.00         1\n",
      "     1618320       0.00      0.00      0.00         1\n",
      "     1618680       0.00      0.00      0.00         1\n",
      "     1619000       0.00      0.00      0.00         1\n",
      "     1622000       0.00      0.00      0.00         0\n",
      "     1625000       0.00      0.00      0.00         4\n",
      "     1627320       0.00      0.00      0.00         1\n",
      "     1627920       0.00      0.00      0.00         1\n",
      "     1628760       0.00      0.00      0.00         1\n",
      "     1630800       0.00      0.00      0.00         1\n",
      "     1643040       0.00      0.00      0.00         1\n",
      "     1645400       0.00      0.00      0.00         1\n",
      "     1646000       0.00      0.00      0.00         1\n",
      "     1650000       0.00      0.00      0.00         6\n",
      "     1652280       0.00      0.00      0.00         1\n",
      "     1654320       0.00      0.00      0.00         1\n",
      "     1655880       0.00      0.00      0.00         1\n",
      "     1658000       0.00      0.00      0.00         1\n",
      "     1662360       0.00      0.00      0.00         1\n",
      "     1662500       0.00      0.00      0.00         1\n",
      "     1662961       0.00      0.00      0.00         1\n",
      "     1665000       0.00      0.00      0.00         1\n",
      "     1667603       0.00      0.00      0.00         1\n",
      "     1669800       0.00      0.00      0.00         1\n",
      "     1670000       0.00      0.00      0.00         1\n",
      "     1673000       0.00      0.00      0.00         1\n",
      "     1675000       0.00      0.00      0.00         1\n",
      "     1676280       0.00      0.00      0.00         0\n",
      "     1678800       0.00      0.00      0.00         1\n",
      "     1680000       0.00      0.00      0.00         5\n",
      "     1681200       0.00      0.00      0.00         1\n",
      "     1682000       0.00      0.00      0.00         1\n",
      "     1682280       0.00      0.00      0.00         1\n",
      "     1687500       0.00      0.00      0.00         1\n",
      "     1689360       0.00      0.00      0.00         1\n",
      "     1690000       0.00      0.00      0.00         2\n",
      "     1690680       0.00      0.00      0.00         1\n",
      "     1695000       0.00      0.00      0.00         1\n",
      "     1695635       0.00      0.00      0.00         1\n",
      "     1696387       0.00      0.00      0.00         1\n",
      "     1700000       0.00      0.00      0.00         7\n",
      "     1702000       0.00      0.00      0.00         1\n",
      "     1707720       0.00      0.00      0.00         1\n",
      "     1709720       0.00      0.00      0.00         1\n",
      "     1710000       0.00      0.00      0.00         1\n",
      "     1714440       0.00      0.00      0.00         1\n",
      "     1715000       0.00      0.00      0.00         1\n",
      "     1715040       0.00      0.00      0.00         1\n",
      "     1720560       0.00      0.00      0.00         1\n",
      "     1721000       0.00      0.00      0.00         1\n",
      "     1722000       0.00      0.00      0.00         1\n",
      "     1723606       0.00      0.00      0.00         1\n",
      "     1731960       0.00      0.00      0.00         1\n",
      "     1732000       0.00      0.00      0.00         1\n",
      "     1733040       0.00      0.00      0.00         1\n",
      "     1739160       0.00      0.00      0.00         1\n",
      "     1740000       0.00      0.00      0.00         1\n",
      "     1741440       0.00      0.00      0.00         2\n",
      "     1743000       0.00      0.00      0.00         1\n",
      "     1745520       0.00      0.00      0.00         1\n",
      "     1748760       0.00      0.00      0.00         0\n",
      "     1750000       0.00      0.00      0.00        12\n",
      "     1752000       0.00      0.00      0.00         1\n",
      "     1760000       0.00      0.00      0.00         3\n",
      "     1762000       0.00      0.00      0.00         1\n",
      "     1762320       0.00      0.00      0.00         1\n",
      "     1762680       0.00      0.00      0.00         0\n",
      "     1767000       0.00      0.00      0.00         1\n",
      "     1767120       0.00      0.00      0.00         0\n",
      "     1768000       0.00      0.00      0.00         1\n",
      "     1768320       0.00      0.00      0.00         1\n",
      "     1768653       0.00      0.00      0.00         1\n",
      "     1768800       0.00      0.00      0.00         2\n",
      "     1775000       0.00      0.00      0.00         1\n",
      "     1780000       0.00      0.00      0.00         1\n",
      "     1785000       0.00      0.00      0.00         1\n",
      "     1785960       0.00      0.00      0.00         0\n",
      "     1787000       0.00      0.00      0.00         1\n",
      "     1790000       0.00      0.00      0.00         1\n",
      "     1792560       0.00      0.00      0.00         1\n",
      "     1793160       0.00      0.00      0.00         0\n",
      "     1794871       0.00      0.00      0.00         1\n",
      "     1797600       0.00      0.00      0.00         1\n",
      "     1797845       0.00      0.00      0.00         1\n",
      "     1800000       0.00      0.00      0.00         8\n",
      "     1802000       0.00      0.00      0.00         2\n",
      "     1803600       0.00      0.00      0.00         1\n",
      "     1815000       0.00      0.00      0.00         1\n",
      "     1817141       0.00      0.00      0.00         1\n",
      "     1818000       0.00      0.00      0.00         1\n",
      "     1818720       0.00      0.00      0.00         0\n",
      "     1820520       0.00      0.00      0.00         0\n",
      "     1823280       0.00      0.00      0.00         1\n",
      "     1825000       0.00      0.00      0.00         1\n",
      "     1828750       0.00      0.00      0.00         1\n",
      "     1830000       0.00      0.00      0.00         1\n",
      "     1830720       0.00      0.00      0.00         1\n",
      "     1833000       0.00      0.00      0.00         1\n",
      "     1833120       0.00      0.00      0.00         1\n",
      "     1834080       0.00      0.00      0.00         1\n",
      "     1834680       0.00      0.00      0.00         1\n",
      "     1836000       0.00      0.00      0.00         1\n",
      "     1842480       0.00      0.00      0.00         2\n",
      "     1850000       0.00      0.00      0.00         3\n",
      "     1861000       0.00      0.00      0.00         1\n",
      "     1861920       0.00      0.00      0.00         1\n",
      "     1868141       0.00      0.00      0.00         1\n",
      "     1870000       0.00      0.00      0.00         1\n",
      "     1870501       0.00      0.00      0.00         1\n",
      "     1879920       0.00      0.00      0.00         1\n",
      "     1881250       0.00      0.00      0.00         1\n",
      "     1885000       0.00      0.00      0.00         2\n",
      "     1886113       0.00      0.00      0.00         1\n",
      "     1887840       0.00      0.00      0.00         1\n",
      "     1887864       0.00      0.00      0.00         1\n",
      "     1888680       0.00      0.00      0.00         1\n",
      "     1889760       0.00      0.00      0.00         0\n",
      "     1900000       0.00      0.00      0.00         4\n",
      "     1900200       0.00      0.00      0.00         1\n",
      "     1906200       0.00      0.00      0.00         1\n",
      "     1906440       0.00      0.00      0.00         1\n",
      "     1908000       0.00      0.00      0.00         2\n",
      "     1910000       0.00      0.00      0.00         1\n",
      "     1910520       0.00      0.00      0.00         0\n",
      "     1913000       0.00      0.00      0.00         1\n",
      "     1914544       0.00      0.00      0.00         1\n",
      "     1917000       0.00      0.00      0.00         1\n",
      "     1919160       0.00      0.00      0.00         1\n",
      "     1920000       0.00      0.00      0.00         6\n",
      "     1921320       0.00      0.00      0.00         1\n",
      "     1923000       0.00      0.00      0.00         1\n",
      "     1923600       0.00      0.00      0.00         1\n",
      "     1927000       0.00      0.00      0.00         1\n",
      "     1930000       0.00      0.00      0.00         1\n",
      "     1930680       0.00      0.00      0.00         1\n",
      "     1931160       0.00      0.00      0.00         1\n",
      "     1934160       0.00      0.00      0.00         1\n",
      "     1935900       0.00      0.00      0.00         1\n",
      "     1939893       0.00      0.00      0.00         1\n",
      "     1946880       0.00      0.00      0.00         1\n",
      "     1950000       0.00      0.00      0.00         3\n",
      "     1955000       0.00      0.00      0.00         1\n",
      "     1957080       0.00      0.00      0.00         1\n",
      "     1958640       0.00      0.00      0.00         0\n",
      "     1959577       0.00      0.00      0.00         1\n",
      "     1959960       0.00      0.00      0.00         1\n",
      "     1961609       0.00      0.00      0.00         1\n",
      "     1962000       0.00      0.00      0.00         0\n",
      "     1962103       0.00      0.00      0.00         1\n",
      "     1964000       0.00      0.00      0.00         1\n",
      "     1970000       0.00      0.00      0.00         1\n",
      "     1971163       0.00      0.00      0.00         1\n",
      "     1971960       0.00      0.00      0.00         1\n",
      "     1974259       0.00      0.00      0.00         1\n",
      "     1975000       0.00      0.00      0.00         1\n",
      "     1980000       0.00      0.00      0.00         1\n",
      "     1980600       0.00      0.00      0.00         1\n",
      "     1983000       0.00      0.00      0.00         1\n",
      "     1988160       0.00      0.00      0.00         1\n",
      "     1993560       0.00      0.00      0.00         1\n",
      "     2000000       0.02      0.06      0.03        33\n",
      "     2002000       0.00      0.00      0.00         3\n",
      "     2002680       0.00      0.00      0.00         1\n",
      "     2004000       0.00      0.00      0.00         1\n",
      "     2005560       0.00      0.00      0.00         1\n",
      "     2013000       0.00      0.00      0.00         1\n",
      "     2016000       0.00      0.00      0.00         1\n",
      "     2016692       0.00      0.00      0.00         1\n",
      "     2020200       0.00      0.00      0.00         0\n",
      "     2023261       0.00      0.00      0.00         1\n",
      "     2025000       0.00      0.00      0.00         1\n",
      "     2026680       0.00      0.00      0.00         0\n",
      "     2032800       0.00      0.00      0.00         1\n",
      "     2033000       0.00      0.00      0.00         1\n",
      "     2034997       0.00      0.00      0.00         1\n",
      "     2040000       0.00      0.00      0.00         1\n",
      "     2050000       0.00      0.00      0.00         2\n",
      "     2051271       0.00      0.00      0.00         1\n",
      "     2052360       0.00      0.00      0.00         1\n",
      "     2056968       0.00      0.00      0.00         1\n",
      "     2058000       0.00      0.00      0.00         1\n",
      "     2059320       0.00      0.00      0.00         1\n",
      "     2060040       0.00      0.00      0.00         1\n",
      "     2061720       0.00      0.00      0.00         1\n",
      "     2063040       0.00      0.00      0.00         1\n",
      "     2066760       0.00      0.00      0.00         1\n",
      "     2067880       0.00      0.00      0.00         1\n",
      "     2067960       0.00      0.00      0.00         1\n",
      "     2069000       0.00      0.00      0.00         1\n",
      "     2069764       0.00      0.00      0.00         1\n",
      "     2071600       0.00      0.00      0.00         1\n",
      "     2074302       0.00      0.00      0.00         1\n",
      "     2075000       0.00      0.00      0.00         1\n",
      "     2077000       0.00      0.00      0.00         4\n",
      "     2082720       0.00      0.00      0.00         1\n",
      "     2090000       0.00      0.00      0.00         4\n",
      "     2090880       0.00      0.00      0.00         1\n",
      "     2091480       0.00      0.00      0.00         1\n",
      "     2094922       0.00      0.00      0.00         1\n",
      "     2096760       0.00      0.00      0.00         1\n",
      "     2098560       0.00      0.00      0.00         1\n",
      "     2100000       0.00      0.00      0.00         8\n",
      "     2102224       0.00      0.00      0.00         1\n",
      "     2106720       0.00      0.00      0.00         1\n",
      "     2109120       0.00      0.00      0.00         1\n",
      "     2110550       0.00      0.00      0.00         1\n",
      "     2111160       0.00      0.00      0.00         1\n",
      "     2111640       0.00      0.00      0.00         0\n",
      "     2115000       0.00      0.00      0.00         2\n",
      "     2119102       0.00      0.00      0.00         1\n",
      "     2120700       0.00      0.00      0.00         1\n",
      "     2121288       0.00      0.00      0.00         1\n",
      "     2125000       0.00      0.00      0.00         1\n",
      "     2126520       0.00      0.00      0.00         2\n",
      "     2127840       0.00      0.00      0.00         1\n",
      "     2128920       0.00      0.00      0.00         1\n",
      "     2140000       0.00      0.00      0.00         0\n",
      "     2145000       0.00      0.00      0.00         2\n",
      "     2146000       0.00      0.00      0.00         1\n",
      "     2153934       0.00      0.00      0.00         1\n",
      "     2155000       0.00      0.00      0.00         1\n",
      "     2156000       0.00      0.00      0.00         3\n",
      "     2157595       0.00      0.00      0.00         1\n",
      "     2160000       0.00      0.00      0.00         1\n",
      "     2161920       0.00      0.00      0.00         0\n",
      "     2162280       0.00      0.00      0.00         1\n",
      "     2162880       0.00      0.00      0.00         0\n",
      "     2168520       0.00      0.00      0.00         1\n",
      "     2175000       0.00      0.00      0.00         1\n",
      "     2177000       0.00      0.00      0.00         1\n",
      "     2178099       0.00      0.00      0.00         1\n",
      "     2179354       0.00      0.00      0.00         1\n",
      "     2180000       0.00      0.00      0.00         2\n",
      "     2180760       0.00      0.00      0.00         1\n",
      "     2181000       0.00      0.00      0.00         1\n",
      "     2185920       0.00      0.00      0.00         1\n",
      "     2186000       0.00      0.00      0.00         1\n",
      "     2187913       0.00      0.00      0.00         1\n",
      "     2190000       0.00      0.00      0.00         1\n",
      "     2200000       0.00      0.00      0.00        13\n",
      "     2201640       0.00      0.00      0.00         1\n",
      "     2202000       0.00      0.00      0.00         1\n",
      "     2203000       0.00      0.00      0.00         1\n",
      "     2203080       0.00      0.00      0.00         1\n",
      "     2204370       0.00      0.00      0.00         1\n",
      "     2207040       0.00      0.00      0.00         1\n",
      "     2208960       0.00      0.00      0.00         1\n",
      "     2210000       0.00      0.00      0.00         1\n",
      "     2213000       0.00      0.00      0.00         1\n",
      "     2216160       0.00      0.00      0.00         1\n",
      "     2222160       0.00      0.00      0.00         1\n",
      "     2225000       0.00      0.00      0.00         1\n",
      "     2225093       0.00      0.00      0.00         1\n",
      "     2225880       0.00      0.00      0.00         1\n",
      "     2238360       0.00      0.00      0.00         0\n",
      "     2238960       0.00      0.00      0.00         1\n",
      "     2239800       0.00      0.00      0.00         1\n",
      "     2240450       0.00      0.00      0.00         1\n",
      "     2245000       0.00      0.00      0.00         1\n",
      "     2246400       0.00      0.00      0.00         2\n",
      "     2249768       0.00      0.00      0.00         1\n",
      "     2250000       0.00      0.00      0.00         6\n",
      "     2250600       0.00      0.00      0.00         1\n",
      "     2252000       0.00      0.00      0.00         1\n",
      "     2252400       0.00      0.00      0.00         1\n",
      "     2256444       0.00      0.00      0.00         1\n",
      "     2266794       0.00      0.00      0.00         1\n",
      "     2267280       0.00      0.00      0.00         1\n",
      "     2269260       0.00      0.00      0.00         1\n",
      "     2275000       0.00      0.00      0.00         1\n",
      "     2277960       0.00      0.00      0.00         1\n",
      "     2279040       0.00      0.00      0.00         1\n",
      "     2281128       0.00      0.00      0.00         1\n",
      "     2282640       0.00      0.00      0.00         1\n",
      "     2284200       0.00      0.00      0.00         1\n",
      "     2285000       0.00      0.00      0.00         2\n",
      "     2286000       0.00      0.00      0.00         3\n",
      "     2288205       0.00      0.00      0.00         1\n",
      "     2295480       0.00      0.00      0.00         1\n",
      "     2298840       0.00      0.00      0.00         1\n",
      "     2300000       0.00      0.00      0.00         8\n",
      "     2303040       0.00      0.00      0.00         1\n",
      "     2313000       0.00      0.00      0.00         1\n",
      "     2317000       0.00      0.00      0.00         1\n",
      "     2317920       0.00      0.00      0.00         1\n",
      "     2320500       0.00      0.00      0.00         1\n",
      "     2325000       0.00      0.00      0.00         1\n",
      "     2328843       0.00      0.00      0.00         1\n",
      "     2329805       0.00      0.00      0.00         1\n",
      "     2330000       0.00      0.00      0.00         2\n",
      "     2331120       0.00      0.00      0.00         1\n",
      "     2333000       0.00      0.00      0.00         1\n",
      "     2333333       0.00      0.00      0.00         1\n",
      "     2336000       0.00      0.00      0.00         1\n",
      "     2338721       0.00      0.00      0.00         1\n",
      "     2339040       0.00      0.00      0.00         1\n",
      "     2340600       0.00      0.00      0.00         1\n",
      "     2343635       0.00      0.00      0.00         1\n",
      "     2348783       0.00      0.00      0.00         1\n",
      "     2350000       0.00      0.00      0.00         4\n",
      "     2350820       0.00      0.00      0.00         1\n",
      "     2353000       0.00      0.00      0.00         1\n",
      "     2356320       0.00      0.00      0.00         2\n",
      "     2369111       0.00      0.00      0.00         1\n",
      "     2372000       0.00      0.00      0.00         1\n",
      "     2376000       0.00      0.00      0.00         2\n",
      "     2380000       0.00      0.00      0.00         1\n",
      "     2381000       0.00      0.00      0.00         1\n",
      "     2382000       0.00      0.00      0.00         0\n",
      "     2382700       0.00      0.00      0.00         1\n",
      "     2399040       0.00      0.00      0.00         1\n",
      "     2400000       0.00      0.00      0.00        15\n",
      "     2403120       0.00      0.00      0.00         1\n",
      "     2406240       0.00      0.00      0.00         1\n",
      "     2406250       0.00      0.00      0.00         1\n",
      "     2406600       0.00      0.00      0.00         1\n",
      "     2407000       0.00      0.00      0.00         1\n",
      "     2413320       0.00      0.00      0.00         1\n",
      "     2420000       0.00      0.00      0.00         2\n",
      "     2425440       0.00      0.00      0.00         1\n",
      "     2425878       0.00      0.00      0.00         1\n",
      "     2430000       0.00      0.00      0.00         1\n",
      "     2433077       0.00      0.00      0.00         1\n",
      "     2433333       0.00      0.00      0.00         1\n",
      "     2433824       0.00      0.00      0.00         1\n",
      "     2434000       0.00      0.00      0.00         0\n",
      "     2440000       0.00      0.00      0.00         1\n",
      "     2440200       0.00      0.00      0.00         1\n",
      "     2445480       0.00      0.00      0.00         1\n",
      "     2452000       0.00      0.00      0.00         1\n",
      "     2453880       0.00      0.00      0.00         1\n",
      "     2455680       0.00      0.00      0.00         1\n",
      "     2457000       0.00      0.00      0.00         1\n",
      "     2458500       0.00      0.00      0.00         2\n",
      "     2470000       0.00      0.00      0.00         1\n",
      "     2471604       0.00      0.00      0.00         1\n",
      "     2472000       0.00      0.00      0.00         1\n",
      "     2473000       0.00      0.00      0.00         0\n",
      "     2480000       0.00      0.00      0.00         2\n",
      "     2480885       0.00      0.00      0.00         1\n",
      "     2483280       0.00      0.00      0.00         1\n",
      "     2483333       0.00      0.00      0.00         1\n",
      "     2484000       0.00      0.00      0.00         1\n",
      "     2487240       0.00      0.00      0.00         1\n",
      "     2490360       0.00      0.00      0.00         1\n",
      "     2500000       0.00      0.00      0.00        31\n",
      "     2501070       0.00      0.00      0.00         1\n",
      "     2503000       0.00      0.00      0.00         1\n",
      "     2503800       0.00      0.00      0.00         0\n",
      "     2511432       0.00      0.00      0.00         1\n",
      "     2520000       0.00      0.00      0.00         1\n",
      "     2525000       0.00      0.00      0.00         1\n",
      "     2530920       0.00      0.00      0.00         1\n",
      "     2532960       0.00      0.00      0.00         1\n",
      "     2540000       0.00      0.00      0.00         1\n",
      "     2541000       0.00      0.00      0.00         1\n",
      "     2544529       0.00      0.00      0.00         1\n",
      "     2545000       0.00      0.00      0.00         1\n",
      "     2546760       0.00      0.00      0.00         0\n",
      "     2550000       0.00      0.00      0.00         2\n",
      "     2554072       0.00      0.00      0.00         1\n",
      "     2557000       0.00      0.00      0.00         1\n",
      "     2557545       0.00      0.00      0.00         1\n",
      "     2562000       0.00      0.00      0.00         0\n",
      "     2563320       0.00      0.00      0.00         1\n",
      "     2574240       0.00      0.00      0.00         1\n",
      "     2585668       0.00      0.00      0.00         1\n",
      "     2594000       0.00      0.00      0.00         1\n",
      "     2600000       0.00      0.00      0.00         7\n",
      "     2605000       0.00      0.00      0.00         1\n",
      "     2607360       0.00      0.00      0.00         1\n",
      "     2612500       0.00      0.00      0.00         2\n",
      "     2612835       0.00      0.00      0.00         1\n",
      "     2613600       0.00      0.00      0.00         1\n",
      "     2614440       0.00      0.00      0.00         1\n",
      "     2625000       0.00      0.00      0.00         3\n",
      "     2625698       0.00      0.00      0.00         1\n",
      "     2626473       0.00      0.00      0.00         1\n",
      "     2628960       0.00      0.00      0.00         1\n",
      "     2630503       0.00      0.00      0.00         1\n",
      "     2631840       0.00      0.00      0.00         1\n",
      "     2633300       0.00      0.00      0.00         1\n",
      "     2636400       0.00      0.00      0.00         1\n",
      "     2636696       0.00      0.00      0.00         1\n",
      "     2640000       0.00      0.00      0.00         4\n",
      "     2643750       0.00      0.00      0.00         1\n",
      "     2650000       0.00      0.00      0.00         1\n",
      "     2653080       0.00      0.00      0.00         1\n",
      "     2661027       0.00      0.00      0.00         1\n",
      "     2669520       0.00      0.00      0.00         1\n",
      "     2670000       0.00      0.00      0.00         1\n",
      "     2676000       0.00      0.00      0.00         1\n",
      "     2678000       0.00      0.00      0.00         1\n",
      "     2681880       0.00      0.00      0.00         1\n",
      "     2695164       0.00      0.00      0.00         1\n",
      "     2696956       0.00      0.00      0.00         1\n",
      "     2700000       0.00      0.00      0.00         5\n",
      "     2703960       0.00      0.00      0.00         1\n",
      "     2704350       0.00      0.00      0.00         1\n",
      "     2715000       0.00      0.00      0.00         1\n",
      "     2716667       0.00      0.00      0.00         1\n",
      "     2717161       0.00      0.00      0.00         1\n",
      "     2721000       0.00      0.00      0.00         1\n",
      "     2721255       0.00      0.00      0.00         1\n",
      "     2725920       0.00      0.00      0.00         1\n",
      "     2730000       0.00      0.00      0.00         2\n",
      "     2732000       0.00      0.00      0.00         1\n",
      "     2739669       0.00      0.00      0.00         1\n",
      "     2742000       0.00      0.00      0.00         1\n",
      "     2750000       0.00      0.00      0.00         4\n",
      "     2751260       0.00      0.00      0.00         1\n",
      "     2751360       0.00      0.00      0.00         1\n",
      "     2753218       0.00      0.00      0.00         1\n",
      "     2755560       0.00      0.00      0.00         1\n",
      "     2763000       0.00      0.00      0.00         1\n",
      "     2767126       0.00      0.00      0.00         1\n",
      "     2770800       0.00      0.00      0.00         0\n",
      "     2772480       0.00      0.00      0.00         1\n",
      "     2775000       0.00      0.00      0.00         2\n",
      "     2780400       0.00      0.00      0.00         1\n",
      "     2789280       0.00      0.00      0.00         1\n",
      "     2793505       0.00      0.00      0.00         1\n",
      "     2798040       0.00      0.00      0.00         2\n",
      "     2800000       0.00      0.00      0.00         8\n",
      "     2801198       0.00      0.00      0.00         1\n",
      "     2804889       0.00      0.00      0.00         1\n",
      "     2809494       0.00      0.00      0.00         1\n",
      "     2812006       0.00      0.00      0.00         1\n",
      "     2812500       0.00      0.00      0.00         1\n",
      "     2815560       0.00      0.00      0.00         1\n",
      "     2819044       0.00      0.00      0.00         1\n",
      "     2819880       0.00      0.00      0.00         1\n",
      "     2837000       0.00      0.00      0.00         1\n",
      "     2843000       0.00      0.00      0.00         1\n",
      "     2847360       0.00      0.00      0.00         1\n",
      "     2850000       0.00      0.00      0.00         2\n",
      "     2855760       0.00      0.00      0.00         1\n",
      "     2857144       0.00      0.00      0.00         1\n",
      "     2858057       0.00      0.00      0.00         1\n",
      "     2863920       0.00      0.00      0.00         1\n",
      "     2869440       0.00      0.00      0.00         1\n",
      "     2870000       0.00      0.00      0.00         1\n",
      "     2873520       0.00      0.00      0.00         1\n",
      "     2873750       0.00      0.00      0.00         1\n",
      "     2875000       0.00      0.00      0.00         1\n",
      "     2880000       0.00      0.00      0.00         2\n",
      "     2894059       0.00      0.00      0.00         1\n",
      "     2895960       0.00      0.00      0.00         1\n",
      "     2898000       0.00      0.00      0.00         3\n",
      "     2900000       0.00      0.00      0.00         6\n",
      "     2915000       0.00      0.00      0.00         1\n",
      "     2923000       0.00      0.00      0.00         0\n",
      "     2923920       0.00      0.00      0.00         1\n",
      "     2925000       0.00      0.00      0.00         4\n",
      "     2929467       0.00      0.00      0.00         1\n",
      "     2947440       0.00      0.00      0.00         1\n",
      "     2950000       0.00      0.00      0.00         1\n",
      "     2950200       0.00      0.00      0.00         1\n",
      "     2951029       0.00      0.00      0.00         1\n",
      "     2960000       0.00      0.00      0.00         1\n",
      "     2969880       0.00      0.00      0.00         1\n",
      "     2970840       0.00      0.00      0.00         1\n",
      "     2978250       0.00      0.00      0.00         1\n",
      "     2978500       0.00      0.00      0.00         1\n",
      "     2990000       0.00      0.00      0.00         2\n",
      "     2995421       0.00      0.00      0.00         1\n",
      "     2997360       0.00      0.00      0.00         1\n",
      "     3000000       0.02      0.11      0.03        37\n",
      "     3004560       0.00      0.00      0.00         1\n",
      "     3007920       0.00      0.00      0.00         1\n",
      "     3016680       0.00      0.00      0.00         1\n",
      "     3024000       0.00      0.00      0.00         1\n",
      "     3025000       0.00      0.00      0.00         1\n",
      "     3027840       0.00      0.00      0.00         1\n",
      "     3031920       0.00      0.00      0.00         1\n",
      "     3033000       0.00      0.00      0.00         1\n",
      "     3034356       0.00      0.00      0.00         1\n",
      "     3039000       0.00      0.00      0.00         0\n",
      "     3047000       0.00      0.00      0.00         1\n",
      "     3057000       0.00      0.00      0.00         1\n",
      "     3059000       0.00      0.00      0.00         1\n",
      "     3060840       0.00      0.00      0.00         1\n",
      "     3065040       0.00      0.00      0.00         2\n",
      "     3068000       0.00      0.00      0.00         2\n",
      "     3073032       0.00      0.00      0.00         1\n",
      "     3075880       0.00      0.00      0.00         1\n",
      "     3089040       0.00      0.00      0.00         1\n",
      "     3090000       0.00      0.00      0.00         3\n",
      "     3100000       0.00      0.00      0.00         5\n",
      "     3102240       0.00      0.00      0.00         1\n",
      "     3103000       0.00      0.00      0.00         1\n",
      "     3117120       0.00      0.00      0.00         1\n",
      "     3120000       0.00      0.00      0.00         2\n",
      "     3125000       0.00      0.00      0.00         1\n",
      "     3129720       0.00      0.00      0.00         1\n",
      "     3132240       0.00      0.00      0.00         1\n",
      "     3140000       0.00      0.00      0.00         1\n",
      "     3150000       0.00      0.00      0.00         4\n",
      "     3164280       0.00      0.00      0.00         1\n",
      "     3175000       0.00      0.00      0.00         1\n",
      "     3180000       0.00      0.00      0.00         1\n",
      "     3183000       0.00      0.00      0.00         2\n",
      "     3184900       0.00      0.00      0.00         1\n",
      "     3194400       0.00      0.00      0.00         1\n",
      "     3200000       0.00      0.00      0.00         4\n",
      "     3202920       0.00      0.00      0.00         1\n",
      "     3206000       0.00      0.00      0.00         1\n",
      "     3210840       0.00      0.00      0.00         1\n",
      "     3212402       0.00      0.00      0.00         1\n",
      "     3217680       0.00      0.00      0.00         1\n",
      "     3229050       0.00      0.00      0.00         1\n",
      "     3233000       0.00      0.00      0.00         1\n",
      "     3240000       0.00      0.00      0.00         2\n",
      "     3240380       0.00      0.00      0.00         1\n",
      "     3244000       0.00      0.00      0.00         1\n",
      "     3246960       0.00      0.00      0.00         1\n",
      "     3250000       0.00      0.00      0.00         6\n",
      "     3260000       0.00      0.00      0.00         1\n",
      "     3267120       0.00      0.00      0.00         1\n",
      "     3267960       0.00      0.00      0.00         1\n",
      "     3272091       0.00      0.00      0.00         1\n",
      "     3278000       0.00      0.00      0.00         1\n",
      "     3287640       0.00      0.00      0.00         1\n",
      "     3300000       0.00      0.00      0.00         3\n",
      "     3302000       0.00      0.00      0.00         1\n",
      "     3308160       0.00      0.00      0.00         0\n",
      "     3308516       0.00      0.00      0.00         1\n",
      "     3315000       0.00      0.00      0.00         1\n",
      "     3315120       0.00      0.00      0.00         1\n",
      "     3333000       0.00      0.00      0.00         0\n",
      "     3333333       0.00      0.00      0.00         3\n",
      "     3333334       0.00      0.00      0.00         1\n",
      "     3336000       0.00      0.00      0.00         1\n",
      "     3343896       0.00      0.00      0.00         1\n",
      "     3344000       0.00      0.00      0.00         1\n",
      "     3344250       0.00      0.00      0.00         1\n",
      "     3348000       0.00      0.00      0.00         2\n",
      "     3360390       0.00      0.00      0.00         1\n",
      "     3371393       0.00      0.00      0.00         1\n",
      "     3377160       0.00      0.00      0.00         1\n",
      "     3377604       0.00      0.00      0.00         1\n",
      "     3380000       0.00      0.00      0.00         1\n",
      "     3380160       0.00      0.00      0.00         1\n",
      "     3386598       0.00      0.00      0.00         1\n",
      "     3388176       0.00      0.00      0.00         1\n",
      "     3390000       0.00      0.00      0.00         1\n",
      "     3396250       0.00      0.00      0.00         1\n",
      "     3398280       0.00      0.00      0.00         1\n",
      "     3400000       0.00      0.00      0.00         6\n",
      "     3401040       0.00      0.00      0.00         1\n",
      "     3413793       0.00      0.00      0.00         1\n",
      "     3414720       0.00      0.00      0.00         1\n",
      "     3417000       0.00      0.00      0.00         1\n",
      "     3425000       0.00      0.00      0.00         1\n",
      "     3425760       0.00      0.00      0.00         1\n",
      "     3428572       0.00      0.00      0.00         1\n",
      "     3440000       0.00      0.00      0.00         1\n",
      "     3441900       0.00      0.00      0.00         1\n",
      "     3448050       0.00      0.00      0.00         1\n",
      "     3450000       0.00      0.00      0.00         2\n",
      "     3451920       0.00      0.00      0.00         1\n",
      "     3455000       0.00      0.00      0.00         1\n",
      "     3457800       0.00      0.00      0.00         1\n",
      "     3463200       0.00      0.00      0.00         0\n",
      "     3470770       0.00      0.00      0.00         1\n",
      "     3471360       0.00      0.00      0.00         1\n",
      "     3472000       0.00      0.00      0.00         1\n",
      "     3473520       0.00      0.00      0.00         1\n",
      "     3475000       0.00      0.00      0.00         1\n",
      "     3481920       0.00      0.00      0.00         1\n",
      "     3487400       0.00      0.00      0.00         1\n",
      "     3488000       0.00      0.00      0.00         1\n",
      "     3500000       0.00      0.00      0.00        15\n",
      "     3505320       0.00      0.00      0.00         1\n",
      "     3517200       0.00      0.00      0.00         1\n",
      "     3525000       0.00      0.00      0.00         1\n",
      "     3532000       0.00      0.00      0.00         1\n",
      "     3541000       0.00      0.00      0.00         1\n",
      "     3542500       0.00      0.00      0.00         1\n",
      "     3543000       0.00      0.00      0.00         1\n",
      "     3551000       0.00      0.00      0.00         1\n",
      "     3552000       0.00      0.00      0.00         1\n",
      "     3553917       0.00      0.00      0.00         1\n",
      "     3557585       0.00      0.00      0.00         1\n",
      "     3560000       0.00      0.00      0.00         1\n",
      "     3563600       0.00      0.00      0.00         1\n",
      "     3567096       0.00      0.00      0.00         1\n",
      "     3574300       0.00      0.00      0.00         1\n",
      "     3575000       0.00      0.00      0.00         1\n",
      "     3575761       0.00      0.00      0.00         1\n",
      "     3579131       0.00      0.00      0.00         1\n",
      "     3580000       0.00      0.00      0.00         1\n",
      "     3587000       0.00      0.00      0.00         1\n",
      "     3588000       0.00      0.00      0.00         1\n",
      "     3594000       0.00      0.00      0.00         1\n",
      "     3595800       0.00      0.00      0.00         1\n",
      "     3596000       0.00      0.00      0.00         1\n",
      "     3600000       0.00      0.00      0.00         9\n",
      "     3610000       0.00      0.00      0.00         2\n",
      "     3610200       0.00      0.00      0.00         1\n",
      "     3615000       0.00      0.00      0.00         1\n",
      "     3616680       0.00      0.00      0.00         1\n",
      "     3629160       0.00      0.00      0.00         1\n",
      "     3630000       0.00      0.00      0.00         1\n",
      "     3633000       0.00      0.00      0.00         1\n",
      "     3640000       0.00      0.00      0.00         1\n",
      "     3650000       0.00      0.00      0.00         1\n",
      "     3657500       0.00      0.00      0.00         1\n",
      "     3666666       0.00      0.00      0.00         2\n",
      "     3675000       0.00      0.00      0.00         1\n",
      "     3678319       0.00      0.00      0.00         1\n",
      "     3680000       0.00      0.00      0.00         2\n",
      "     3687000       0.00      0.00      0.00         1\n",
      "     3695857       0.00      0.00      0.00         1\n",
      "     3697440       0.00      0.00      0.00         0\n",
      "     3700748       0.00      0.00      0.00         1\n",
      "     3703000       0.00      0.00      0.00         1\n",
      "     3726600       0.00      0.00      0.00         1\n",
      "     3726994       0.00      0.00      0.00         1\n",
      "     3739680       0.00      0.00      0.00         1\n",
      "     3741120       0.00      0.00      0.00         1\n",
      "     3749040       0.00      0.00      0.00         1\n",
      "     3750000       0.00      0.00      0.00         9\n",
      "     3752000       0.00      0.00      0.00         1\n",
      "     3755142       0.00      0.00      0.00         1\n",
      "     3755640       0.00      0.00      0.00         1\n",
      "     3762500       0.00      0.00      0.00         1\n",
      "     3765000       0.00      0.00      0.00         2\n",
      "     3780000       0.00      0.00      0.00         1\n",
      "     3792817       0.00      0.00      0.00         1\n",
      "     3800000       0.00      0.00      0.00         2\n",
      "     3801960       0.00      0.00      0.00         1\n",
      "     3809524       0.00      0.00      0.00         1\n",
      "     3810000       0.00      0.00      0.00         1\n",
      "     3818750       0.00      0.00      0.00         1\n",
      "     3830000       0.00      0.00      0.00         1\n",
      "     3840000       0.00      0.00      0.00         1\n",
      "     3841443       0.00      0.00      0.00         1\n",
      "     3850000       0.00      0.00      0.00         3\n",
      "     3860000       0.00      0.00      0.00         1\n",
      "     3862080       0.00      0.00      0.00         1\n",
      "     3867282       0.00      0.00      0.00         1\n",
      "     3873398       0.00      0.00      0.00         1\n",
      "     3882360       0.00      0.00      0.00         1\n",
      "     3883560       0.00      0.00      0.00         1\n",
      "     3884678       0.00      0.00      0.00         1\n",
      "     3894240       0.00      0.00      0.00         1\n",
      "     3898692       0.00      0.00      0.00         1\n",
      "     3900000       0.00      0.00      0.00         3\n",
      "     3937500       0.00      0.00      0.00         1\n",
      "     3938000       0.00      0.00      0.00         1\n",
      "     3940000       0.00      0.00      0.00         1\n",
      "     3941000       0.00      0.00      0.00         1\n",
      "     3950000       0.00      0.00      0.00         1\n",
      "     3957143       0.00      0.00      0.00         1\n",
      "     3958742       0.00      0.00      0.00         1\n",
      "     3960000       0.00      0.00      0.00         1\n",
      "     4000000       0.03      0.18      0.05        39\n",
      "     4002000       0.00      0.00      0.00         1\n",
      "     4006080       0.00      0.00      0.00         1\n",
      "     4008882       0.00      0.00      0.00         1\n",
      "     4010000       0.00      0.00      0.00         1\n",
      "     4015334       0.00      0.00      0.00         1\n",
      "     4025000       0.00      0.00      0.00         1\n",
      "     4027320       0.00      0.00      0.00         0\n",
      "     4030000       0.00      0.00      0.00         1\n",
      "     4050000       0.00      0.00      0.00         3\n",
      "     4051024       0.00      0.00      0.00         1\n",
      "     4053000       0.00      0.00      0.00         1\n",
      "     4054160       0.00      0.00      0.00         1\n",
      "     4060000       0.00      0.00      0.00         1\n",
      "     4062000       0.00      0.00      0.00         0\n",
      "     4064373       0.00      0.00      0.00         1\n",
      "     4100000       0.00      0.00      0.00         1\n",
      "     4110000       0.00      0.00      0.00         1\n",
      "     4125000       0.00      0.00      0.00         2\n",
      "     4126600       0.00      0.00      0.00         1\n",
      "     4133280       0.00      0.00      0.00         3\n",
      "     4160000       0.00      0.00      0.00         1\n",
      "     4164100       0.00      0.00      0.00         1\n",
      "     4172432       0.00      0.00      0.00         1\n",
      "     4174800       0.00      0.00      0.00         1\n",
      "     4186542       0.00      0.00      0.00         1\n",
      "     4190182       0.00      0.00      0.00         1\n",
      "     4190476       0.00      0.00      0.00         1\n",
      "     4200000       0.00      0.00      0.00         5\n",
      "     4212000       0.00      0.00      0.00         1\n",
      "     4225200       0.00      0.00      0.00         1\n",
      "     4228000       0.00      0.00      0.00         1\n",
      "     4234000       0.00      0.00      0.00         1\n",
      "     4250000       0.00      0.00      0.00         7\n",
      "     4251250       0.00      0.00      0.00         1\n",
      "     4252000       0.00      0.00      0.00         1\n",
      "     4257973       0.00      0.00      0.00         1\n",
      "     4260000       0.00      0.00      0.00         1\n",
      "     4264900       0.00      0.00      0.00         1\n",
      "     4266000       0.00      0.00      0.00         1\n",
      "     4276320       0.00      0.00      0.00         1\n",
      "     4278000       0.00      0.00      0.00         1\n",
      "     4285560       0.00      0.00      0.00         1\n",
      "     4290000       0.00      0.00      0.00         1\n",
      "     4295000       0.00      0.00      0.00         1\n",
      "     4300000       0.00      0.00      0.00         2\n",
      "     4305000       0.00      0.00      0.00         0\n",
      "     4307640       0.00      0.00      0.00         1\n",
      "     4318481       0.00      0.00      0.00         1\n",
      "     4320000       0.00      0.00      0.00         2\n",
      "     4333000       0.00      0.00      0.00         1\n",
      "     4344000       0.00      0.00      0.00         1\n",
      "     4347826       0.00      0.00      0.00         1\n",
      "     4350000       0.00      0.00      0.00         4\n",
      "     4370000       0.00      0.00      0.00         1\n",
      "     4390000       0.00      0.00      0.00         1\n",
      "     4394225       0.00      0.00      0.00         1\n",
      "     4400000       0.00      0.00      0.00         4\n",
      "     4408000       0.00      0.00      0.00         1\n",
      "     4413375       0.00      0.00      0.00         1\n",
      "     4433334       0.00      0.00      0.00         1\n",
      "     4443360       0.00      0.00      0.00         1\n",
      "     4448000       0.00      0.00      0.00         1\n",
      "     4458840       0.00      0.00      0.00         1\n",
      "     4466040       0.00      0.00      0.00         1\n",
      "     4469548       0.00      0.00      0.00         1\n",
      "     4483516       0.00      0.00      0.00         0\n",
      "     4500000       0.00      0.00      0.00        11\n",
      "     4501200       0.00      0.00      0.00         1\n",
      "     4505280       0.00      0.00      0.00         1\n",
      "     4533300       0.00      0.00      0.00         1\n",
      "     4538000       0.00      0.00      0.00         1\n",
      "     4546000       0.00      0.00      0.00         3\n",
      "     4550000       0.00      0.00      0.00         2\n",
      "     4560000       0.00      0.00      0.00         1\n",
      "     4574189       0.00      0.00      0.00         1\n",
      "     4582680       0.00      0.00      0.00         1\n",
      "     4592418       0.00      0.00      0.00         1\n",
      "     4598000       0.00      0.00      0.00         1\n",
      "     4600000       0.00      0.00      0.00         2\n",
      "     4602720       0.00      0.00      0.00         0\n",
      "     4605196       0.00      0.00      0.00         1\n",
      "     4609701       0.00      0.00      0.00         1\n",
      "     4621800       0.00      0.00      0.00         1\n",
      "     4640000       0.00      0.00      0.00         2\n",
      "     4643000       0.00      0.00      0.00         0\n",
      "     4649534       0.00      0.00      0.00         1\n",
      "     4660482       0.00      0.00      0.00         1\n",
      "     4665960       0.00      0.00      0.00         1\n",
      "     4680000       0.00      0.00      0.00         1\n",
      "     4690000       0.00      0.00      0.00         1\n",
      "     4694041       0.00      0.00      0.00         1\n",
      "     4700000       0.00      0.00      0.00         1\n",
      "     4702000       0.00      0.00      0.00         1\n",
      "     4702500       0.00      0.00      0.00         1\n",
      "     4725000       0.00      0.00      0.00         1\n",
      "     4750000       0.00      0.00      0.00         3\n",
      "     4752000       0.00      0.00      0.00         1\n",
      "     4781250       0.00      0.00      0.00         1\n",
      "     4796880       0.00      0.00      0.00         1\n",
      "     4799108       0.00      0.00      0.00         1\n",
      "     4800000       0.00      0.00      0.00         5\n",
      "     4801102       0.00      0.00      0.00         1\n",
      "     4809840       0.00      0.00      0.00         1\n",
      "     4818000       0.00      0.00      0.00         1\n",
      "     4822800       0.00      0.00      0.00         1\n",
      "     4831461       0.00      0.00      0.00         1\n",
      "     4833333       0.00      0.00      0.00         1\n",
      "     4837633       0.00      0.00      0.00         1\n",
      "     4840000       0.00      0.00      0.00         1\n",
      "     4847586       0.00      0.00      0.00         1\n",
      "     4860000       0.00      0.00      0.00         1\n",
      "     4881669       0.00      0.00      0.00         1\n",
      "     4895656       0.00      0.00      0.00         1\n",
      "     4899293       0.00      0.00      0.00         1\n",
      "     4900000       0.00      0.00      0.00         2\n",
      "     4903750       0.00      0.00      0.00         2\n",
      "     4917000       0.00      0.00      0.00         2\n",
      "     4947840       0.00      0.00      0.00         1\n",
      "     4962240       0.00      0.00      0.00         1\n",
      "     4972500       0.00      0.00      0.00         1\n",
      "     4985001       0.00      0.00      0.00         1\n",
      "     4991800       0.00      0.00      0.00         3\n",
      "     4992900       0.00      0.00      0.00         1\n",
      "     5000000       0.02      0.12      0.04        25\n",
      "     5000600       0.00      0.00      0.00         2\n",
      "     5004000       0.00      0.00      0.00         1\n",
      "     5039068       0.00      0.00      0.00         1\n",
      "     5040000       0.00      0.00      0.00         1\n",
      "     5050000       0.00      0.00      0.00         1\n",
      "     5060000       0.00      0.00      0.00         1\n",
      "     5062500       0.00      0.00      0.00         1\n",
      "     5070686       0.00      0.00      0.00         1\n",
      "     5075000       0.00      0.00      0.00         0\n",
      "     5082416       0.00      0.00      0.00         1\n",
      "     5095088       0.00      0.00      0.00         1\n",
      "     5103120       0.00      0.00      0.00         1\n",
      "     5117880       0.00      0.00      0.00         1\n",
      "     5125088       0.00      0.00      0.00         1\n",
      "     5128689       0.00      0.00      0.00         1\n",
      "     5130000       0.00      0.00      0.00         0\n",
      "     5138430       0.00      0.00      0.00         0\n",
      "     5144280       0.06      1.00      0.11         1\n",
      "     5152440       0.00      0.00      0.00         1\n",
      "     5200000       0.00      0.00      0.00         4\n",
      "     5223333       0.00      0.00      0.00         1\n",
      "     5236000       0.00      0.00      0.00         1\n",
      "     5238750       0.00      0.00      0.00         1\n",
      "     5250000       0.00      0.00      0.00         3\n",
      "     5251825       0.00      0.00      0.00         1\n",
      "     5259697       0.00      0.00      0.00         1\n",
      "     5281680       0.00      0.00      0.00         1\n",
      "     5293080       0.00      0.00      0.00         1\n",
      "     5300000       0.00      0.00      0.00         3\n",
      "     5318313       0.00      0.00      0.00         1\n",
      "     5318437       0.00      0.00      0.00         1\n",
      "     5332800       0.00      0.00      0.00         1\n",
      "     5333000       0.00      0.00      0.00         0\n",
      "     5356000       0.00      0.00      0.00         2\n",
      "     5361873       0.00      0.00      0.00         0\n",
      "     5375760       0.00      0.00      0.00         1\n",
      "     5393300       0.00      0.00      0.00         3\n",
      "     5394125       0.00      0.00      0.00         2\n",
      "     5400000       0.00      0.00      0.00         6\n",
      "     5401906       0.00      0.00      0.00         1\n",
      "     5408700       0.00      0.00      0.00         1\n",
      "     5410000       0.00      0.00      0.00         1\n",
      "     5444857       0.00      0.00      0.00         1\n",
      "     5445600       0.00      0.00      0.00         2\n",
      "     5450000       0.00      0.00      0.00         1\n",
      "     5455200       0.00      0.00      0.00         0\n",
      "     5456000       0.00      0.00      0.00         1\n",
      "     5462500       0.00      0.00      0.00         1\n",
      "     5486250       0.00      0.00      0.00         1\n",
      "     5500000       0.00      0.00      0.00        14\n",
      "     5501196       0.00      0.00      0.00         1\n",
      "     5510000       0.00      0.00      0.00         1\n",
      "     5510640       0.00      0.00      0.00         1\n",
      "     5525000       0.00      0.00      0.00         1\n",
      "     5530080       0.00      0.00      0.00         0\n",
      "     5543116       0.00      0.00      0.00         1\n",
      "     5543725       0.00      0.00      0.00         2\n",
      "     5544370       0.00      0.00      0.00         1\n",
      "     5546160       0.00      0.00      0.00         1\n",
      "     5585000       0.00      0.00      0.00         3\n",
      "     5600000       0.00      0.00      0.00         5\n",
      "     5607240       0.00      0.00      0.00         1\n",
      "     5610000       0.00      0.00      0.00         1\n",
      "     5625000       0.00      0.00      0.00         1\n",
      "     5628000       0.00      0.00      0.00         3\n",
      "     5630000       0.00      0.00      0.00         1\n",
      "     5632200       0.00      0.00      0.00         3\n",
      "     5636143       0.00      0.00      0.00         1\n",
      "     5680000       0.00      0.00      0.00         1\n",
      "     5694674       0.00      0.00      0.00         0\n",
      "     5695715       0.00      0.00      0.00         1\n",
      "     5731080       0.00      0.00      0.00         1\n",
      "     5746000       0.00      0.00      0.00         1\n",
      "     5750000       0.00      0.00      0.00         3\n",
      "     5758680       0.00      0.00      0.00         1\n",
      "     5762575       0.00      0.00      0.00         1\n",
      "     5784480       0.00      0.00      0.00         1\n",
      "     5792250       0.00      0.00      0.00         1\n",
      "     5800000       0.00      0.00      0.00         3\n",
      "     5820417       0.00      0.00      0.00         1\n",
      "     5828090       0.00      0.00      0.00         1\n",
      "     5831326       0.00      0.00      0.00         1\n",
      "     5844827       0.00      0.00      0.00         1\n",
      "     5850000       0.00      0.00      0.00         1\n",
      "     5854000       0.00      0.00      0.00         1\n",
      "     5883600       0.00      0.00      0.00         3\n",
      "     5884500       0.00      0.00      0.00         2\n",
      "     5899400       0.00      0.00      0.00         1\n",
      "     5900000       0.00      0.00      0.00         1\n",
      "     5900700       0.00      0.00      0.00         1\n",
      "     5910000       0.00      0.00      0.00         1\n",
      "     5915880       0.00      0.00      0.00         1\n",
      "     5953000       0.00      0.00      0.00         1\n",
      "     5987500       0.00      0.00      0.00         1\n",
      "     6000000       0.00      0.00      0.00        12\n",
      "     6006600       0.00      0.00      0.00         1\n",
      "     6016965       0.00      0.00      0.00         1\n",
      "     6030000       0.00      0.00      0.00         1\n",
      "     6031800       0.00      0.00      0.00         2\n",
      "     6048000       0.00      0.00      0.00         1\n",
      "     6050000       0.00      0.00      0.00         1\n",
      "     6061213       0.00      0.00      0.00         1\n",
      "     6091363       0.00      0.00      0.00         1\n",
      "     6100000       0.00      0.00      0.00         1\n",
      "     6120000       0.00      0.00      0.00         1\n",
      "     6125000       0.00      0.00      0.00         2\n",
      "     6138888       0.00      0.00      0.00         1\n",
      "     6187500       0.00      0.00      0.00         1\n",
      "     6200000       0.00      0.00      0.00         3\n",
      "     6212960       0.00      0.00      0.00         1\n",
      "     6226200       0.00      0.00      0.00         1\n",
      "     6235000       0.00      0.00      0.00         1\n",
      "     6250000       0.00      0.00      0.00         3\n",
      "     6262347       0.00      0.00      0.00         1\n",
      "     6270000       0.00      0.00      0.00         1\n",
      "     6274937       0.00      0.00      0.00         1\n",
      "     6292135       0.00      0.00      0.00         1\n",
      "     6299000       0.00      0.00      0.00         1\n",
      "     6300000       0.00      0.00      0.00         4\n",
      "     6310000       0.00      0.00      0.00         1\n",
      "     6325000       0.00      0.00      0.00         1\n",
      "     6331404       0.00      0.00      0.00         1\n",
      "     6333333       0.00      0.00      0.00         1\n",
      "     6350000       0.00      0.00      0.00         1\n",
      "     6353200       0.00      0.00      0.00         1\n",
      "     6364400       0.00      0.00      0.00         2\n",
      "     6375000       0.00      0.00      0.00         1\n",
      "     6400000       0.00      0.00      0.00         1\n",
      "     6404750       0.00      0.00      0.00         1\n",
      "     6431250       0.00      0.00      0.00         1\n",
      "     6480000       0.00      0.00      0.00         1\n",
      "     6500000       0.00      0.00      0.00         4\n",
      "     6525000       0.00      0.00      0.00         1\n",
      "     6541000       0.00      0.00      0.00         1\n",
      "     6545000       0.00      0.00      0.00         1\n",
      "     6575000       0.00      0.00      0.00         1\n",
      "     6585000       0.00      0.00      0.00         2\n",
      "     6596990       0.00      0.00      0.00         1\n",
      "     6600000       0.00      0.00      0.00         2\n",
      "     6601125       0.00      0.00      0.00         1\n",
      "     6603500       0.00      0.00      0.00         1\n",
      "     6645402       0.00      0.00      0.00         1\n",
      "     6655000       0.00      0.00      0.00         1\n",
      "     6666667       0.00      0.00      0.00         2\n",
      "     6667000       0.00      0.00      0.00         1\n",
      "     6679867       0.00      0.00      0.00         1\n",
      "     6696000       0.00      0.00      0.00         1\n",
      "     6700000       0.00      0.00      0.00         1\n",
      "     6730800       0.00      0.00      0.00         1\n",
      "     6749260       0.00      0.00      0.00         1\n",
      "     6750000       0.00      0.00      0.00         5\n",
      "     6757913       0.00      0.00      0.00         1\n",
      "     6760563       0.00      0.00      0.00         1\n",
      "     6764045       0.00      0.00      0.00         1\n",
      "     6790640       0.00      0.00      0.00         1\n",
      "     6800000       0.00      0.00      0.00         1\n",
      "     6807000       0.00      0.00      0.00         1\n",
      "     6850000       0.00      0.00      0.00         1\n",
      "     6858500       0.00      0.00      0.00         1\n",
      "     6864200       0.00      0.00      0.00         1\n",
      "     6900000       0.00      0.00      0.00         1\n",
      "     6906250       0.00      0.00      0.00         1\n",
      "     6925400       0.00      0.00      0.00         1\n",
      "     6939000       0.00      0.00      0.00         1\n",
      "     6940000       0.00      0.00      0.00         1\n",
      "     6957500       0.00      0.00      0.00         1\n",
      "     6993708       0.00      0.00      0.00         1\n",
      "     7000000       0.00      0.00      0.00        18\n",
      "     7010000       0.00      0.00      0.00         1\n",
      "     7020000       0.00      0.00      0.00         1\n",
      "     7070730       0.00      0.00      0.00         1\n",
      "     7085000       0.00      0.00      0.00         1\n",
      "     7100000       0.00      0.00      0.00         2\n",
      "     7123626       0.00      0.00      0.00         1\n",
      "     7150000       0.00      0.00      0.00         2\n",
      "     7151183       0.00      0.00      0.00         1\n",
      "     7166666       0.00      0.00      0.00         1\n",
      "     7187500       0.00      0.00      0.00         1\n",
      "     7200000       0.00      0.00      0.00         3\n",
      "     7222000       0.00      0.00      0.00         0\n",
      "     7238606       0.00      0.00      0.00         1\n",
      "     7250000       0.00      0.00      0.00         1\n",
      "     7258960       0.00      0.00      0.00         2\n",
      "     7280000       0.00      0.00      0.00         1\n",
      "     7300000       0.00      0.00      0.00         3\n",
      "     7305765       0.00      0.00      0.00         1\n",
      "     7312500       0.00      0.00      0.00         1\n",
      "     7333333       0.00      0.00      0.00         1\n",
      "     7344000       0.00      0.00      0.00         1\n",
      "     7365079       0.00      0.00      0.00         1\n",
      "     7370000       0.00      0.00      0.00         1\n",
      "     7372200       0.00      0.00      0.00         1\n",
      "     7375500       0.00      0.00      0.00         1\n",
      "     7400000       0.00      0.00      0.00         2\n",
      "     7405300       0.00      0.00      0.00         1\n",
      "     7437500       0.00      0.00      0.00         1\n",
      "     7438000       0.00      0.00      0.00         1\n",
      "     7500000       0.00      0.00      0.00         6\n",
      "     7520000       0.00      0.00      0.00         1\n",
      "     7525000       0.00      0.00      0.00         1\n",
      "     7560000       0.00      0.00      0.00         1\n",
      "     7600000       0.00      0.00      0.00         1\n",
      "     7624500       0.00      0.00      0.00         1\n",
      "     7643979       0.00      0.00      0.00         1\n",
      "     7655503       0.00      0.00      0.00         1\n",
      "     7700000       0.00      0.00      0.00         5\n",
      "     7727280       0.00      0.00      0.00         2\n",
      "     7730337       0.00      0.00      0.00         1\n",
      "     7750000       0.00      0.00      0.00         2\n",
      "     7794000       0.00      0.00      0.00         1\n",
      "     7800000       0.00      0.00      0.00         2\n",
      "     7812500       0.00      0.00      0.00         1\n",
      "     7840000       0.00      0.00      0.00         1\n",
      "     7842000       0.00      0.00      0.00         1\n",
      "     7900000       0.00      0.00      0.00         2\n",
      "     7906783       0.00      0.00      0.00         1\n",
      "     7974482       0.00      0.00      0.00         1\n",
      "     7992000       0.00      0.00      0.00         1\n",
      "     8000000       0.03      0.29      0.06        14\n",
      "     8000001       0.00      0.00      0.00         1\n",
      "     8022449       0.00      0.00      0.00         1\n",
      "     8037037       0.00      0.00      0.00         1\n",
      "     8046500       0.00      0.00      0.00         1\n",
      "     8100000       0.00      0.00      0.00         1\n",
      "     8200000       0.00      0.00      0.00         1\n",
      "     8218990       0.00      0.00      0.00         1\n",
      "     8219009       0.00      0.00      0.00         1\n",
      "     8250000       0.00      0.00      0.00         1\n",
      "     8287500       0.00      0.00      0.00         1\n",
      "     8300000       0.00      0.00      0.00         1\n",
      "     8333333       0.00      0.00      0.00         1\n",
      "     8344497       0.00      0.00      0.00         1\n",
      "     8353000       0.00      0.00      0.00         1\n",
      "     8367187       0.00      0.00      0.00         1\n",
      "     8368182       0.00      0.00      0.00         1\n",
      "     8370000       0.00      0.00      0.00         1\n",
      "     8374646       0.00      0.00      0.00         3\n",
      "     8375000       0.00      0.00      0.00         1\n",
      "     8400000       0.00      0.00      0.00         2\n",
      "     8425625       0.00      0.00      0.00         1\n",
      "     8433334       0.00      0.00      0.00         1\n",
      "     8470000       0.00      0.00      0.00         1\n",
      "     8477437       0.00      0.00      0.00         1\n",
      "     8491500       0.00      0.00      0.00         1\n",
      "     8500000       0.00      0.00      0.00         7\n",
      "     8550000       0.00      0.00      0.00         1\n",
      "     8562500       0.00      0.00      0.00         1\n",
      "     8600000       0.00      0.00      0.00         1\n",
      "     8625000       0.00      0.00      0.00         1\n",
      "     8640000       0.00      0.00      0.00         1\n",
      "     8666666       0.00      0.00      0.00         0\n",
      "     8750000       0.00      0.00      0.00         1\n",
      "     8760335       0.00      0.00      0.00         1\n",
      "     8800000       0.00      0.00      0.00         1\n",
      "     8837774       0.00      0.00      0.00         1\n",
      "     8888888       0.00      0.00      0.00         1\n",
      "     8898000       0.00      0.00      0.00         1\n",
      "     8900000       0.00      0.00      0.00         1\n",
      "     8937500       0.00      0.00      0.00         1\n",
      "     8937931       0.00      0.00      0.00         1\n",
      "     8990000       0.00      0.00      0.00         1\n",
      "     9000000       0.01      0.09      0.01        11\n",
      "     9028575       0.00      0.00      0.00         1\n",
      "     9036364       0.00      0.00      0.00         1\n",
      "     9100000       0.00      0.00      0.00         1\n",
      "     9196000       0.00      0.00      0.00         1\n",
      "     9200000       0.00      0.00      0.00         2\n",
      "     9213484       0.00      0.00      0.00         0\n",
      "     9226250       0.00      0.00      0.00         1\n",
      "     9249980       0.00      0.00      0.00         1\n",
      "     9250000       0.00      0.00      0.00         1\n",
      "     9265000       0.00      0.00      0.00         1\n",
      "     9296874       0.00      0.00      0.00         1\n",
      "     9300000       0.00      0.00      0.00         1\n",
      "     9319000       0.00      0.00      0.00         1\n",
      "     9352400       0.00      0.00      0.00         1\n",
      "     9360000       0.00      0.00      0.00         2\n",
      "     9388000       0.00      0.00      0.00         1\n",
      "     9424084       0.00      0.00      0.00         1\n",
      "     9445000       0.00      0.00      0.00         1\n",
      "     9454546       0.00      0.00      0.00         1\n",
      "     9500000       0.20      0.25      0.22         4\n",
      "     9566667       0.00      0.00      0.00         1\n",
      "     9628000       0.00      0.00      0.00         1\n",
      "     9640000       0.00      0.00      0.00         1\n",
      "     9654342       0.00      0.00      0.00         1\n",
      "     9660000       0.00      0.00      0.00         1\n",
      "     9667969       0.00      0.00      0.00         1\n",
      "     9723983       0.00      0.00      0.00         1\n",
      "     9740000       0.00      0.00      0.00         1\n",
      "     9779349       0.00      0.00      0.00         1\n",
      "     9780992       0.00      0.00      0.00         1\n",
      "     9862500       0.00      0.00      0.00         1\n",
      "     9904494       0.00      0.00      0.00         1\n",
      "     9923285       0.00      0.00      0.00         1\n",
      "     9945000       0.00      0.00      0.00         2\n",
      "     9999999       0.00      0.00      0.00         1\n",
      "    10000000       0.00      0.00      0.00         8\n",
      "    10067750       0.00      0.00      0.00         2\n",
      "    10114000       0.00      0.00      0.00         1\n",
      "    10121000       0.00      0.00      0.00         1\n",
      "    10125000       0.00      0.00      0.00         1\n",
      "    10130000       0.00      0.00      0.00         3\n",
      "    10243200       0.00      0.00      0.00         1\n",
      "    10250000       0.00      0.00      0.00         1\n",
      "    10324380       0.00      0.00      0.00         1\n",
      "    10361446       0.00      0.00      0.00         1\n",
      "    10370425       0.00      0.00      0.00         1\n",
      "    10434782       0.00      0.00      0.00         1\n",
      "    10444642       0.00      0.00      0.00         1\n",
      "    10500000       0.00      0.00      0.00         2\n",
      "    10532977       0.00      0.00      0.00         1\n",
      "    10538937       0.00      0.00      0.00         1\n",
      "    10548596       0.00      0.00      0.00         1\n",
      "    10560000       0.00      0.00      0.00         1\n",
      "    10602667       0.00      0.00      0.00         1\n",
      "    10650000       0.00      0.00      0.00         1\n",
      "    10666667       0.00      0.00      0.00         1\n",
      "    10728130       0.00      0.00      0.00         1\n",
      "    10750000       0.00      0.00      0.00         1\n",
      "    10770000       0.00      0.00      0.00         1\n",
      "    10800000       0.00      0.00      0.00         5\n",
      "    10850000       0.00      0.00      0.00         1\n",
      "    10854850       0.00      0.00      0.00         1\n",
      "    10860000       0.00      0.00      0.00         1\n",
      "    10865250       0.00      0.00      0.00         2\n",
      "    10890000       0.00      0.00      0.00         1\n",
      "    10937500       0.00      0.00      0.00         1\n",
      "    10960000       0.00      0.00      0.00         1\n",
      "    10967500       0.00      0.00      0.00         1\n",
      "    10983000       0.00      0.00      0.00         1\n",
      "    10991957       0.00      0.00      0.00         1\n",
      "    11000000       0.00      0.00      0.00         1\n",
      "    11027862       0.00      0.00      0.00         1\n",
      "    11100005       0.00      0.00      0.00         1\n",
      "    11200000       0.00      0.00      0.00         1\n",
      "    11212500       0.00      0.00      0.00         1\n",
      "    11227000       0.00      0.00      0.00         1\n",
      "    11238564       0.00      0.00      0.00         1\n",
      "    11248076       0.00      0.00      0.00         1\n",
      "    11250000       0.00      0.00      0.00         6\n",
      "    11300000       0.00      0.00      0.00         1\n",
      "    11326219       0.00      0.00      0.00         3\n",
      "    11483254       0.00      0.00      0.00         1\n",
      "    11532037       0.00      0.00      0.00         1\n",
      "    11550000       0.00      0.00      0.00         1\n",
      "    11553000       0.00      0.00      0.00         1\n",
      "    11595506       0.00      0.00      0.00         1\n",
      "    11641095       0.00      0.00      0.00         1\n",
      "    11689062       0.00      0.00      0.00         1\n",
      "    11710456       0.00      0.00      0.00         1\n",
      "    11825000       0.00      0.00      0.00         1\n",
      "    11854584       0.00      0.00      0.00         1\n",
      "    11950400       0.00      0.00      0.00         1\n",
      "    11968253       0.00      0.00      0.00         1\n",
      "    12000000       0.02      0.30      0.04        10\n",
      "    12015904       0.00      0.00      0.00         1\n",
      "    12025694       0.00      0.00      0.00         1\n",
      "    12051510       0.00      0.00      0.00         1\n",
      "    12068182       0.00      0.00      0.00         1\n",
      "    12071250       0.00      0.00      0.00         1\n",
      "    12150000       0.00      0.00      0.00         1\n",
      "    12173913       0.00      0.00      0.00         1\n",
      "    12199968       0.00      0.00      0.00         1\n",
      "    12200000       0.00      0.00      0.00         2\n",
      "    12235750       0.00      0.00      0.00         1\n",
      "    12250000       0.00      0.00      0.00         1\n",
      "    12289544       0.00      0.00      0.00         1\n",
      "    12330000       0.00      0.00      0.00         1\n",
      "    12350000       0.00      0.00      0.00         1\n",
      "    12375000       0.22      0.33      0.27         6\n",
      "    12400000       0.00      0.00      0.00         1\n",
      "    12403101       0.00      0.00      0.00         1\n",
      "    12404495       0.00      0.00      0.00         1\n",
      "    12415000       0.00      0.00      0.00         1\n",
      "    12440787       0.00      0.00      0.00         1\n",
      "    12500000       0.00      0.00      0.00         3\n",
      "    12584688       0.00      0.00      0.00         1\n",
      "    12606250       0.00      0.00      0.00         1\n",
      "    12660000       0.00      0.00      0.00         1\n",
      "    12676125       0.00      0.00      0.00         1\n",
      "    12744000       0.00      0.00      0.00         1\n",
      "    12750000       0.00      0.00      0.00         1\n",
      "    12833333       0.00      0.00      0.00         1\n",
      "    12868632       0.00      0.00      0.00         1\n",
      "    12922194       0.00      0.00      0.00         1\n",
      "    12981038       0.00      0.00      0.00         1\n",
      "    13000000       0.00      0.00      0.00         2\n",
      "    13041250       0.00      0.00      0.00         1\n",
      "    13152000       0.00      0.00      0.00         1\n",
      "    13223140       0.00      0.00      0.00         1\n",
      "    13279750       0.00      0.00      0.00         2\n",
      "    13305000       0.00      0.00      0.00         1\n",
      "    13333333       0.00      0.00      0.00         2\n",
      "    13363012       0.00      0.00      0.00         1\n",
      "    13428129       0.00      0.00      0.00         1\n",
      "    13488377       0.00      0.00      0.00         1\n",
      "    13490000       0.00      0.00      0.00         1\n",
      "    13500000       0.00      0.00      0.00         6\n",
      "    13520500       0.00      0.00      0.00         1\n",
      "    13531750       0.00      0.00      0.00         1\n",
      "    13550000       0.00      0.00      0.00         2\n",
      "    13603750       0.00      0.00      0.00         1\n",
      "    13655268       0.00      0.00      0.00         1\n",
      "    13666667       0.00      0.00      0.00         1\n",
      "    13668750       0.00      0.00      0.00         1\n",
      "    13700000       0.00      0.00      0.00         2\n",
      "    13735000       0.00      0.00      0.00         1\n",
      "    13758000       0.00      0.00      0.00         1\n",
      "    13762775       0.00      0.00      0.00         1\n",
      "    13843156       0.00      0.00      0.00         1\n",
      "    13876321       0.00      0.00      0.00         1\n",
      "    13878000       0.00      0.00      0.00         1\n",
      "    13925000       0.00      0.00      0.00         1\n",
      "    14000000       0.00      0.00      0.00         1\n",
      "    14128000       0.00      0.00      0.00         1\n",
      "    14232567       0.00      0.00      0.00         1\n",
      "    14260870       0.00      0.00      0.00         0\n",
      "    14283844       0.00      0.00      0.00         1\n",
      "    14300000       0.00      0.00      0.00         1\n",
      "    14382022       0.00      0.00      0.00         1\n",
      "    14400000       0.00      0.00      0.00         1\n",
      "    14410581       0.00      0.00      0.00         1\n",
      "    14487000       0.00      0.00      0.00         1\n",
      "    14500000       0.00      0.00      0.00         1\n",
      "    14598888       0.00      0.00      0.00         1\n",
      "    14601500       0.00      0.00      0.00         1\n",
      "    14625000       0.25      0.50      0.33         2\n",
      "    14653466       0.00      0.00      0.00         1\n",
      "    14693906       0.00      0.00      0.00         1\n",
      "    14700000       0.00      0.00      0.00         1\n",
      "    14746000       0.00      0.00      0.00         1\n",
      "    14860523       0.00      0.00      0.00         1\n",
      "    14880000       0.00      0.00      0.00         1\n",
      "    14900000       0.00      0.00      0.00         1\n",
      "    14940152       0.00      0.00      0.00         1\n",
      "    14940153       0.00      0.00      0.00         1\n",
      "    14956522       0.00      0.00      0.00         1\n",
      "    14976754       0.00      0.00      0.00         1\n",
      "    15000000       0.00      0.00      0.00         4\n",
      "    15050000       0.00      0.00      0.00         1\n",
      "    15070000       0.00      0.00      0.00         1\n",
      "    15101625       0.00      0.00      0.00         3\n",
      "    15200000       0.00      0.00      0.00         1\n",
      "    15260000       0.00      0.00      0.00         1\n",
      "    15330435       0.00      0.00      0.00         0\n",
      "    15500000       0.00      0.00      0.00         3\n",
      "    15694250       0.00      0.00      0.00         1\n",
      "    15719062       0.00      0.00      0.00         1\n",
      "    15750000       0.00      0.00      0.00         1\n",
      "    15779912       0.00      0.00      0.00         0\n",
      "    15937500       0.00      0.00      0.00         1\n",
      "    15959099       0.00      0.00      0.00         1\n",
      "    16000000       0.00      0.00      0.00         1\n",
      "    16006000       0.00      0.00      0.00         1\n",
      "    16192080       0.00      0.00      0.00         1\n",
      "    16324500       0.00      0.00      0.00         1\n",
      "    16359805       0.00      0.00      0.00         2\n",
      "    16400000       0.00      0.00      0.00         1\n",
      "    16440000       0.00      0.00      0.00         2\n",
      "    16447871       0.00      0.00      0.00         1\n",
      "    16452000       0.00      0.00      0.00         1\n",
      "    16460538       0.00      0.00      0.00         1\n",
      "    16500000       0.00      0.00      0.00         1\n",
      "    16647180       0.00      0.00      0.00         1\n",
      "    16663575       0.00      0.00      0.00         1\n",
      "    16744218       0.00      0.00      0.00         1\n",
      "    16901500       0.00      0.00      0.00         1\n",
      "    17000000       0.00      0.00      0.00         3\n",
      "    17059727       0.00      0.00      0.00         1\n",
      "    17149243       0.00      0.00      0.00         1\n",
      "    17177795       0.00      0.00      0.00         1\n",
      "    17184375       0.00      0.00      0.00         1\n",
      "    17429672       0.00      0.00      0.00         1\n",
      "    17545000       0.00      0.00      0.00         1\n",
      "    17638063       0.00      0.00      0.00         2\n",
      "    17718750       0.00      0.00      0.00         1\n",
      "    17730694       0.00      0.00      0.00         1\n",
      "    17800000       0.00      0.00      0.00         1\n",
      "    18000000       0.00      0.00      0.00         1\n",
      "    18091770       0.00      0.00      0.00         1\n",
      "    18300000       0.00      0.00      0.00         2\n",
      "    18314532       0.00      0.00      0.00         1\n",
      "    18466130       0.00      0.00      0.00         1\n",
      "    18500000       0.00      0.00      0.00         1\n",
      "    18776860       0.00      0.00      0.00         1\n",
      "    18862875       0.00      0.00      0.00         1\n",
      "    19000000       0.00      0.00      0.00         1\n",
      "    19014187       0.00      0.00      0.00         1\n",
      "    19067500       0.00      0.00      0.00         1\n",
      "    19536360       0.00      0.00      0.00         1\n",
      "    19573711       0.00      0.00      0.00         1\n",
      "    19752645       0.00      0.00      0.00         1\n",
      "    19795712       0.00      0.00      0.00         1\n",
      "    19795714       0.00      0.00      0.00         1\n",
      "    19948799       0.00      0.00      0.00         1\n",
      "    20072033       0.00      0.00      0.00         1\n",
      "    20140838       0.00      0.00      0.00         1\n",
      "    20370437       0.00      0.00      0.00         1\n",
      "    20513178       0.00      0.00      0.00         1\n",
      "    20575005       0.00      0.00      0.00         1\n",
      "    20644400       0.00      0.00      0.00         1\n",
      "    20869566       0.00      0.00      0.00         1\n",
      "    21165675       0.00      0.00      0.00         1\n",
      "    21323250       0.00      0.00      0.00         1\n",
      "    21372000       0.00      0.00      0.00         1\n",
      "    21679893       0.00      0.00      0.00         1\n",
      "    22116750       0.00      0.00      0.00         4\n",
      "    22407474       0.00      0.00      0.00         1\n",
      "    22721381       0.00      0.00      0.00         1\n",
      "    23410988       0.00      0.00      0.00         1\n",
      "    23750000       0.00      0.00      0.00         1\n",
      "    24806250       0.00      0.00      0.00         1\n",
      "    26540100       0.00      0.00      0.00         1\n",
      "    27849149       0.00      0.00      0.00         1\n",
      "    30963450       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.03      4037\n",
      "   macro avg       0.00      0.00      0.00      4037\n",
      "weighted avg       0.01      0.03      0.01      4037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lukmac/.local/share/virtualenvs/data-mining-nba-jhiA2YFt/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_nn, predictions))\n",
    "print(classification_report(y_test_nn, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
